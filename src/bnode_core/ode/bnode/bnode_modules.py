import torch
import torch.nn as nn
import logging
from bnode_core.ode.ode_utils.initialize_model import initialize_weights_biases
from bnode_core.nn.nn_utils.normalization import NormalizationLayer1D
    
class GeneralEncoder(nn.Module):

    def __init__(self, 
                 input_dim: int,
                 lat_dim: int,
                 hidden_dim: int,
                 n_layers: int,
                 activation: nn.Module = nn.ELU,
                 initialization: str = 'identity',
                 include_parameters: bool = False,
                 include_controls: bool = False,
                 param_dim: int = 0,
                 controls_dim: int = 0,
                 linear: bool = False,
                 ):
        # include_parameters and param_dim was added to incorporate a state and controls encoder that is dependent on parameters
        super().__init__()
        if param_dim > 0 and include_parameters is False:
            raise ValueError('param_dim > 0 but include_parameters is False')
        self.input_dim = input_dim
        if include_parameters:
            self.input_dim += param_dim
        if include_controls:
            self.input_dim += controls_dim
        self.lat_dim = lat_dim

        self.include_parameters = include_parameters
        self.include_controls = include_controls
        # define layers
        self.normalization = NormalizationLayer1D(input_dim)
        if include_parameters:
            self.normalization_params = NormalizationLayer1D(param_dim)
        if self.include_controls:
            self.normalization_controls = NormalizationLayer1D(controls_dim)


        if not linear:
            modules = [
                nn.Linear(self.input_dim, hidden_dim),
                activation(),
            ]
            if n_layers < 2:
                logging.warning('n_layers must be at least 2, setting n_layers to 2')
            for i in range(n_layers-2):
                modules.append(nn.Linear(hidden_dim, hidden_dim))
                modules.append(activation())
            modules.append(nn.Linear(hidden_dim, 2 * self.lat_dim))
            self.net = nn.Sequential(*modules)
        else:
            self.net= nn.Sequential(nn.Linear(self.input_dim, 2 * self.lat_dim, bias=True))
        
        initialize_weights_biases(self.net, initialization)

        # initialize mask
        self.register_buffer("mask_set", torch.tensor(False))
        self.register_buffer("mask", torch.ones(self.lat_dim))
    
    def set_mask(self, mask):
        self.mask_set.set_(torch.tensor(True, device=mask.device))
        self.mask.set_(torch.tensor(mask.clone().detach(), device=mask.device, dtype=torch.float32))

    def forward(self, x, params = None, controls = None):
        """
        x: [batch_size, input_dim]
        """
        x = self.normalization(x)
        if self.include_parameters:
            params = self.normalization_params(params)
            x = torch.cat([x, params], dim=1)
        if self.include_controls:
            controls = self.normalization_controls(controls)
            x = torch.cat([x, controls], dim=1)
        mu, logvar = torch.split(self.net(x), self.lat_dim, dim=1)

        if self.mask_set:
            mu = mu * self.mask
            logvar = torch.zeros(logvar.size(), device=logvar.device) # set logvar to zero if mask is set

        return mu, logvar
    
class ssm_from_param(nn.Module):
    '''
    This is a module to compute the system matrix A and control matrix B from parameters.
    It is used for BNODE with a linear latent ODE function.
    It is a simple linear layer that takes the parameters as input and outputs the system matrix A and control matrix B.
    It is a separate module to allow easy onnx export and allow one calculation of the matrices A and B for a whole trajectory.
    '''
    def __init__(self, lat_parameter_dim: int, lat_state_dim: int, include_controls: bool = False, lat_control_dim: int = 0, initialization_ode: str = None):
        super().__init__()
        self.lat_state_dim = lat_state_dim
        self.lat_parameter_dim = lat_parameter_dim
        self.include_controls = include_controls
        self.lat_control_dim = lat_control_dim

        self.A_from_param = nn.Linear(self.lat_parameter_dim, self.lat_state_dim * self.lat_state_dim, bias=True)
        if self.include_controls:
            self.B_from_param = nn.Linear(self.lat_parameter_dim, self.lat_state_dim * self.lat_control_dim, bias=True)
        # for the initialization of the weights and biases
        _in_n_args = [self.lat_state_dim, self.lat_parameter_dim]
        if self.include_controls:
            _in_n_args.append(self.lat_control_dim)
        _out_features = self.lat_state_dim
        initialize_weights_biases(self, initialization_ode, in_n_args=_in_n_args, out_features=_out_features)

    def forward(self, lat_parameters):
        """
        lat_parameters: [batch_size, lat_parameter_dim]
        """
        A = self.A_from_param(lat_parameters)
        A = A.view(-1, self.lat_state_dim, self.lat_state_dim)

        if self.include_controls:
            B = self.B_from_param(lat_parameters)
            B = B.view(-1, self.lat_state_dim, self.lat_control_dim)
        
        return A, B if self.include_controls else A
    
class LatentODEFunc(nn.Module):

    def __init__(self,
                 lat_state_mu_dim: int,
                 lat_control_dim: int,
                 lat_parameter_dim: int,
                 hidden_dim: int,
                 n_layers: int,
                 activation: nn.Module = nn.ELU,
                 initialization_ode: str = 'identity',
                 initialization_system_matrix: str = None,
                 lat_ode_type: str = 'variance_constant', # must be one of ['variance_constant', 'variance_dynamic', 'vanilla']
                 linear: bool = False,
                 lat_state_mu_independent: bool = False,
                 ):
        if initialization_system_matrix is not None and linear is False:
            logging.warning('initialization_system_matrix is only used for linear models, setting it to None')
            initialization_system_matrix = None
        if initialization_system_matrix is not None and linear is True and lat_parameter_dim > 0:
            logging.warning('initialization_system_matrix is only used for linear models without parameters, setting it to None')
            logging.warning('if you want to do eigenvalue shifting with parameters, you can use the move_eigvals_net method')
            initialization_system_matrix = None
        
        super().__init__()
        self.lat_state_dim = lat_state_mu_dim if not lat_ode_type == 'variance_dynamic' else 2 * lat_state_mu_dim
        self.lat_state_mu_dim = lat_state_mu_dim
        self.lat_control_dim = lat_control_dim
        self.lat_parameter_dim = lat_parameter_dim

        self.include_controls = True if lat_control_dim > 0 else False
        self.include_parameters = True if lat_parameter_dim > 0 else False

        self.lat_ode_type = lat_ode_type
        self.lat_state_mu_independent = lat_state_mu_independent
        if self.lat_ode_type != 'variance_dynamic' and self.lat_state_mu_independent:
            logging.warning('lat_state_mu_independent is only used for lat_ode_type variance_dynamic, setting it to False')
            self.lat_state_mu_independent, lat_state_mu_independent = False, False
        self.linear = linear

        # initialize mask
        self.register_buffer("mask_set", torch.tensor(False))
        self.register_buffer("mask", torch.ones(self.lat_state_dim))

        # define layers
        if not linear:
            if lat_ode_type == 'variance_dynamic':
                if self.lat_state_mu_independent is False:
                    modules = self.construct_net(self.lat_state_dim, self.lat_state_dim, hidden_dim, n_layers, activation)
                    self.net = nn.Sequential(*modules)
                else:
                    modules = self.construct_net(lat_state_mu_dim, lat_state_mu_dim, hidden_dim, n_layers, activation) # (f(\mu(x), u, p))
                    self.net = nn.Sequential(*modules)
                    modules = self.construct_net(self.lat_state_dim, lat_state_mu_dim, hidden_dim, n_layers, activation) # (f(\mu(x), \sigma(x), u, p))
                    self.net_sigma = nn.Sequential(*modules)
            else:
                modules = self.construct_net(self.lat_state_dim, self.lat_state_dim, hidden_dim, n_layers, activation)
                self.net = nn.Sequential(*modules)
            initialize_weights_biases(self.net, initialization_ode)
            if self.lat_state_mu_independent:
                initialize_weights_biases(self.net_sigma, initialization_ode)
        else: # linear case
            if self.lat_state_mu_independent is True: # TODO: test this. This must be set here, before calling initialize_weights_biases if we use a train_to_negative_eigenvalues method
                # create a mask of the form for the system matrix A:
                # [[1,0]   * [\mu(x),
                #  [1,1]]    \sigma(x)]
                self.register_buffer("mask_A_mu_independent", torch.zeros(self.lat_state_dim, self.lat_state_dim))
                mask_A_mu_independent = torch.zeros(self.lat_state_dim, self.lat_state_dim)
                mask_A_mu_independent[:self.lat_state_mu_dim, :self.lat_state_mu_dim] = 1
                mask_A_mu_independent[self.lat_state_mu_dim:, :] = 1
                self.mask_A_mu_independent.set_(mask_A_mu_independent)
                assert self.mask_A_mu_independent.requires_grad == False
            # construct a linear state space model: xdot = Ax + Bu
            if not self.include_parameters:
                # if no parameters are included, we can use a simple linear model
                self.A = nn.Linear(self.lat_state_dim, self.lat_state_dim, bias=False)
                initialize_weights_biases(self.A, initialization_system_matrix)
                if self.include_controls:
                    self.B = nn.Linear(self.lat_control_dim, self.lat_state_dim, bias=False)
                    if initialization_ode == 'move_eigvals_net':
                        logging.warning('move_eigvals_net is an unsuitable initialization method for the control matrix')
                    initialize_weights_biases(self.B, initialization_ode)
            else:           
                # if parameters are included, we need to calculate the matrices A and B depending on the parameters
                self.ssm_from_param = ssm_from_param(lat_parameter_dim, self.lat_state_dim, self.include_controls, self.lat_control_dim, initialization_ode)
    
    def set_mask(self, mask):
        '''
        Set the mask for the latent state, used for deterministic training.
        mask: [lat_state_dim] or [lat_state_mu_dim] if lat_ode_type == 'variance_dynamic': mask for the latent state (boolean tensor or tensor with values 0 or 1)
        '''
        self.mask_set.set_(torch.tensor(True, device=mask.device))
        if self.lat_ode_type == 'variance_dynamic':
            _mask = torch.zeros(self.lat_state_dim, device=mask.device)
            _mask[:self.lat_state_mu_dim] = mask # set mask for mu
            # sigma mask is set to 1, as we do not want to include dynamics for sigma
            self.mask.set_(torch.tensor(_mask.clone().detach(), device=mask.device, dtype=torch.float32))
        else:
            self.mask.set_(torch.tensor(mask.clone().detach(), device=mask.device, dtype=torch.float32))
    
    def construct_net(self, state_in_dim, state_out_dim, hidden_dim, n_layers, activation):
        modules = [
                nn.Linear(state_in_dim + self.lat_control_dim + self.lat_parameter_dim, hidden_dim),
                activation(),
            ]
        if n_layers < 2:
            logging.warning('n_layers must be at least 2, setting n_layers to 2')#
        for i in range(n_layers-2):
            modules.append(nn.Linear(hidden_dim, hidden_dim))
            modules.append(activation())
        modules.append(nn.Linear(hidden_dim, state_out_dim))
        return modules

    def forward(self, lat_states, lat_parameters = None, lat_controls=None, 
                A_from_param: torch.Tensor = None, B_from_param: torch.Tensor = None
                ):
        """
        lat_state: [batch_size, lat_state_dim]
        lat_parameters: [batch_size, lat_parameter_dim]
        lat_controls: [batch_size, lat_control_dim]
        """
        if not self.linear:
            if not self.lat_ode_type == 'variance_dynamic' or (self.lat_ode_type == 'variance_dynamic' and self.lat_state_mu_independent is False):
                if self.include_controls and self.include_parameters:
                    x = torch.cat([lat_states, lat_parameters, lat_controls], dim=1)
                elif self.include_controls:
                    x = torch.cat([lat_states, lat_controls], dim=1)
                elif self.include_parameters:
                    x = torch.cat([lat_states, lat_parameters], dim=1)
                else:
                    x = lat_states
                lat_states_dot = self.net(x)
            else: # independent mu from sigma
                _states_mu = lat_states[:, :self.lat_state_mu_dim]
                if self.include_controls and self.include_parameters:
                    x_mu = torch.cat([_states_mu, lat_parameters, lat_controls], dim=1)
                    x_sigma = torch.cat([lat_states, lat_parameters, lat_controls], dim=1)
                elif self.include_controls:
                    x_mu = torch.cat([_states_mu, lat_controls], dim=1)
                    x_sigma = torch.cat([lat_states, lat_controls], dim=1)
                elif self.include_parameters:
                    x_mu = torch.cat([_states_mu, lat_parameters], dim=1)
                    x_sigma = torch.cat([lat_states, lat_parameters], dim=1)
                else:
                    x_mu = _states_mu
                    x_sigma = lat_states
                lat_state_mu_dot = self.net(x_mu)
                lat_state_sigma_dot = self.net_sigma(x_sigma)
                lat_states_dot = torch.cat([lat_state_mu_dot, lat_state_sigma_dot], dim=1)
        else: # linear case
            if self.include_parameters:
                if self.lat_state_mu_independent: # TODO: test this
                    A_from_param = A_from_param * self.mask_A_mu_independent # element-wise multiplication with mask
                lat_states_dot = torch.matmul(A_from_param, lat_states.unsqueeze(-1)).squeeze(-1)
                if self.include_controls:
                    B_from_param = B_from_param.view(-1, self.lat_state_dim, self.lat_control_dim)
                    lat_states_dot += torch.matmul(B_from_param, lat_controls.unsqueeze(-1)).squeeze(-1)
            else:
                if self.lat_state_mu_independent: # TODO: test this 
                    # TODO: could make this more efficient by using a multiplication with the mask as above?
                    self.A.weight = torch.nn.Parameter(self.A.weight * self.mask_A_mu_independent)
                lat_states_dot = self.A(lat_states)
                if self.include_controls:
                    lat_states_dot += self.B(lat_controls)
        
        if self.mask_set:
            lat_states_dot = lat_states_dot * self.mask

        return lat_states_dot
    
class Decoder(nn.Module):

    def __init__(self, 
                 lat_state_mu_dim: int,
                 lat_control_dim: int,
                 lat_parameter_dim: int,
                 state_dim: int,
                 outputs_dim: int,
                 hidden_dim: int,
                 n_layers: int,
                 activation: nn.Module = nn.ELU,
                 initialization: str = 'identity',
                 linear: bool = False,
                 include_states_grad: bool = False,
                 include_outputs_grad: bool = False,
                 ):
        super().__init__()
        self.lat_state_mu_dim = lat_state_mu_dim
        self.lat_control_dim = lat_control_dim
        self.lat_parameter_dim = lat_parameter_dim

        self.out_dim = state_dim + outputs_dim
        self.state_dim = state_dim
        self.outputs_dim = outputs_dim

        self.include_controls = True if lat_control_dim > 0 else False
        self.include_parameters = True if lat_parameter_dim > 0 else False
        self.include_outputs = True if outputs_dim > 0 else False
        self.include_states = True if state_dim > 0 else False
        self.include_states_grad = include_states_grad and self.include_states
        self.include_outputs_grad = include_outputs_grad and self.include_outputs

        self.linear = linear

        self.onnx_export = False # used for disabling the concatenation of the outputs in the forward method

        # define layers
        self.state_normalization = NormalizationLayer1D(state_dim) if state_dim > 0 else None
        self.outputs_normalization = NormalizationLayer1D(outputs_dim) if outputs_dim > 0 else None
        self.states_grad_normalization = NormalizationLayer1D(state_dim) if self.include_states_grad else None
        self.outputs_grad_normalization = NormalizationLayer1D(outputs_dim) if self.include_outputs_grad else None

        if self.state_dim == 0 and self.outputs_dim == 0:
            raise ValueError('state_dim and outputs_dim cannot be both zero, you need to include at least one of them')

        if not linear:
            modules = [
                nn.Linear(self.lat_state_mu_dim + self.lat_control_dim + self.lat_parameter_dim, hidden_dim),
                activation(),
            ]
            if n_layers < 2:
                logging.warning('n_layers must be at least 2, setting n_layers to 2')
            for i in range(n_layers-2):
                modules.append(nn.Linear(hidden_dim, hidden_dim))
                modules.append(activation())
            modules.append(nn.Linear(hidden_dim, self.out_dim))
            self.net = nn.Sequential(*modules)

            initialize_weights_biases(self.net, initialization)
        else:
            # construct a linear state space model: y = Cx + Du
            if not self.include_parameters:
                self.C = nn.Linear(self.lat_state_mu_dim, self.out_dim, bias=True) # a bias shouldn't be harmful
                initialize_weights_biases(self.C, initialization)
                if self.include_controls:
                    self.D = nn.Linear(self.lat_control_dim, self.out_dim, bias=False)
                    initialize_weights_biases(self.D, initialization)
            else:
                self.C_and_constant_from_param = nn.Linear(self.lat_parameter_dim, self.out_dim * self.lat_state_mu_dim + self.out_dim, bias=True) # to get C matrix + constant
                initialize_weights_biases(self.C_and_constant_from_param, initialization)
                if self.include_controls:
                    self.D_from_param = nn.Linear(self.lat_parameter_dim, self.out_dim * self.lat_control_dim, bias=True)
                    initialize_weights_biases(self.D_from_param, initialization)

    def forward(self, 
                lat_state: torch.Tensor,
                lat_parameters: torch.Tensor = None,
                lat_controls: torch.Tensor = None,
                ):
        """
        lat_state: [batch_size, lat_state_mu_dim]
        lat_parameters: [batch_size, lat_parameter_dim]
        lat_controls: [batch_size, lat_control_dim]
        """
        if not self.linear:
            if self.include_controls and self.include_parameters:
                lat_state = torch.cat([lat_state, lat_parameters, lat_controls], dim=1)
            elif self.include_controls:
                lat_state = torch.cat([lat_state, lat_controls], dim=1)
            elif self.include_parameters:
                lat_state = torch.cat([lat_state, lat_parameters], dim=1)
            x = self.net(lat_state)
        else:
            if not self.include_parameters:
                x = self.C(lat_state)
                if self.include_controls:
                    x += self.D(lat_controls)
            else:
                _C = self.C_and_constant_from_param(lat_parameters)
                C, constant = torch.split(_C, [self.out_dim * self.lat_state_mu_dim, self.out_dim], dim=1) # TODO: check if this is correct
                C = C.view(-1, self.out_dim, self.lat_state_mu_dim)
                constant = constant.reshape(-1, self.out_dim)
                x = torch.matmul(C, lat_state.unsqueeze(-1)).squeeze(-1) + constant
                if self.include_controls:
                    D = self.D_from_param(lat_parameters)
                    D = D.view(-1, self.out_dim, self.lat_control_dim)
                    x += torch.matmul(D, lat_controls.unsqueeze(-1)).squeeze(-1)
        if self.include_outputs and self.include_states:
            state_norm, outputs_norm = torch.split(x, [self.state_dim, self.outputs_dim], dim=1)
        elif self.include_states:
            state_norm, outputs_norm = x, None
        elif self.include_outputs:
            state_norm, outputs_norm = None, x  
        else:
            raise ValueError('state_dim and outputs_dim cannot be both zero, you need to include at least one of them')
        
        state = self.state_normalization(state_norm, denormalize=True) if self.include_states else None
        outputs = self.outputs_normalization(outputs_norm, denormalize=True) if self.include_outputs else None
        if self.onnx_export:
            # return without concatenation for ONNX export
            if self.include_outputs and self.include_states:
                return state, outputs
            elif self.include_outputs:
                return outputs
            elif self.include_states:
                return state
        if self.include_outputs and self.include_states:
            return torch.cat([state_norm, outputs_norm, state, outputs], dim=1)
        elif self.include_outputs:
            return torch.cat([outputs_norm, outputs], dim=1)
        elif self.include_states:
            return torch.cat([state_norm, state], dim=1)
    
    def split_return(self, x):
        if self.include_outputs and self.include_states:
            state_norm, outputs_norm, state, outputs = torch.split(x, [self.state_dim, self.outputs_dim, self.state_dim, self.outputs_dim], dim=1)
        elif self.include_states:
            state_norm, state = torch.split(x, [self.state_dim, self.state_dim], dim=1)
            outputs_norm, outputs = None, None
        elif self.include_outputs:
            outputs_norm, outputs = torch.split(x, [self.outputs_dim, self.outputs_dim], dim=1)
            state_norm, state = None, None
        return state, outputs, state_norm, outputs_norm