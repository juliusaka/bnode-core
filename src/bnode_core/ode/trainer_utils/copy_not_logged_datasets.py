"""Copy artifacts that failed to log during MLflow training runs.

.. warning::
    **NOT CURRENTLY MAINTAINED OR TESTED**
    **Documentation generated by AI - please be aware of mistakes**
    
    This module is not actively maintained and has not been tested recently.
    Use at your own risk. The functionality may be outdated or incompatible
    with current MLflow/project versions.

This utility script recovers artifacts that could not be logged to MLflow during
training runs due to various issues (network failures, file locks, timeout, etc.).
It reads a special error file (`could_not_log_artifacts.txt`) from the MLflow
artifact store and copies the listed files to their intended destination.

Typical Usage Example
---------------------
Copy artifacts for specific runs::

    python copy_not_logged_datasets.py \\
        run_id=8c2c32b9407a4e20946f72cd1c714776,fef513818b67421eb5f450169a429508 \\
        mlflow_tracking_uri=http://localhost:5000

Copy artifacts for all runs in an experiment::

    python copy_not_logged_datasets.py \\
        experiment=my_experiment \\
        mlflow_tracking_uri=http://localhost:5000

Copy artifacts for specific run names::

    python copy_not_logged_datasets.py \\
        experiment=my_experiment \\
        run_name=rebellious-quail-290,traveling-worm-98 \\
        mlflow_tracking_uri=http://localhost:5000

Command Line Arguments
----------------------
Run Selection (one of):
    run_id : str or list[str]
        Comma-separated MLflow run ID(s) to process.
    experiment : str
        Experiment name. Processes all runs if no run_name specified.
    experiment + run_name : str
        Experiment name with specific comma-separated run names.

Optional:
    mlflow_tracking_uri : str
        URI of MLflow tracking server. Defaults to 'http://localhost:5000'.

How It Works
------------
1. Connects to the MLflow tracking server.
2. For each specified run:
   - Checks for `could_not_log_artifacts.txt` in the artifact store.
   - If found, reads the list of files that failed to log.
   - Copies each missing/different file to the MLflow artifact directory.
   - Skips files that already exist with matching size.

Error File Format
-----------------
The `could_not_log_artifacts.txt` file should contain entries like::

    File: /path/to/file1.pt
    File: /path/to/file2.hdf5

Notes
-----
- The script assumes the error file exists in the artifact URI.
- Files are compared by size before copying to avoid redundant operations.
- Original file paths must still be accessible from where the script runs.
- No validation is performed on file integrity beyond size comparison.

Limitations
-----------
- Not tested with recent MLflow versions.
- No comprehensive error handling for corrupted error files.
- Does not handle files that have been moved/deleted since training.
- No progress indication for large file copies.

See Also
--------
bnode_core.ode.trainer : Main training module that may generate the error file.
mlflow : MLflow documentation for artifact management.
"""

import mlflow
import sys
import logging
import tempfile
import shutil
import bnode_core.filepaths as filepaths
import yaml
import pathlib
import subprocess
import hydra
from bnode_core.ode.trainer import train_all_phases
from multiprocessing import Pool

def parse_command_line_args(sys_argv):
    """Parse command line arguments into a dictionary.
    
    Args:
        sys_argv (list[str]): System argument vector (typically sys.argv).
            Expected format: 'key=value1,value2' (values split by comma).
    
    Returns:
        dict: Parsed arguments with keys mapped to lists of values.
    
    Examples:
        >>> parse_command_line_args(['script.py', 'run_id=abc123,def456'])
        {'run_id': ['abc123', 'def456']}
    """
    command_line_args = {}
    sys_argv = sys_argv[1:]
    for arg in sys_argv:
        key, value = arg.split("=")
        command_line_args[key] = value.split(",")
    return command_line_args

def get_run_ids(command_line_args):
    """Retrieve MLflow run IDs based on provided selection criteria.
    
    Resolves run IDs from either direct run_id specification, run_name lookup
    within an experiment, or all runs from an experiment.
    
    Args:
        command_line_args (dict): Parsed command line arguments containing one of:
            - 'run_id': Direct list of run IDs.
            - 'experiment' + 'run_name': Experiment name and specific run names.
            - 'experiment': All runs from the experiment.
            Optional:
            - 'mlflow_tracking_uri': MLflow server URI.
    
    Returns:
        list[str]: List of MLflow run IDs to process.
    
    Raises:
        ValueError: If incompatible argument combinations are provided
            (e.g., both run_name and run_id, or both run_id and experiment).
    
    Side Effects:
        - Sets MLflow tracking URI via mlflow.set_tracking_uri().
        - Prints progress messages about run ID retrieval.
    """
    if "mlflow_tracking_uri" in command_line_args:
        mlflow.set_tracking_uri(command_line_args["mlflow_tracking_uri"][0])
    else:
        print("No mlflow_tracking_uri provided. Using default.")
        mlflow.set_tracking_uri("http://localhost:5000")

    # get run_ids
    if "run_name" in command_line_args.keys() and "run_id" in command_line_args.keys():
        raise ValueError("Both run_name and run_id provided. Please provide only one.")
    
    if "run_id" in command_line_args.keys() and "experiment" in command_line_args.keys():
        raise ValueError("Both run_id and experiment provided. Please provide only one.")

    if "experiment" in command_line_args.keys():
        experiment_name = command_line_args["experiment"]
        print("experiment_name: ", experiment_name)
        print("searching for runs of experiment")
        experiment = mlflow.get_experiment_by_name(experiment_name[0])
        runs = mlflow.search_runs(experiment.experiment_id)
        if "run_name" in command_line_args:
            # retrieve run_ids from run_names
            print("searching for run_ids of run_names")
            run_names = command_line_args["run_name"]
            run_ids = []
            for run_name in run_names:
                run_ids.append(runs[runs["tags.mlflow.runName"] == run_name]["run_id"].values[0])
        else:
            print("using all runs of experiment")
            run_ids = runs["run_id"].to_list()
    else:
        run_ids = command_line_args["run_id"]
    print("run_ids: ", run_ids)
    return run_ids

def main():
    """Main execution function for copying unlogged artifacts.
    
    Orchestrates the complete workflow:
    1. Parses command line arguments.
    2. Retrieves run IDs from MLflow.
    3. For each run:
       - Checks for the error file indicating failed artifact logging.
       - Parses the list of files from the error file.
       - Copies each file to the MLflow artifact directory if missing or different.
       - Compares files by size to avoid redundant copies.
    
    Side Effects:
        - Connects to MLflow tracking server.
        - Reads `could_not_log_artifacts.txt` from artifact store.
        - Copies files from their original locations to MLflow artifacts.
        - Prints progress and status messages.
    
    Notes:
        - Files are only copied if they don't exist or have different sizes.
        - Original file paths from the error file must be accessible.
        - No backup is created before copying.
    
    Raises:
        FileNotFoundError: If original files listed in error file are missing.
        PermissionError: If insufficient permissions to copy files.
    """
    command_line_args = parse_command_line_args(sys.argv)

    run_ids = get_run_ids(command_line_args)
    
    jobs = 0
    for run_id in run_ids:
        # retrieve config from mlflow
        _artifact_uri = mlflow.get_run(run_id).info.artifact_uri
        _error_file_path = filepaths.filepath_from_ml_artifacts_uri(_artifact_uri + "/could_not_log_artifacts.txt")
        if pathlib.Path(_error_file_path).exists():
            print("For run_id {} files could not be logged.".format(run_id))
            with open(_error_file_path, 'r') as f:
                file = f.read()
            unlogged_files = file.split("\nFile: ")
            unlogged_files = unlogged_files[1:]
            unlogged_files[-1] = unlogged_files[-1].split("\n")[0]
            print(unlogged_files)
            for file in unlogged_files:
                _file_path = pathlib.Path(file)
                _target_path = filepaths.filepath_from_ml_artifacts_uri(_artifact_uri) / _file_path.name
                print("Copying file {} \n\tto {}".format(_file_path, _target_path))
                _copy = False
                if _target_path.exists():
                    # compare file sizes
                    if _file_path.stat().st_size == _target_path.stat().st_size:
                        print("Files are equal. Skipping.")
                    else:
                        print("Files are not equal. Copying file")
                        _copy = True
                else:
                    print("File does not exist. Copying file.")
                    _copy = True
                if _copy:
                    shutil.copy(_file_path, _target_path)



if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    # experiment_id
    # sys.argv += ["experiment=myModel"] # oder 232112805895166389"]
    # run_name
    # sys.argv += ["run_name=rebellious-quail-290,traveling-worm-98,capable-hawk-622"]
    # # or run_id
    # sys.argv = ["run_id=8c2c32b9407a4e20946f72cd1c714776,fef513818b67421eb5f450169a429508"]
    # mlflow_tracking_uri
    # sys.argv += ["mlflow_tracking_uri=http://localhost:5000"]
    main()