"""Early stopping utility for PyTorch model training.

Monitors validation loss and stops training when no improvement is observed
for a specified number of epochs (patience). Saves best model checkpoint.

Attention:
    This documentation is generated by AI. Please be aware of possible inaccurcies.

"""

import numpy as np
import logging
import torch

class EarlyStopping:
    """Stop training early if validation loss doesn't improve after given patience.
    
    Tracks validation loss and saves model checkpoints when improvements occur.
    Triggers early stopping flag when loss plateaus for 'patience' epochs.
    
    Attributes:
        patience: Number of epochs to wait before stopping after loss plateau.
        verbose: If True, print messages for each loss improvement.
        counter: Number of epochs since last loss improvement.
        best_score: Best validation loss seen so far.
        corresponding_score: Training loss corresponding to best validation loss.
        early_stop: Flag indicating whether to stop training.
        score_last_save: Validation loss at last checkpoint save.
        threshold: Minimum loss improvement to qualify as improvement.
        threshold_mode: Either 'abs' (absolute) or 'rel' (relative) threshold.
        path: File path for saving model checkpoint.
        optimizer_path: File path for saving optimizer state.
    """

    def __init__(self, patience=7, verbose=False, threshold=0, threshold_mode ='abs', 
                 path='checkpoint.pt', optimizer_path='optimizer.pt', trace_func=print):
        """Initialize early stopping monitor.
        
        Args:
            patience: Number of epochs to wait after last validation loss improvement
                before triggering early stop. Default: 7.
            verbose: If True, prints message for each validation loss improvement. Default: False.
            threshold: Minimum change in monitored loss to qualify as improvement. Default: 0.
            threshold_mode: Either 'abs' (absolute: loss < best - threshold) or 
                'rel' (relative: loss < best * (1 - threshold)). Default: 'abs'.
            path: Path to save best model checkpoint. Default: 'checkpoint.pt'.
            optimizer_path: Path to save optimizer state. Default: 'optimizer.pt'.
            trace_func: Logging function for status messages. Default: print.
        """
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.corresponding_score = None
        self.early_stop = False
        self.score_last_save = np.inf
        self.threshold = threshold
        self.threshold_mode = threshold_mode
        self.path = path
        self.optimizer_path = optimizer_path
        self.trace_func = trace_func
        self.trace_func('EarlyStopping initialized with patience = {}, threshold = {}, threshold_mode = {}'.format(
            self.patience, self.threshold, self.threshold_mode))
        
    def reset(self):
        """Reset all early stopping state to initial values.
        
        Useful for starting a new training phase with fresh early stopping.
        """
        self.reset_counter()
        self.best_score = None
        self.corresponding_score = None
        self.early_stop = False
        self.score_last_save = np.inf

    def reset_counter(self):
        """Reset only the patience counter and early_stop flag.
        
        Keeps best_score intact. Useful after manual interventions.
        """
        self.counter = 0
        self.early_stop = False

    def __call__(self, loss, model, epoch = None, optimizer = None, corresponding_loss = None):
        """Update early stopping state based on current validation loss.
        
        Checks if loss has improved according to threshold criteria. Saves checkpoint
        if improvement occurred, otherwise increments patience counter. Sets early_stop
        flag when counter reaches patience.
        
        Args:
            loss: Current validation loss.
            model: PyTorch model with save() method.
            epoch: Current epoch number (for logging). Optional.
            optimizer: PyTorch optimizer to save state. Optional.
            corresponding_loss: Training loss from same epoch (for tracking). Optional.
        
        Side Effects:
            - Updates counter, best_score, and corresponding_score
            - Saves model checkpoint when loss improves
            - Sets early_stop flag when patience exceeded
            - Handles NaN loss by setting to infinity
        """
        # if loss is not a number
        if np.isnan(loss):
            loss = np.inf
            logging.warning('EarlyStopping: loss is NaN. Setting to Inf for early stopping update.')
        score = loss
        
        # initial case
        if self.best_score is None:
            self.best_score = score
            self.corresponding_score = corresponding_loss
            self.save_checkpoint(loss, model, optimizer, epoch)
        
        _update_flag = False
        
        if self.threshold_mode == 'abs':
            if score < self.best_score - self.threshold:
                _update_flag = True
        elif self.threshold_mode == 'rel':
            if score < self.best_score * (1 - self.threshold):
                _update_flag = True
        else:
            raise ValueError('Invalid threshold mode selected.')
        
        if _update_flag:
            self.best_score = score
            self.counter = 0
            self.corresponding_score = corresponding_loss
            self.save_checkpoint(loss, model, optimizer, epoch)
        else:
            self.counter += 1
        if self.counter >= self.patience:
                self.early_stop = True

    def save_checkpoint(self, loss, model, optimizer, epoch):
        """Save model checkpoint when validation loss improves.
        
        Args:
            loss: Current validation loss (for logging).
            model: PyTorch model with save() method.
            optimizer: PyTorch optimizer (state saved if not None).
            epoch: Current epoch number (for logging).
        
        Side Effects:
            - Calls model.save(path) to persist model state
            - Saves optimizer state_dict if optimizer provided
            - Updates score_last_save
            - Logs checkpoint save if verbose=True
        """
        if self.verbose:
            self.trace_func('----------------------> Epoch {} Validation loss decreased ({:.6f} --> {:.6f}).  Saving model to {}'.format(epoch, self.score_last_save, loss, self.path))
        model.save(self.path)
        self.score_last_save = loss
        if optimizer is not None:
                torch.save(optimizer.state_dict(), self.optimizer_path)