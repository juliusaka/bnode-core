
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="bnode-core">
      
      
        <meta name="author" content="Julius Aka">
      
      
        <link rel="canonical" href="https://github.com/juliusaka/balanced-neural-odes/bnode_core/nn/nn_utils/">
      
      
        <link rel="prev" href="../../ode/trainer_utils/test_from_mlflow/">
      
      
        <link rel="next" href="../vae/">
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>Neural Network Utils - bnode-core</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#neural-network-utils" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="bnode-core" class="md-header__button md-logo" aria-label="bnode-core" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M16 0H8C6.9 0 6 .9 6 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V6zm4 18H8V2h7v5h5zM4 4v18h16v2H4c-1.1 0-2-.9-2-2V4zm6 6v2h8v-2zm0 4v2h5v-2z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            bnode-core
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Neural Network Utils
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 0-7 7c0 2.38 1.19 4.47 3 5.74V17a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1v-2.26c1.81-1.27 3-3.36 3-5.74a7 7 0 0 0-7-7M9 21a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1H9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 1 7 7c0 2.38-1.19 4.47-3 5.74V17a1 1 0 0 1-1 1H9a1 1 0 0 1-1-1v-2.26C6.19 13.47 5 11.38 5 9a7 7 0 0 1 7-7M9 21v-1h6v1a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1m3-17a5 5 0 0 0-5 5c0 2.05 1.23 3.81 3 4.58V16h4v-2.42c1.77-.77 3-2.53 3-4.58a5 5 0 0 0-5-5"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/juliusaka/balanced-neural-odes" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../reference/" class="md-tabs__link">
          
  
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../config/" class="md-tabs__link">
          
  
  
  Config

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../LICENSE/" class="md-tabs__link">
        
  
  
    
  
  License

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="bnode-core" class="md-nav__button md-logo" aria-label="bnode-core" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M16 0H8C6.9 0 6 .9 6 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V6zm4 18H8V2h7v5h5zM4 4v18h16v2H4c-1.1 0-2-.9-2-2V4zm6 6v2h8v-2zm0 4v2h5v-2z"/></svg>

    </a>
    bnode-core
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/juliusaka/balanced-neural-odes" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Data Generation
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data Generation
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../data_generation/introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../data_generation/raw_data_generation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Raw Data Generation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../data_generation/data_preperation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data Preparation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    (B)NODE Module
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    (B)NODE Module
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/trainer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Trainer Module
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_2" >
        
          
          <label class="md-nav__link" for="__nav_2_3_2" id="__nav_2_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    BNODE
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    BNODE
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/bnode/bnode/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    BNODE Module
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/bnode/bnode_export/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    BNODE Export
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/node/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    NODE
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_4" >
        
          
          <label class="md-nav__link" for="__nav_2_3_4" id="__nav_2_3_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ODE Utilities
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    ODE Utilities
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/trainer_utils/test_from_mlflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Testing from MLflow checkpointed runs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" checked>
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Neural Networks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Neural Networks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Neural Network Utils
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Neural Network Utils
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization" class="md-nav__link">
    <span class="md-ellipsis">
      
        normalization
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="normalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries" class="md-nav__link">
    <span class="md-ellipsis">
      
        NormalizationLayerTimeSeries
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NormalizationLayerTimeSeries">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.initialize_normalization" class="md-nav__link">
    <span class="md-ellipsis">
      
        initialize_normalization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D" class="md-nav__link">
    <span class="md-ellipsis">
      
        NormalizationLayer1D
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NormalizationLayer1D">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.initialize_normalization" class="md-nav__link">
    <span class="md-ellipsis">
      
        initialize_normalization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.__repr__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __repr__
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_data
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="load_data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset" class="md-nav__link">
    <span class="md-ellipsis">
      
        TimeSeriesDataset
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TimeSeriesDataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.set_seq_len" class="md-nav__link">
    <span class="md-ellipsis">
      
        set_seq_len
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.initialize_map" class="md-nav__link">
    <span class="md-ellipsis">
      
        initialize_map
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__getitem__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __getitem__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__getitems__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __getitems__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__len__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __len__
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.load_validate_dataset_config" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_validate_dataset_config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.load_dataset_and_config" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_dataset_and_config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.make_stacked_dataset" class="md-nav__link">
    <span class="md-ellipsis">
      
        make_stacked_dataset
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.kullback_leibler" class="md-nav__link">
    <span class="md-ellipsis">
      
        kullback_leibler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="kullback_leibler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.kullback_leibler.kullback_leibler" class="md-nav__link">
    <span class="md-ellipsis">
      
        kullback_leibler
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.kullback_leibler.count_populated_dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      
        count_populated_dimensions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping" class="md-nav__link">
    <span class="md-ellipsis">
      
        early_stopping
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="early_stopping">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping" class="md-nav__link">
    <span class="md-ellipsis">
      
        EarlyStopping
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="EarlyStopping">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.reset" class="md-nav__link">
    <span class="md-ellipsis">
      
        reset
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.reset_counter" class="md-nav__link">
    <span class="md-ellipsis">
      
        reset_counter
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __call__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.save_checkpoint" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_checkpoint
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.count_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        count_parameters
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="count_parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.count_parameters.count_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        count_parameters
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      
        capacity_scheduler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="capacity_scheduler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      
        capacity_scheduler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="capacity_scheduler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.update" class="md-nav__link">
    <span class="md-ellipsis">
      
        update
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.get_capacity" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_capacity
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vae/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VAE (Variational Autoencoder)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../filepaths/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Filepaths
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../config/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Config
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Config
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../config/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../LICENSE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    License
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization" class="md-nav__link">
    <span class="md-ellipsis">
      
        normalization
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="normalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries" class="md-nav__link">
    <span class="md-ellipsis">
      
        NormalizationLayerTimeSeries
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NormalizationLayerTimeSeries">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.initialize_normalization" class="md-nav__link">
    <span class="md-ellipsis">
      
        initialize_normalization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D" class="md-nav__link">
    <span class="md-ellipsis">
      
        NormalizationLayer1D
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NormalizationLayer1D">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.initialize_normalization" class="md-nav__link">
    <span class="md-ellipsis">
      
        initialize_normalization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.__repr__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __repr__
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_data
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="load_data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset" class="md-nav__link">
    <span class="md-ellipsis">
      
        TimeSeriesDataset
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TimeSeriesDataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.set_seq_len" class="md-nav__link">
    <span class="md-ellipsis">
      
        set_seq_len
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.initialize_map" class="md-nav__link">
    <span class="md-ellipsis">
      
        initialize_map
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__getitem__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __getitem__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__getitems__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __getitems__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__len__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __len__
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.load_validate_dataset_config" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_validate_dataset_config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.load_dataset_and_config" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_dataset_and_config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.load_data.make_stacked_dataset" class="md-nav__link">
    <span class="md-ellipsis">
      
        make_stacked_dataset
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.kullback_leibler" class="md-nav__link">
    <span class="md-ellipsis">
      
        kullback_leibler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="kullback_leibler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.kullback_leibler.kullback_leibler" class="md-nav__link">
    <span class="md-ellipsis">
      
        kullback_leibler
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.kullback_leibler.count_populated_dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      
        count_populated_dimensions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping" class="md-nav__link">
    <span class="md-ellipsis">
      
        early_stopping
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="early_stopping">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping" class="md-nav__link">
    <span class="md-ellipsis">
      
        EarlyStopping
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="EarlyStopping">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.reset" class="md-nav__link">
    <span class="md-ellipsis">
      
        reset
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.reset_counter" class="md-nav__link">
    <span class="md-ellipsis">
      
        reset_counter
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __call__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.early_stopping.EarlyStopping.save_checkpoint" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_checkpoint
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.count_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        count_parameters
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="count_parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.count_parameters.count_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        count_parameters
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      
        capacity_scheduler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="capacity_scheduler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      
        capacity_scheduler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="capacity_scheduler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.update" class="md-nav__link">
    <span class="md-ellipsis">
      
        update
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.get_capacity" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_capacity
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="neural-network-utils">Neural Network Utils</h1>


<div class="doc doc-object doc-module">



<h2 id="bnode_core.nn.nn_utils.normalization" class="doc doc-heading">
            <code>bnode_core.nn.nn_utils.normalization</code>


</h2>

    <div class="doc doc-contents first">

        <p>Normalization layers for neural network inputs with time series and 1D data support.</p>
<p>This module provides PyTorch normalization layers that compute and store mean/std statistics
from data, then normalize (or denormalize) inputs during forward passes. Supports both time
series data (batch, channels, time) and 1D feature vectors (batch, features).</p>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries" class="doc doc-heading">
            <code>NormalizationLayerTimeSeries</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Normalization layer for time series data with shape (batch, channels, time).</p>
<p>Computes and stores per-channel mean and standard deviation from input data, then
normalizes future inputs to zero mean and unit variance. Can also denormalize outputs
back to original scale. Statistics are computed once during first forward pass or via
explicit initialization.</p>
<p>Expected input shape: (batch_size, n_channels, sequence_length)</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries._initialized">_initialized</span></code></td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether mean/std have been computed from data.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.std">std</span></code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Per-channel standard deviations, shape (n_channels,).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.mu">mu</span></code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Per-channel means, shape (n_channels,).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/bnode_core/nn/nn_utils/normalization.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span>
<span class="normal"><a href="#__codelineno-0-87">87</a></span>
<span class="normal"><a href="#__codelineno-0-88">88</a></span>
<span class="normal"><a href="#__codelineno-0-89">89</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="k">class</span><span class="w"> </span><span class="nc">NormalizationLayerTimeSeries</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Normalization layer for time series data with shape (batch, channels, time).</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Computes and stores per-channel mean and standard deviation from input data, then</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">    normalizes future inputs to zero mean and unit variance. Can also denormalize outputs</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    back to original scale. Statistics are computed once during first forward pass or via</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    explicit initialization.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">    Expected input shape: (batch_size, n_channels, sequence_length)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">        _initialized (bool): Whether mean/std have been computed from data.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        std (torch.Tensor): Per-channel standard deviations, shape (n_channels,).</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        mu (torch.Tensor): Per-channel means, shape (n_channels,).</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">):</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize normalization layer buffers.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">            n_channels (int): Number of channels in time series data.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_initialized&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">))</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;std&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_channels</span><span class="p">))</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_channels</span><span class="p">))</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize_normalization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute and store mean and std from input data.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">        Calculates per-channel statistics across batch and time dimensions. Adds small</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        epsilon (1e-3) to variance for numerical stability. Only runs if not already</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">        initialized.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">            x (torch.Tensor): Input data with shape (batch_size, n_channels, sequence_length).</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        Side Effects:</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">            Sets self.mu and self.std buffers if not already initialized.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>            <span class="n">variance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-3</span><span class="p">))</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">denormalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize or denormalize input time series.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        If not initialized and normalizing, automatically initializes from input data.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        Normalizes via (x - mu) / std or denormalizes via x * std + mu.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">            x (torch.Tensor): Input with shape (batch_size, n_channels, sequence_length).</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">            denormalize (bool, optional): If False, normalize input. If True, denormalize</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">                (reverse transformation). Defaults to False.</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">            torch.Tensor: Normalized or denormalized data with same shape as input.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="k">if</span> <span class="n">denormalize</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">initialize_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="c1"># add dimensions at position 0 (for number of batches) and at position 2 (for sequence length)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="c1"># expand these dimensions</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="k">if</span> <span class="n">denormalize</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">n_channels</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize normalization layer buffers.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n_channels</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of channels in time series data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/normalization.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">):</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize normalization layer buffers.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        n_channels (int): Number of channels in time series data.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_initialized&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">))</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;std&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_channels</span><span class="p">))</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_channels</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.initialize_normalization" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">initialize_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Compute and store mean and std from input data.</p>
<p>Calculates per-channel statistics across batch and time dimensions. Adds small
epsilon (1e-3) to variance for numerical stability. Only runs if not already
initialized.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input data with shape (batch_size, n_channels, sequence_length).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


<details class="side-effects" open>
  <summary>Side Effects</summary>
  <p>Sets self.mu and self.std buffers if not already initialized.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/normalization.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="k">def</span><span class="w"> </span><span class="nf">initialize_normalization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute and store mean and std from input data.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    Calculates per-channel statistics across batch and time dimensions. Adds small</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    epsilon (1e-3) to variance for numerical stability. Only runs if not already</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">    initialized.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">        x (torch.Tensor): Input data with shape (batch_size, n_channels, sequence_length).</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    Side Effects:</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        Sets self.mu and self.std buffers if not already initialized.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="n">variance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-3</span><span class="p">))</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.normalization.NormalizationLayerTimeSeries.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">denormalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Normalize or denormalize input time series.</p>
<p>If not initialized and normalizing, automatically initializes from input data.
Normalizes via (x - mu) / std or denormalizes via x * std + mu.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input with shape (batch_size, n_channels, sequence_length).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>denormalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If False, normalize input. If True, denormalize
(reverse transformation). Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: Normalized or denormalized data with same shape as input.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/normalization.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span>
<span class="normal"><a href="#__codelineno-0-87">87</a></span>
<span class="normal"><a href="#__codelineno-0-88">88</a></span>
<span class="normal"><a href="#__codelineno-0-89">89</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">denormalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Normalize or denormalize input time series.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">    If not initialized and normalizing, automatically initializes from input data.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    Normalizes via (x - mu) / std or denormalizes via x * std + mu.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        x (torch.Tensor): Input with shape (batch_size, n_channels, sequence_length).</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        denormalize (bool, optional): If False, normalize input. If True, denormalize</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">            (reverse transformation). Defaults to False.</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">        torch.Tensor: Normalized or denormalized data with same shape as input.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="k">if</span> <span class="n">denormalize</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">initialize_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="c1"># add dimensions at position 0 (for number of batches) and at position 2 (for sequence length)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="c1"># expand these dimensions</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="k">if</span> <span class="n">denormalize</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="bnode_core.nn.nn_utils.normalization.NormalizationLayer1D" class="doc doc-heading">
            <code>NormalizationLayer1D</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Normalization layer for 1D feature vectors with shape (batch, features).</p>
<p>Computes and stores per-feature mean and standard deviation, then normalizes inputs
to zero mean and unit variance. Can also denormalize outputs. Supports both 2D
(batch, features) and 3D (batch, features, time) inputs. Accepts both torch.Tensor
and numpy.ndarray for initialization.</p>
<p>Expected input shape: (batch_size, num_features) or (batch_size, num_features, sequence_length)</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.normalization.NormalizationLayer1D._initialized">_initialized</span></code></td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether mean/std have been computed.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.std">std</span></code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Per-feature standard deviations, shape (num_features,).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.mu">mu</span></code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Per-feature means, shape (num_features,).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/bnode_core/nn/nn_utils/normalization.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="k">class</span><span class="w"> </span><span class="nc">NormalizationLayer1D</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Normalization layer for 1D feature vectors with shape (batch, features).</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">    Computes and stores per-feature mean and standard deviation, then normalizes inputs</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    to zero mean and unit variance. Can also denormalize outputs. Supports both 2D</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">    (batch, features) and 3D (batch, features, time) inputs. Accepts both torch.Tensor</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">    and numpy.ndarray for initialization.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    Expected input shape: (batch_size, num_features) or (batch_size, num_features, sequence_length)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">        _initialized (bool): Whether mean/std have been computed.</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">        std (torch.Tensor): Per-feature standard deviations, shape (num_features,).</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">        mu (torch.Tensor): Per-feature means, shape (num_features,).</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize normalization layer buffers.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">            num_features (int): Number of features/channels to normalize.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_initialized&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">))</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;std&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">)))</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize_normalization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute and store mean and std from input data.</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">        Calculates per-feature statistics across batch dimension. Adds epsilon to variance</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">        for numerical stability. Supports both torch.Tensor and numpy.ndarray inputs.</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">            x (torch.Tensor or np.ndarray): Input data with shape (batch_size, num_features).</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">            eps (float, optional): Small constant added to variance for stability. Defaults to 1e-5.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">            verbose (bool, optional): If True, logs initialization info. Defaults to False.</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">            name (str, optional): Name for logging output. Defaults to None.</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">        Raises:</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">            ValueError: If x is neither torch.Tensor nor np.ndarray.</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">            RuntimeError: If normalization layer has already been initialized.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">        Side Effects:</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">            Sets self.mu and self.std buffers, logs initialization if verbose=True.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>                <span class="n">variance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span><span class="p">))</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>                <span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown type of input: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initialized normalization layer </span><span class="si">{}</span><span class="s2"> with mean </span><span class="si">{}</span><span class="s2"> and std </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">))</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;normalization layer has already been initialized&quot;</span><span class="p">)</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">denormalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize or denormalize input features.</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">        If not initialized and normalizing, automatically initializes from input. Handles</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">        both 2D (batch, features) and 3D (batch, features, time) inputs by broadcasting.</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">        Normalizes via (x - mu) / std or denormalizes via x * std + mu.</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">            x (torch.Tensor): Input with shape (batch_size, num_features) or </span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">                (batch_size, num_features, sequence_length).</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">            denormalize (bool, optional): If False, normalize input. If True, denormalize.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">                Defaults to False.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">            torch.Tensor: Normalized or denormalized data with same shape as input.</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">denormalize</span><span class="p">:</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">initialize_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="c1"># add dimension at position 0 and expand to batch_size</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>            <span class="c1"># if x is a 3D tensor, we assume it has shape (batch_size, num_features, sequence_length)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>            <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>            <span class="n">std</span> <span class="o">=</span> <span class="n">std</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>            <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">denormalize</span><span class="p">:</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>        <span class="k">return</span> <span class="n">x</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return string representation of the layer.</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">            str: String showing layer type and number of features.</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="k">return</span> <span class="s1">&#39;NormalizationLayer1D(num_features=</span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_features</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize normalization layer buffers.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>num_features</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of features/channels to normalize.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/normalization.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize normalization layer buffers.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">        num_features (int): Number of features/channels to normalize.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_initialized&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">))</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;std&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">)))</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.initialize_normalization" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">initialize_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Compute and store mean and std from input data.</p>
<p>Calculates per-feature statistics across batch dimension. Adds epsilon to variance
for numerical stability. Supports both torch.Tensor and numpy.ndarray inputs.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span> or <span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input data with shape (batch_size, num_features).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eps</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Small constant added to variance for stability. Defaults to 1e-5.</p>
              </div>
            </td>
            <td>
                  <code>1e-05</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbose</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, logs initialization info. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name for logging output. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If x is neither torch.Tensor nor np.ndarray.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="RuntimeError">RuntimeError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If normalization layer has already been initialized.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="side-effects" open>
  <summary>Side Effects</summary>
  <p>Sets self.mu and self.std buffers, logs initialization if verbose=True.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/normalization.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="k">def</span><span class="w"> </span><span class="nf">initialize_normalization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute and store mean and std from input data.</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">    Calculates per-feature statistics across batch dimension. Adds epsilon to variance</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">    for numerical stability. Supports both torch.Tensor and numpy.ndarray inputs.</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">        x (torch.Tensor or np.ndarray): Input data with shape (batch_size, num_features).</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">        eps (float, optional): Small constant added to variance for stability. Defaults to 1e-5.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">        verbose (bool, optional): If True, logs initialization info. Defaults to False.</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">        name (str, optional): Name for logging output. Defaults to None.</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">        ValueError: If x is neither torch.Tensor nor np.ndarray.</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        RuntimeError: If normalization layer has already been initialized.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">    Side Effects:</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">        Sets self.mu and self.std buffers, logs initialization if verbose=True.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>            <span class="n">variance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span><span class="p">))</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>            <span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">eps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown type of input: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initialized normalization layer </span><span class="si">{}</span><span class="s2"> with mean </span><span class="si">{}</span><span class="s2"> and std </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">))</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;normalization layer has already been initialized&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">denormalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Normalize or denormalize input features.</p>
<p>If not initialized and normalizing, automatically initializes from input. Handles
both 2D (batch, features) and 3D (batch, features, time) inputs by broadcasting.
Normalizes via (x - mu) / std or denormalizes via x * std + mu.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input with shape (batch_size, num_features) or 
(batch_size, num_features, sequence_length).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>denormalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If False, normalize input. If True, denormalize.
Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: Normalized or denormalized data with same shape as input.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/normalization.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">denormalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Normalize or denormalize input features.</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">    If not initialized and normalizing, automatically initializes from input. Handles</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">    both 2D (batch, features) and 3D (batch, features, time) inputs by broadcasting.</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">    Normalizes via (x - mu) / std or denormalizes via x * std + mu.</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">        x (torch.Tensor): Input with shape (batch_size, num_features) or </span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">            (batch_size, num_features, sequence_length).</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">        denormalize (bool, optional): If False, normalize input. If True, denormalize.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">            Defaults to False.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">        torch.Tensor: Normalized or denormalized data with same shape as input.</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">denormalize</span><span class="p">:</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">initialize_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="c1"># add dimension at position 0 and expand to batch_size</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="c1"># if x is a 3D tensor, we assume it has shape (batch_size, num_features, sequence_length)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>        <span class="n">std</span> <span class="o">=</span> <span class="n">std</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>        <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">denormalize</span><span class="p">:</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.normalization.NormalizationLayer1D.__repr__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__repr__</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Return string representation of the layer.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>str</code></td>            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>String showing layer type and number of features.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/normalization.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return string representation of the layer.</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">        str: String showing layer type and number of features.</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>    <span class="k">return</span> <span class="s1">&#39;NormalizationLayer1D(num_features=</span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="bnode_core.nn.nn_utils.load_data" class="doc doc-heading">
            <code>bnode_core.nn.nn_utils.load_data</code>


</h2>

    <div class="doc doc-contents first">

        <p>Dataset loading utilities for neural network training.</p>
<p>Provides functions to load HDF5 datasets and their configurations,
and create PyTorch-compatible dataset objects for training.</p>


<details class="attention" open>
  <summary>Attention</summary>
  <p>This documentation is generated by AI. Please be aware of possible inaccurcies.</p>
</details>









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset" class="doc doc-heading">
            <code>TimeSeriesDataset</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.utils.data.StackDataset">StackDataset</span></code></p>



        <p>Dataset for time series with sliding window sampling of variable-length subsequences.</p>
<p>Extends StackDataset to enable extracting subsequences from longer time series via a
sliding window approach. The full sequences are stored internally, but <strong>getitem</strong>
returns only a subsequence of specified length. This enables training on different
sequence lengths without reloading data, and increases effective dataset size by
treating each sliding window position as a separate sample.</p>
<p>The dataset expects dict-style data with a 'time' key, where all time series have shape
(n_samples, n_channels, n_timesteps). Non-time-series data (2D) is replicated across
all windows from the same sample.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.seq_len">seq_len</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of subsequences returned by <strong>getitem</strong>.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.mapping">mapping</span></code></td>
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of [sample_idx, start_pos, end_pos] tuples defining each
sliding window position across all samples.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset._length">_length</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of sliding windows (dataset length).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset._length_old">_length_old</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Original number of samples before windowing.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="k">class</span><span class="w"> </span><span class="nc">TimeSeriesDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">StackDataset</span><span class="p">):</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Dataset for time series with sliding window sampling of variable-length subsequences.</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">    Extends StackDataset to enable extracting subsequences from longer time series via a</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">    sliding window approach. The full sequences are stored internally, but __getitem__</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">    returns only a subsequence of specified length. This enables training on different</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">    sequence lengths without reloading data, and increases effective dataset size by</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">    treating each sliding window position as a separate sample.</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">    The dataset expects dict-style data with a &#39;time&#39; key, where all time series have shape</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">    (n_samples, n_channels, n_timesteps). Non-time-series data (2D) is replicated across</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">    all windows from the same sample.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">        seq_len (int): Length of subsequences returned by __getitem__.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        mapping (list): List of [sample_idx, start_pos, end_pos] tuples defining each</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">            sliding window position across all samples.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">        _length (int): Total number of sliding windows (dataset length).</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">        _length_old (int): Original number of samples before windowing.</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize TimeSeriesDataset with sliding window parameters.</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">            seq_len (int): Length of subsequences to extract. If larger than available</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">                time series length, will be clamped to maximum available length.</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">            *args: Positional arguments passed to parent StackDataset.</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">            **kwargs: Keyword arguments passed to parent StackDataset. Must result in</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">                a dict-style dataset with a &#39;time&#39; key.</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">        Raises:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">            AssertionError: If datasets is not a dict or lacks &#39;time&#39; key.</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="s2">&quot;can only handle dict style stacked datasets with one key-value pair time&quot;</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="k">assert</span> <span class="s1">&#39;time&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="s2">&quot;need one dataset with key time to define the map&quot;</span> 
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_length_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>        <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>            <span class="ne">Warning</span><span class="p">(</span><span class="s2">&quot;seq_len is </span><span class="si">{}</span><span class="s2">, setting to len of timeseries&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">seq_len</span><span class="p">))</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>            <span class="n">seq_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_map</span><span class="p">(</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seq_len</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Change the subsequence length and rebuild the sliding window mapping.</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a><span class="sd">            seq_len (int): New subsequence length. If None, 0, or larger than available</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a><span class="sd">                time series length, will be clamped to maximum available length.</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="k">if</span> <span class="n">seq_len</span> <span class="o">==</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">seq_len</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>            <span class="ne">Warning</span><span class="p">(</span><span class="s2">&quot;seq_len is </span><span class="si">{}</span><span class="s2">, setting to len of timeseries&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">seq_len</span><span class="p">))</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>            <span class="n">seq_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_map</span><span class="p">(</span><span class="n">seq_len</span><span class="p">)</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize_map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Create the sliding window index mapping for all samples.</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a><span class="sd">        Builds a mapping list where each entry [sample_idx, start_pos, end_pos] defines</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a><span class="sd">        a sliding window position. Windows slide by 1 timestep across each sample, then</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a><span class="sd">        continue to the next sample. This treats each window position as an independent</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a><span class="sd">        dataset item.</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a><span class="sd">            seq_len (int): Length of sliding windows. Must be at least 1.</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a><span class="sd">        Raises:</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a><span class="sd">            AssertionError: If seq_len &lt; 1.</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a><span class="sd">        Side Effects:</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">            - Sets self.mapping to list of [sample, start, end] tuples</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a><span class="sd">            - Updates self._length to total number of windows across all samples</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>        <span class="k">assert</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;seq_len must be at least 1&quot;</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>        <span class="c1"># define map</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>        <span class="n">n_batches_per_sample</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">seq_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>        <span class="n">n_batches_total</span> <span class="o">=</span> <span class="n">n_batches_per_sample</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length_old</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches_total</span><span class="p">)]</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">=</span> <span class="n">n_batches_total</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>        <span class="c1"># fill out map. mapping shall contain [n_sample, start_position, stop_position]</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>        <span class="n">k_stop</span><span class="o">=</span><span class="n">seq_len</span> <span class="c1"># stop position in sequence</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>        <span class="n">j</span><span class="o">=</span><span class="mi">0</span> <span class="c1"># sample position in datasets</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches_total</span><span class="p">):</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k_stop</span><span class="o">-</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">k_stop</span><span class="p">]</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>            <span class="k">if</span> <span class="n">k_stop</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">&gt;</span> <span class="n">n_batches_per_sample</span> <span class="o">+</span> <span class="n">seq_len</span><span class="p">:</span> <span class="c1"># if the over next sequence would be out of bounds, go to next sample (+1 more because of &gt; and not &gt;=)</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>                <span class="n">k_stop</span> <span class="o">=</span> <span class="n">seq_len</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>                <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>                <span class="n">k_stop</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>        <span class="c1">#self.mapping = torch.tensor(np.array(self.mapping), dtype=torch.int64)</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get a single sliding window sample.</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">            index (int): Index of the sliding window to retrieve.</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="sd">            dict: Dictionary with same keys as self.datasets. For 3D+ arrays (time series),</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="sd">                returns subsequence [start:end] from appropriate sample. For 2D arrays,</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a><span class="sd">                returns full array for the sample.</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>        <span class="n">i</span><span class="p">,</span> <span class="n">k_start</span><span class="p">,</span> <span class="n">k_stop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>        <span class="n">ret_val</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>            <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>                <span class="n">ret_val</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>                <span class="n">ret_val</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="n">k_start</span><span class="p">:</span><span class="n">k_stop</span><span class="p">]</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>        <span class="k">return</span> <span class="n">ret_val</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">__getitems__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get multiple sliding window samples (batch retrieval).</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">            indices (list): List of window indices to retrieve.</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">            list: List of dictionaries, one per index, each containing the requested</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a><span class="sd">                sliding window data.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">        Note:</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">            This method requires PyTorch &gt;= 2.2 for optimal batched data loading.</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>        <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>            <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>        <span class="k">return</span> <span class="n">samples</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the total number of sliding windows in the dataset.</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a><span class="sd">            int: Total number of windows across all samples.</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize TimeSeriesDataset with sliding window parameters.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>seq_len</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of subsequences to extract. If larger than available
time series length, will be clamped to maximum available length.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>*args</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Positional arguments passed to parent StackDataset.</p>
              </div>
            </td>
            <td>
                  <code>()</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments passed to parent StackDataset. Must result in
a dict-style dataset with a 'time' key.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="AssertionError">AssertionError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If datasets is not a dict or lacks 'time' key.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize TimeSeriesDataset with sliding window parameters.</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">        seq_len (int): Length of subsequences to extract. If larger than available</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">            time series length, will be clamped to maximum available length.</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">        *args: Positional arguments passed to parent StackDataset.</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">        **kwargs: Keyword arguments passed to parent StackDataset. Must result in</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">            a dict-style dataset with a &#39;time&#39; key.</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">        AssertionError: If datasets is not a dict or lacks &#39;time&#39; key.</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="s2">&quot;can only handle dict style stacked datasets with one key-value pair time&quot;</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="k">assert</span> <span class="s1">&#39;time&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="s2">&quot;need one dataset with key time to define the map&quot;</span> 
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_length_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="ne">Warning</span><span class="p">(</span><span class="s2">&quot;seq_len is </span><span class="si">{}</span><span class="s2">, setting to len of timeseries&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">seq_len</span><span class="p">))</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="n">seq_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">initialize_map</span><span class="p">(</span><span class="n">seq_len</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.set_seq_len" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">set_seq_len</span><span class="p">(</span><span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Change the subsequence length and rebuild the sliding window mapping.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>seq_len</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>New subsequence length. If None, 0, or larger than available
time series length, will be clamped to maximum available length.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="k">def</span><span class="w"> </span><span class="nf">set_seq_len</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Change the subsequence length and rebuild the sliding window mapping.</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a><span class="sd">        seq_len (int): New subsequence length. If None, 0, or larger than available</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a><span class="sd">            time series length, will be clamped to maximum available length.</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="k">if</span> <span class="n">seq_len</span> <span class="o">==</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">seq_len</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>        <span class="ne">Warning</span><span class="p">(</span><span class="s2">&quot;seq_len is </span><span class="si">{}</span><span class="s2">, setting to len of timeseries&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">seq_len</span><span class="p">))</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>        <span class="n">seq_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">initialize_map</span><span class="p">(</span><span class="n">seq_len</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.initialize_map" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">initialize_map</span><span class="p">(</span><span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Create the sliding window index mapping for all samples.</p>
<p>Builds a mapping list where each entry [sample_idx, start_pos, end_pos] defines
a sliding window position. Windows slide by 1 timestep across each sample, then
continue to the next sample. This treats each window position as an independent
dataset item.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>seq_len</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of sliding windows. Must be at least 1.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="AssertionError">AssertionError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If seq_len &lt; 1.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="side-effects" open>
  <summary>Side Effects</summary>
  <ul>
<li>Sets self.mapping to list of [sample, start, end] tuples</li>
<li>Updates self._length to total number of windows across all samples</li>
</ul>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-208" name="__codelineno-0-208"></a><span class="k">def</span><span class="w"> </span><span class="nf">initialize_map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Create the sliding window index mapping for all samples.</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a><span class="sd">    Builds a mapping list where each entry [sample_idx, start_pos, end_pos] defines</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a><span class="sd">    a sliding window position. Windows slide by 1 timestep across each sample, then</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a><span class="sd">    continue to the next sample. This treats each window position as an independent</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a><span class="sd">    dataset item.</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a><span class="sd">        seq_len (int): Length of sliding windows. Must be at least 1.</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a><span class="sd">        AssertionError: If seq_len &lt; 1.</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a><span class="sd">    Side Effects:</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">        - Sets self.mapping to list of [sample, start, end] tuples</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a><span class="sd">        - Updates self._length to total number of windows across all samples</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>    <span class="k">assert</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;seq_len must be at least 1&quot;</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>    <span class="c1"># define map</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>    <span class="n">n_batches_per_sample</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">seq_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>    <span class="n">n_batches_total</span> <span class="o">=</span> <span class="n">n_batches_per_sample</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length_old</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches_total</span><span class="p">)]</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">=</span> <span class="n">n_batches_total</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>    <span class="c1"># fill out map. mapping shall contain [n_sample, start_position, stop_position]</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>    <span class="n">k_stop</span><span class="o">=</span><span class="n">seq_len</span> <span class="c1"># stop position in sequence</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>    <span class="n">j</span><span class="o">=</span><span class="mi">0</span> <span class="c1"># sample position in datasets</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches_total</span><span class="p">):</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k_stop</span><span class="o">-</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">k_stop</span><span class="p">]</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>        <span class="k">if</span> <span class="n">k_stop</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">&gt;</span> <span class="n">n_batches_per_sample</span> <span class="o">+</span> <span class="n">seq_len</span><span class="p">:</span> <span class="c1"># if the over next sequence would be out of bounds, go to next sample (+1 more because of &gt; and not &gt;=)</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>            <span class="n">k_stop</span> <span class="o">=</span> <span class="n">seq_len</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>            <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>            <span class="n">k_stop</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__getitem__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__getitem__</span><span class="p">(</span><span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Get a single sliding window sample.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>index</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Index of the sliding window to retrieve.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary with same keys as self.datasets. For 3D+ arrays (time series),
returns subsequence [start:end] from appropriate sample. For 2D arrays,
returns full array for the sample.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-245" name="__codelineno-0-245"></a><span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a single sliding window sample.</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">        index (int): Index of the sliding window to retrieve.</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="sd">        dict: Dictionary with same keys as self.datasets. For 3D+ arrays (time series),</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="sd">            returns subsequence [start:end] from appropriate sample. For 2D arrays,</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a><span class="sd">            returns full array for the sample.</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>    <span class="n">i</span><span class="p">,</span> <span class="n">k_start</span><span class="p">,</span> <span class="n">k_stop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>    <span class="n">ret_val</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>            <span class="n">ret_val</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>            <span class="n">ret_val</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="n">k_start</span><span class="p">:</span><span class="n">k_stop</span><span class="p">]</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>    <span class="k">return</span> <span class="n">ret_val</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__getitems__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">__getitems__</span><span class="p">(</span><span class="n">indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Get multiple sliding window samples (batch retrieval).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>indices</code>
            </td>
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of window indices to retrieve.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>list</code></td>            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of dictionaries, one per index, each containing the requested
sliding window data.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <p>This method requires PyTorch &gt;= 2.2 for optimal batched data loading.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-265" name="__codelineno-0-265"></a><span class="k">def</span><span class="w"> </span><span class="nf">__getitems__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get multiple sliding window samples (batch retrieval).</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">        indices (list): List of window indices to retrieve.</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">        list: List of dictionaries, one per index, each containing the requested</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a><span class="sd">            sliding window data.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">        This method requires PyTorch &gt;= 2.2 for optimal batched data loading.</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>    <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>        <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>    <span class="k">return</span> <span class="n">samples</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.load_data.TimeSeriesDataset.__len__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__len__</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">int</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Return the total number of sliding windows in the dataset.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>int</code></td>            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of windows across all samples.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the total number of sliding windows in the dataset.</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a><span class="sd">        int: Total number of windows across all samples.</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="bnode_core.nn.nn_utils.load_data.load_validate_dataset_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_validate_dataset_config</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">base_pModelClass</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Load and validate dataset configuration from YAML file.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="pathlib.Path">Path</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to the dataset configuration YAML file.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="base_pModelClass (bnode_core.config.base_pModelClass)" href="../../config/#bnode_core.config.base_pModelClass">base_pModelClass</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Validated dataset configuration as base_pModelClass instance.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="FileNotFoundError">FileNotFoundError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If configuration file doesn't exist.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <p>Uses OmegaConf to load YAML and validates against base_pModelClass schema.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="k">def</span><span class="w"> </span><span class="nf">load_validate_dataset_config</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">base_pModelClass</span><span class="p">:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Load and validate dataset configuration from YAML file.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">        path: Path to the dataset configuration YAML file.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        Validated dataset configuration as base_pModelClass instance.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        FileNotFoundError: If configuration file doesn&#39;t exist.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        Uses OmegaConf to load YAML and validates against base_pModelClass schema.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="s1">&#39;Dataset config file not found: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Loading dataset config file: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="n">_dataset_config_dict</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="n">_dataset_config_dict</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_object</span><span class="p">(</span><span class="n">_dataset_config_dict</span><span class="p">)</span> <span class="c1"># make dict</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="n">dataset_config</span> <span class="o">=</span> <span class="n">base_pModelClass</span><span class="p">(</span><span class="o">**</span><span class="n">_dataset_config_dict</span><span class="p">)</span> <span class="c1"># validate</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Validated dataset config file: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="k">return</span> <span class="n">dataset_config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="bnode_core.nn.nn_utils.load_data.load_dataset_and_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_dataset_and_config</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">base_pModelClass</span><span class="p">]]</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Load HDF5 dataset and its configuration.</p>
<p>Loads the HDF5 dataset file and attempts to load its configuration.
If configuration file doesn't exist, returns None for config.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dataset_name</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name/identifier of the dataset.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataset_path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Explicit path to dataset file, or empty string to use default location.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Tuple">Tuple</span>[<span title="h5py.File">File</span>, <span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="base_pModelClass (bnode_core.config.base_pModelClass)" href="../../config/#bnode_core.config.base_pModelClass">base_pModelClass</a>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple of (dataset, dataset_config) where:</p>
<ul>
<li>dataset: Open h5py.File handle to HDF5 dataset.</li>
<li>dataset_config: Validated configuration (base_pModelClass) or None if not found.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <p>The returned h5py.File should be closed when done (dataset.close()).
Uses filepath_dataset_from_config to resolve actual file path.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="k">def</span><span class="w"> </span><span class="nf">load_dataset_and_config</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">base_pModelClass</span><span class="p">]]:</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Load HDF5 dataset and its configuration.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    Loads the HDF5 dataset file and attempts to load its configuration.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    If configuration file doesn&#39;t exist, returns None for config.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        dataset_name: Name/identifier of the dataset.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        dataset_path: Explicit path to dataset file, or empty string to use default location.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        Tuple of (dataset, dataset_config) where:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">            - dataset: Open h5py.File handle to HDF5 dataset.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">            - dataset_config: Validated configuration (base_pModelClass) or None if not found.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        The returned h5py.File should be closed when done (dataset.close()).</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        Uses filepath_dataset_from_config to resolve actual file path.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="n">_path</span> <span class="o">=</span> <span class="n">filepath_dataset_from_config</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_path</span><span class="p">)</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>    <span class="n">dataset</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Loaded dataset from file: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">_path</span><span class="p">))</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>    <span class="n">_path</span> <span class="o">=</span> <span class="n">filepath_dataset_config_from_name</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">)</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;No dataset config file found, using information from dataset file&#39;</span><span class="p">)</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="n">dataset_config</span> <span class="o">=</span> <span class="n">load_validate_dataset_config</span><span class="p">(</span><span class="n">_path</span><span class="p">)</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="k">return</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="bnode_core.nn.nn_utils.load_data.make_stacked_dataset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">make_stacked_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">seq_len_from_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">seq_len_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">StackDataset</span><span class="p">,</span> <span class="n">TimeSeriesDataset</span><span class="p">]</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Create a PyTorch dataset from HDF5 data with optional time series batching.</p>
<p>Loads time series data (states, derivatives, parameters, controls, outputs) from an HDF5
file and wraps it in a PyTorch StackDataset. If seq_len_batches is specified, returns a
TimeSeriesDataset that enables sliding window sampling for variable-length sequences.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dataset</code>
            </td>
            <td>
                  <code><span title="h5py.File">File</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Open HDF5 file containing time series data with groups for
different contexts (train/test/validation).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>context</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataset context to load. Must be one of: 'train', 'test', 'validation',
'common_test', or 'common_validation'.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seq_len_from_file</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If provided, truncates loaded sequences to this length
from the original file data. Defaults to None (use full sequence length).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seq_len_batches</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If provided, returns a TimeSeriesDataset that extracts
subsequences of this length via sliding window. If None, returns standard StackDataset
with full sequences. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="torch.utils.data.StackDataset">StackDataset</span>, <a class="autorefs autorefs-internal" title="TimeSeriesDataset (bnode_core.nn.nn_utils.load_data.TimeSeriesDataset)" href="#bnode_core.nn.nn_utils.load_data.TimeSeriesDataset">TimeSeriesDataset</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.utils.data.StackDataset or TimeSeriesDataset: A dataset that yields dictionaries
containing tensors for 'time', 'states', and optionally 'states_der', 'parameters',
'controls', and 'outputs'. Each tensor has shape (batch, channels, time_steps).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <ul>
<li>All None-valued arrays are automatically excluded from the returned dataset</li>
<li>Time tensor is replicated across batch dimension from single time vector</li>
<li>When seq_len_batches is used, the dataset length increases to accommodate all
  possible sliding windows across the original sequences</li>
</ul>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/load_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="k">def</span><span class="w"> </span><span class="nf">make_stacked_dataset</span><span class="p">(</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="n">dataset</span><span class="p">:</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">,</span> 
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="n">context</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="n">seq_len_from_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="n">seq_len_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">StackDataset</span><span class="p">,</span> <span class="s1">&#39;TimeSeriesDataset&#39;</span><span class="p">]:</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a PyTorch dataset from HDF5 data with optional time series batching.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">    Loads time series data (states, derivatives, parameters, controls, outputs) from an HDF5</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">    file and wraps it in a PyTorch StackDataset. If seq_len_batches is specified, returns a</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">    TimeSeriesDataset that enables sliding window sampling for variable-length sequences.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        dataset (h5py.File): Open HDF5 file containing time series data with groups for</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">            different contexts (train/test/validation).</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        context (str): Dataset context to load. Must be one of: &#39;train&#39;, &#39;test&#39;, &#39;validation&#39;,</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">            &#39;common_test&#39;, or &#39;common_validation&#39;.</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">        seq_len_from_file (int, optional): If provided, truncates loaded sequences to this length</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">            from the original file data. Defaults to None (use full sequence length).</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">        seq_len_batches (int, optional): If provided, returns a TimeSeriesDataset that extracts</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">            subsequences of this length via sliding window. If None, returns standard StackDataset</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">            with full sequences. Defaults to None.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">        torch.utils.data.StackDataset or TimeSeriesDataset: A dataset that yields dictionaries</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">            containing tensors for &#39;time&#39;, &#39;states&#39;, and optionally &#39;states_der&#39;, &#39;parameters&#39;,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">            &#39;controls&#39;, and &#39;outputs&#39;. Each tensor has shape (batch, channels, time_steps).</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">        - All None-valued arrays are automatically excluded from the returned dataset</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">        - Time tensor is replicated across batch dimension from single time vector</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">        - When seq_len_batches is used, the dataset length increases to accommodate all</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">          possible sliding windows across the original sequences</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="k">assert</span> <span class="n">context</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">,</span> <span class="s1">&#39;common_test&#39;</span><span class="p">,</span> <span class="s1">&#39;common_validation&#39;</span><span class="p">],</span> <span class="s1">&#39;context must be one of train, test, validation, common_test, common_validation&#39;</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="c1"># get tensors of dataset</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">time</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">][:]</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="n">states</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">context</span><span class="p">][</span><span class="s1">&#39;states&#39;</span><span class="p">][:]</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="n">states_der</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">context</span><span class="p">][</span><span class="s1">&#39;states_der&#39;</span><span class="p">][:]</span> <span class="k">if</span> <span class="s1">&#39;states_der&#39;</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="n">context</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="n">parameters</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">context</span><span class="p">][</span><span class="s1">&#39;parameters&#39;</span><span class="p">][:]</span> <span class="k">if</span> <span class="s1">&#39;parameters&#39;</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="n">context</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>    <span class="n">controls</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">context</span><span class="p">][</span><span class="s1">&#39;controls&#39;</span><span class="p">][:]</span> <span class="k">if</span> <span class="s1">&#39;controls&#39;</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="n">context</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">context</span><span class="p">][</span><span class="s1">&#39;outputs&#39;</span><span class="p">][:]</span> <span class="k">if</span> <span class="s1">&#39;outputs&#39;</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="n">context</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="c1"># cut data from file to seq_len</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>    <span class="k">if</span> <span class="n">seq_len_from_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="p">[:</span><span class="n">seq_len_from_file</span><span class="p">]</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>        <span class="n">states</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,:,:</span><span class="n">seq_len_from_file</span><span class="p">]</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="n">states_der</span> <span class="o">=</span> <span class="n">states_der</span><span class="p">[:,:,:</span><span class="n">seq_len_from_file</span><span class="p">]</span> <span class="k">if</span> <span class="n">states_der</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span> <span class="c1"># TODO: add finite difference calculation for states_der and cfg.dataset_prep entries to say if derivatives are included</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="n">parameters</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[:]</span> <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="n">controls</span> <span class="o">=</span> <span class="n">controls</span><span class="p">[:,:,:</span><span class="n">seq_len_from_file</span><span class="p">]</span> <span class="k">if</span> <span class="n">controls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[:,:,:</span><span class="n">seq_len_from_file</span><span class="p">]</span> <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>    <span class="c1"># define wrapper to delete nones from kwargs dict</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_delete_nones</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="k">return</span> <span class="n">kwargs</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="c1"># make torch dataset with dict as output</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="n">dataset_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">StackDataset</span> <span class="k">if</span> <span class="n">seq_len_batches</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">TimeSeriesDataset</span><span class="p">(</span><span class="n">seq_len_batches</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="n">torch_dataset</span> <span class="o">=</span> <span class="n">dataset_type</span><span class="p">(</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>        <span class="o">**</span><span class="n">_delete_nones</span><span class="p">(</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>            <span class="n">time</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>            <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>            <span class="n">states_der</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">states_der</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">states_der</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>            <span class="n">parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>            <span class="n">controls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">controls</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">controls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="p">)</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>    <span class="p">)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Created </span><span class="si">{}</span><span class="s1"> with </span><span class="si">{}</span><span class="s1"> and sequence length </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">torch_dataset</span><span class="p">),</span><span class="n">torch_dataset</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">torch_dataset</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>    <span class="k">return</span> <span class="n">torch_dataset</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="bnode_core.nn.nn_utils.kullback_leibler" class="doc doc-heading">
            <code>bnode_core.nn.nn_utils.kullback_leibler</code>


</h2>

    <div class="doc doc-contents first">

        <p>Kullback-Leibler divergence computation for VAE training.</p>
<p>Provides functions to compute KL divergence between learned latent distributions
and standard normal prior, with support for timeseries data and dimension analysis.</p>


<details class="attention" open>
  <summary>Attention</summary>
  <p>This documentation is generated by AI. Please be aware of possible inaccurcies.</p>
</details>









<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="bnode_core.nn.nn_utils.kullback_leibler.kullback_leibler" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">kullback_leibler</span><span class="p">(</span><span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">per_dimension</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">reduce</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">time_series_aggregation_mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute KL divergence KL(N(mu, exp(logvar)) || N(0, I)).</p>
<p>Calculates the Kullback-Leibler divergence between a learned normal distribution
N(mu, sigma^2) and the standard normal prior N(0, 1). Uses the analytical formula:
KL = -0.5 * sum(1 + logvar - mu^2 - exp(logvar))</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mu</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mean of learned distribution, shape (batch, latent_dim) or 
(batch, latent_dim, seq_len) for timeseries.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logvar</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Log-variance of learned distribution, same shape as mu.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>per_dimension</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, return KL divergence per latent dimension instead of
summing across dimensions. Default: False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>reduce</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, return mean over batch. If False, return per-sample values.
Default: True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>time_series_aggregation_mode</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>How to aggregate over time dimension if input is
timeseries (3D). Options: 'mean', 'max', 'sum', or None (keep time dim).
Default: 'mean'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>KL divergence tensor. Shape depends on parameters:
- per_dimension=False, reduce=True: scalar
- per_dimension=False, reduce=False: (batch,)
- per_dimension=True, reduce=True: (latent_dim,)
- per_dimension=True, reduce=False: (batch, latent_dim)</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <p>The KL divergence is always non-negative and equals zero only when the learned
distribution matches the prior exactly.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/kullback_leibler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="k">def</span><span class="w"> </span><span class="nf">kullback_leibler</span><span class="p">(</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>    <span class="n">per_dimension</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="n">reduce</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="n">time_series_aggregation_mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute KL divergence KL(N(mu, exp(logvar)) || N(0, I)).</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">    Calculates the Kullback-Leibler divergence between a learned normal distribution</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    N(mu, sigma^2) and the standard normal prior N(0, 1). Uses the analytical formula:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    KL = -0.5 * sum(1 + logvar - mu^2 - exp(logvar))</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">        mu: Mean of learned distribution, shape (batch, latent_dim) or </span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">            (batch, latent_dim, seq_len) for timeseries.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        logvar: Log-variance of learned distribution, same shape as mu.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">        per_dimension: If True, return KL divergence per latent dimension instead of</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">            summing across dimensions. Default: False.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        reduce: If True, return mean over batch. If False, return per-sample values.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">            Default: True.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">        time_series_aggregation_mode: How to aggregate over time dimension if input is</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">            timeseries (3D). Options: &#39;mean&#39;, &#39;max&#39;, &#39;sum&#39;, or None (keep time dim).</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">            Default: &#39;mean&#39;.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">        KL divergence tensor. Shape depends on parameters:</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">            - per_dimension=False, reduce=True: scalar</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">            - per_dimension=False, reduce=False: (batch,)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">            - per_dimension=True, reduce=True: (latent_dim,)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">            - per_dimension=True, reduce=False: (batch, latent_dim)</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        The KL divergence is always non-negative and equals zero only when the learned</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">        distribution matches the prior exactly.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>    <span class="n">is_timeseries</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mu</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>    <span class="n">kl</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="k">if</span> <span class="n">is_timeseries</span><span class="p">:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="k">if</span> <span class="n">time_series_aggregation_mode</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>            <span class="n">kl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">kl</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="k">elif</span> <span class="n">time_series_aggregation_mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>            <span class="n">kl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">kl</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="k">elif</span> <span class="n">time_series_aggregation_mode</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>            <span class="n">kl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">kl</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="k">elif</span> <span class="n">time_series_aggregation_mode</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>            <span class="k">pass</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>    <span class="k">if</span> <span class="n">per_dimension</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>        <span class="n">kl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">kl</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>    <span class="k">if</span> <span class="n">reduce</span><span class="p">:</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>        <span class="n">kl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">kl</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>    <span class="k">return</span> <span class="n">kl</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="bnode_core.nn.nn_utils.kullback_leibler.count_populated_dimensions" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">count_populated_dimensions</span><span class="p">(</span><span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">kl_timeseries_aggregation_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">return_idx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Count number of latent dimensions actively used by the model.</p>
<p>A dimension is considered "populated" or "active" if its KL divergence exceeds
a threshold. This helps diagnose posterior collapse (when KL  0 for all dimensions)
and track how many dimensions the model actually uses.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mu</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mean of learned distribution, shape (batch, latent_dim) or (batch, latent_dim, seq_len).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logvar</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Log-variance of learned distribution, same shape as mu.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum KL divergence for a dimension to be considered active. Default: 0.05.</p>
              </div>
            </td>
            <td>
                  <code>0.05</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>kl_timeseries_aggregation_mode</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Aggregation mode for timeseries data ('mean', 'max', 'sum').
Default: 'mean'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_idx</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, also return boolean mask of active dimensions. Default: False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple of (n_dim_populated, idx):
- n_dim_populated: Number of dimensions with KL &gt; threshold (scalar tensor).
- idx: Boolean mask of active dimensions (tensor or None if return_idx=False).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <p>Computes KL per dimension averaged over batch (per_dimension=True, reduce=True).
Uses torch.no_grad() for efficiency since this is a diagnostic metric.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/kullback_leibler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="k">def</span><span class="w"> </span><span class="nf">count_populated_dimensions</span><span class="p">(</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>    <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>    <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> 
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="n">kl_timeseries_aggregation_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span> 
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="n">return_idx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Count number of latent dimensions actively used by the model.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">    A dimension is considered &quot;populated&quot; or &quot;active&quot; if its KL divergence exceeds</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">    a threshold. This helps diagnose posterior collapse (when KL  0 for all dimensions)</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">    and track how many dimensions the model actually uses.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">        mu: Mean of learned distribution, shape (batch, latent_dim) or (batch, latent_dim, seq_len).</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">        logvar: Log-variance of learned distribution, same shape as mu.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">        threshold: Minimum KL divergence for a dimension to be considered active. Default: 0.05.</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">        kl_timeseries_aggregation_mode: Aggregation mode for timeseries data (&#39;mean&#39;, &#39;max&#39;, &#39;sum&#39;).</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">            Default: &#39;mean&#39;.</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">        return_idx: If True, also return boolean mask of active dimensions. Default: False.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        Tuple of (n_dim_populated, idx):</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">            - n_dim_populated: Number of dimensions with KL &gt; threshold (scalar tensor).</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">            - idx: Boolean mask of active dimensions (tensor or None if return_idx=False).</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        Computes KL per dimension averaged over batch (per_dimension=True, reduce=True).</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">        Uses torch.no_grad() for efficiency since this is a diagnostic metric.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="n">kl</span> <span class="o">=</span> <span class="n">kullback_leibler</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">,</span> <span class="n">per_dimension</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">reduce</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">time_series_aggregation_mode</span> <span class="o">=</span> <span class="n">kl_timeseries_aggregation_mode</span><span class="p">)</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="c1"># print histogram of kl divergence to terminal</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="c1"># print(&#39;kl divergence histogram: 0.0 - 2.0&#39;)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="c1"># print(torch.histc(kl, bins=21, min=0, max=2.0))</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="n">idx</span> <span class="o">=</span> <span class="n">kl</span> <span class="o">&gt;</span> <span class="n">threshold</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="n">n_dim_populated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="k">if</span> <span class="n">return_idx</span><span class="p">:</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="k">return</span> <span class="n">n_dim_populated</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">idx</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="k">return</span> <span class="n">n_dim_populated</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="bnode_core.nn.nn_utils.early_stopping" class="doc doc-heading">
            <code>bnode_core.nn.nn_utils.early_stopping</code>


</h2>

    <div class="doc doc-contents first">

        <p>Early stopping utility for PyTorch model training.</p>
<p>Monitors validation loss and stops training when no improvement is observed
for a specified number of epochs (patience). Saves best model checkpoint.</p>


<details class="attention" open>
  <summary>Attention</summary>
  <p>This documentation is generated by AI. Please be aware of possible inaccurcies.</p>
</details>









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="bnode_core.nn.nn_utils.early_stopping.EarlyStopping" class="doc doc-heading">
            <code>EarlyStopping</code>


</h3>


    <div class="doc doc-contents ">



        <p>Stop training early if validation loss doesn't improve after given patience.</p>
<p>Tracks validation loss and saves model checkpoints when improvements occur.
Triggers early stopping flag when loss plateaus for 'patience' epochs.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.patience">patience</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs to wait before stopping after loss plateau.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.verbose">verbose</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, print messages for each loss improvement.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.counter">counter</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs since last loss improvement.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.best_score">best_score</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Best validation loss seen so far.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.corresponding_score">corresponding_score</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Training loss corresponding to best validation loss.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.early_stop">early_stop</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag indicating whether to stop training.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.score_last_save">score_last_save</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Validation loss at last checkpoint save.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.threshold">threshold</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum loss improvement to qualify as improvement.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.threshold_mode">threshold_mode</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either 'abs' (absolute) or 'rel' (relative) threshold.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.path">path</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>File path for saving model checkpoint.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.optimizer_path">optimizer_path</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>File path for saving optimizer state.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/bnode_core/nn/nn_utils/early_stopping.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="k">class</span><span class="w"> </span><span class="nc">EarlyStopping</span><span class="p">:</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Stop training early if validation loss doesn&#39;t improve after given patience.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">    Tracks validation loss and saves model checkpoints when improvements occur.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">    Triggers early stopping flag when loss plateaus for &#39;patience&#39; epochs.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        patience: Number of epochs to wait before stopping after loss plateau.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        verbose: If True, print messages for each loss improvement.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">        counter: Number of epochs since last loss improvement.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">        best_score: Best validation loss seen so far.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        corresponding_score: Training loss corresponding to best validation loss.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">        early_stop: Flag indicating whether to stop training.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        score_last_save: Validation loss at last checkpoint save.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        threshold: Minimum loss improvement to qualify as improvement.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        threshold_mode: Either &#39;abs&#39; (absolute) or &#39;rel&#39; (relative) threshold.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">        path: File path for saving model checkpoint.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">        optimizer_path: File path for saving optimizer state.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>        <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span> 
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> 
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="n">threshold_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;abs&#39;</span><span class="p">,</span> 
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;checkpoint.pt&#39;</span><span class="p">,</span> 
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="n">optimizer_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;optimizer.pt&#39;</span><span class="p">,</span> 
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>        <span class="n">trace_func</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="nb">print</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>    <span class="p">):</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize early stopping monitor.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">            patience: Number of epochs to wait after last validation loss improvement</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">                before triggering early stop. Default: 7.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">            verbose: If True, prints message for each validation loss improvement. Default: False.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">            threshold: Minimum change in monitored loss to qualify as improvement. Default: 0.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">            threshold_mode: Either &#39;abs&#39; (absolute: loss &lt; best - threshold) or </span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">                &#39;rel&#39; (relative: loss &lt; best * (1 - threshold)). Default: &#39;abs&#39;.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">            path: Path to save best model checkpoint. Default: &#39;checkpoint.pt&#39;.</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">            optimizer_path: Path to save optimizer state. Default: &#39;optimizer.pt&#39;.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">            trace_func: Logging function for status messages. Default: print.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">score_last_save</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">=</span> <span class="n">threshold_mode</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_path</span> <span class="o">=</span> <span class="n">optimizer_path</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span> <span class="o">=</span> <span class="n">trace_func</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;EarlyStopping initialized with patience = </span><span class="si">{}</span><span class="s1">, threshold = </span><span class="si">{}</span><span class="s1">, threshold_mode = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span><span class="p">))</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset all early stopping state to initial values.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">        Useful for starting a new training phase with fresh early stopping.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reset_counter</span><span class="p">()</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">score_last_save</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset_counter</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset only the patience counter and early_stop flag.</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">        Keeps best_score intact. Useful after manual interventions.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>        <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>        <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> 
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="n">epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="n">corresponding_loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="p">):</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Update early stopping state based on current validation loss.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">        Checks if loss has improved according to threshold criteria. Saves checkpoint</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">        if improvement occurred, otherwise increments patience counter. Sets early_stop</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">        flag when counter reaches patience.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">            loss: Current validation loss.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">            model: PyTorch model with save() method.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">            epoch: Current epoch number (for logging). Optional.</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">            optimizer: PyTorch optimizer to save state. Optional.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">            corresponding_loss: Training loss from same epoch (for tracking). Optional.</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">        Side Effects:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">            - Updates counter, best_score, and corresponding_score</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">            - Saves model checkpoint when loss improves</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">            - Sets early_stop flag when patience exceeded</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">            - Handles NaN loss by setting to infinity</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="c1"># if loss is not a number</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;EarlyStopping: loss is NaN. Setting to Inf for early stopping update.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>        <span class="n">score</span> <span class="o">=</span> <span class="n">loss</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="c1"># initial case</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="n">corresponding_loss</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">==</span> <span class="s1">&#39;abs&#39;</span><span class="p">:</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>            <span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>                <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">==</span> <span class="s1">&#39;rel&#39;</span><span class="p">:</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>            <span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">):</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>                <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid threshold mode selected.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="k">if</span> <span class="n">_update_flag</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="n">corresponding_loss</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_checkpoint</span><span class="p">(</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> 
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">],</span> 
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>        <span class="n">epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>    <span class="p">):</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Save model checkpoint when validation loss improves.</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">            loss: Current validation loss (for logging).</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">            model: PyTorch model with save() method.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">            optimizer: PyTorch optimizer (state saved if not None).</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">            epoch: Current epoch number (for logging).</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">        Side Effects:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">            - Calls model.save(path) to persist model state</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">            - Saves optimizer state_dict if optimizer provided</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">            - Updates score_last_save</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">            - Logs checkpoint save if verbose=True</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;----------------------&gt; Epoch </span><span class="si">{}</span><span class="s1"> Validation loss decreased (</span><span class="si">{:.6f}</span><span class="s1"> --&gt; </span><span class="si">{:.6f}</span><span class="s1">).  Saving model to </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">score_last_save</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">))</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">score_last_save</span> <span class="o">=</span> <span class="n">loss</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">threshold_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;abs&#39;</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;checkpoint.pt&#39;</span><span class="p">,</span> <span class="n">optimizer_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;optimizer.pt&#39;</span><span class="p">,</span> <span class="n">trace_func</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="nb">print</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize early stopping monitor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>patience</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs to wait after last validation loss improvement
before triggering early stop. Default: 7.</p>
              </div>
            </td>
            <td>
                  <code>7</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbose</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, prints message for each validation loss improvement. Default: False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum change in monitored loss to qualify as improvement. Default: 0.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold_mode</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either 'abs' (absolute: loss &lt; best - threshold) or 
'rel' (relative: loss &lt; best * (1 - threshold)). Default: 'abs'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;abs&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to save best model checkpoint. Default: 'checkpoint.pt'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;checkpoint.pt&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>optimizer_path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to save optimizer state. Default: 'optimizer.pt'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;optimizer.pt&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>trace_func</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Logging function for status messages. Default: print.</p>
              </div>
            </td>
            <td>
                  <code><span title="print">print</span></code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/early_stopping.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span> 
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> 
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="n">threshold_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;abs&#39;</span><span class="p">,</span> 
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="n">path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;checkpoint.pt&#39;</span><span class="p">,</span> 
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="n">optimizer_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;optimizer.pt&#39;</span><span class="p">,</span> 
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">trace_func</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="nb">print</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="p">):</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize early stopping monitor.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        patience: Number of epochs to wait after last validation loss improvement</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">            before triggering early stop. Default: 7.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        verbose: If True, prints message for each validation loss improvement. Default: False.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        threshold: Minimum change in monitored loss to qualify as improvement. Default: 0.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        threshold_mode: Either &#39;abs&#39; (absolute: loss &lt; best - threshold) or </span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">            &#39;rel&#39; (relative: loss &lt; best * (1 - threshold)). Default: &#39;abs&#39;.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        path: Path to save best model checkpoint. Default: &#39;checkpoint.pt&#39;.</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        optimizer_path: Path to save optimizer state. Default: &#39;optimizer.pt&#39;.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        trace_func: Logging function for status messages. Default: print.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">score_last_save</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">=</span> <span class="n">threshold_mode</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_path</span> <span class="o">=</span> <span class="n">optimizer_path</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span> <span class="o">=</span> <span class="n">trace_func</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;EarlyStopping initialized with patience = </span><span class="si">{}</span><span class="s1">, threshold = </span><span class="si">{}</span><span class="s1">, threshold_mode = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.reset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Reset all early stopping state to initial values.</p>
<p>Useful for starting a new training phase with fresh early stopping.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/early_stopping.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Reset all early stopping state to initial values.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">    Useful for starting a new training phase with fresh early stopping.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">reset_counter</span><span class="p">()</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">score_last_save</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.reset_counter" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset_counter</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Reset only the patience counter and early_stop flag.</p>
<p>Keeps best_score intact. Useful after manual interventions.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/early_stopping.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-87">87</a></span>
<span class="normal"><a href="#__codelineno-0-88">88</a></span>
<span class="normal"><a href="#__codelineno-0-89">89</a></span>
<span class="normal"><a href="#__codelineno-0-90">90</a></span>
<span class="normal"><a href="#__codelineno-0-91">91</a></span>
<span class="normal"><a href="#__codelineno-0-92">92</a></span>
<span class="normal"><a href="#__codelineno-0-93">93</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="k">def</span><span class="w"> </span><span class="nf">reset_counter</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Reset only the patience counter and early_stop flag.</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">    Keeps best_score intact. Useful after manual interventions.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">corresponding_loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Update early stopping state based on current validation loss.</p>
<p>Checks if loss has improved according to threshold criteria. Saves checkpoint
if improvement occurred, otherwise increments patience counter. Sets early_stop
flag when counter reaches patience.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>loss</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current validation loss.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>PyTorch model with save() method.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current epoch number (for logging). Optional.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>optimizer</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.optim.Optimizer">Optimizer</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>PyTorch optimizer to save state. Optional.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>corresponding_loss</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Training loss from same epoch (for tracking). Optional.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="side-effects" open>
  <summary>Side Effects</summary>
  <ul>
<li>Updates counter, best_score, and corresponding_score</li>
<li>Saves model checkpoint when loss improves</li>
<li>Sets early_stop flag when patience exceeded</li>
<li>Handles NaN loss by setting to infinity</li>
</ul>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/early_stopping.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> 
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="n">epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="n">corresponding_loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="p">):</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Update early stopping state based on current validation loss.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">    Checks if loss has improved according to threshold criteria. Saves checkpoint</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">    if improvement occurred, otherwise increments patience counter. Sets early_stop</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">    flag when counter reaches patience.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">        loss: Current validation loss.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">        model: PyTorch model with save() method.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">        epoch: Current epoch number (for logging). Optional.</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">        optimizer: PyTorch optimizer to save state. Optional.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">        corresponding_loss: Training loss from same epoch (for tracking). Optional.</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">    Side Effects:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">        - Updates counter, best_score, and corresponding_score</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">        - Saves model checkpoint when loss improves</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">        - Sets early_stop flag when patience exceeded</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">        - Handles NaN loss by setting to infinity</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="c1"># if loss is not a number</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;EarlyStopping: loss is NaN. Setting to Inf for early stopping update.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>    <span class="n">score</span> <span class="o">=</span> <span class="n">loss</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>    <span class="c1"># initial case</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="n">corresponding_loss</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>    <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">==</span> <span class="s1">&#39;abs&#39;</span><span class="p">:</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>            <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">==</span> <span class="s1">&#39;rel&#39;</span><span class="p">:</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>        <span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">):</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>            <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid threshold mode selected.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>    <span class="k">if</span> <span class="n">_update_flag</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="n">corresponding_loss</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.early_stopping.EarlyStopping.save_checkpoint" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">],</span> <span class="n">epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Save model checkpoint when validation loss improves.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>loss</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current validation loss (for logging).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>PyTorch model with save() method.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>optimizer</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.optim.Optimizer">Optimizer</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>PyTorch optimizer (state saved if not None).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current epoch number (for logging).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


<details class="side-effects" open>
  <summary>Side Effects</summary>
  <ul>
<li>Calls model.save(path) to persist model state</li>
<li>Saves optimizer state_dict if optimizer provided</li>
<li>Updates score_last_save</li>
<li>Logs checkpoint save if verbose=True</li>
</ul>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/early_stopping.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="k">def</span><span class="w"> </span><span class="nf">save_checkpoint</span><span class="p">(</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>    <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> 
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">],</span> 
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="n">epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="p">):</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Save model checkpoint when validation loss improves.</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">        loss: Current validation loss (for logging).</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">        model: PyTorch model with save() method.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        optimizer: PyTorch optimizer (state saved if not None).</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">        epoch: Current epoch number (for logging).</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    Side Effects:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">        - Calls model.save(path) to persist model state</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">        - Saves optimizer state_dict if optimizer provided</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">        - Updates score_last_save</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">        - Logs checkpoint save if verbose=True</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;----------------------&gt; Epoch </span><span class="si">{}</span><span class="s1"> Validation loss decreased (</span><span class="si">{:.6f}</span><span class="s1"> --&gt; </span><span class="si">{:.6f}</span><span class="s1">).  Saving model to </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">score_last_save</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">))</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">score_last_save</span> <span class="o">=</span> <span class="n">loss</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="bnode_core.nn.nn_utils.count_parameters" class="doc doc-heading">
            <code>bnode_core.nn.nn_utils.count_parameters</code>


</h2>

    <div class="doc doc-contents first">

        <p>Utility for counting trainable parameters in PyTorch models.</p>










<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="bnode_core.nn.nn_utils.count_parameters.count_parameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Count total number of trainable parameters in a model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>PyTorch model (nn.Module).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of trainable parameters (int).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>model = VAE(...)
num_params = count_parameters(model)
print(f"Model has {num_params:,} trainable parameters")</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/count_parameters.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="k">def</span><span class="w"> </span><span class="nf">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Count total number of trainable parameters in a model.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">        model: PyTorch model (nn.Module).</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        Total number of trainable parameters (int).</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">        &gt;&gt;&gt; model = VAE(...)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">        &gt;&gt;&gt; num_params = count_parameters(model)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">        &gt;&gt;&gt; print(f&quot;Model has {num_params:,} trainable parameters&quot;)</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="bnode_core.nn.nn_utils.capacity_scheduler" class="doc doc-heading">
            <code>bnode_core.nn.nn_utils.capacity_scheduler</code>


</h2>

    <div class="doc doc-contents first">

        <p>Capacity scheduler for VAE training with controlled KL divergence growth.</p>
<p>This module implements a scheduler that gradually increases the KL divergence capacity
during VAE training to prevent posterior collapse while maintaining good reconstruction quality.</p>


<details class="attention" open>
  <summary>Attention</summary>
  <p>This documentation is generated by AI. Please be aware of possible inaccurcies.</p>
</details>









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler" class="doc doc-heading">
            <code>capacity_scheduler</code>


</h3>


    <div class="doc doc-contents ">



        <p>Schedule the KL divergence capacity for VAE bottleneck layer.</p>
<p>Gradually increases the target KL divergence (capacity) to allow the model to
learn meaningful latent representations without posterior collapse. The capacity
increases when validation loss plateaus, encouraging the model to use more of
the latent space.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.patience">patience</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs to wait before increasing capacity after loss plateau.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.capacity">capacity</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current KL divergence capacity target.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.capacity_max">capacity_max</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum capacity value (stops increasing after reaching this).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.capacity_increment">capacity_increment</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Amount to increase capacity by (absolute or relative).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.capacity_increment_mode">capacity_increment_mode</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either 'abs' (add increment) or 'rel' (multiply by increment).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.counter">counter</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs since last loss improvement.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.best_score">best_score</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Best validation loss seen so far.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.threshold">threshold</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum loss improvement to reset counter.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.threshold_mode">threshold_mode</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either 'abs' (absolute threshold) or 'rel' (relative threshold).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.enabled">enabled</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If False, scheduler is disabled and returns None for capacity.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.reached_max_capacity">reached_max_capacity</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>True if capacity has reached capacity_max.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/bnode_core/nn/nn_utils/capacity_scheduler.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-0-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-0-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="k">class</span><span class="w"> </span><span class="nc">capacity_scheduler</span><span class="p">:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Schedule the KL divergence capacity for VAE bottleneck layer.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    Gradually increases the target KL divergence (capacity) to allow the model to</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    learn meaningful latent representations without posterior collapse. The capacity</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">    increases when validation loss plateaus, encouraging the model to use more of</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">    the latent space.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">        patience: Number of epochs to wait before increasing capacity after loss plateau.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        capacity: Current KL divergence capacity target.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        capacity_max: Maximum capacity value (stops increasing after reaching this).</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">        capacity_increment: Amount to increase capacity by (absolute or relative).</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">        capacity_increment_mode: Either &#39;abs&#39; (add increment) or &#39;rel&#39; (multiply by increment).</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        counter: Number of epochs since last loss improvement.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">        best_score: Best validation loss seen so far.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        threshold: Minimum loss improvement to reset counter.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        threshold_mode: Either &#39;abs&#39; (absolute threshold) or &#39;rel&#39; (relative threshold).</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        enabled: If False, scheduler is disabled and returns None for capacity.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">        reached_max_capacity: True if capacity has reached capacity_max.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>        <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>        <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="n">capacity_start</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>        <span class="n">capacity_max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="n">capacity_increment</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="n">capacity_increment_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="n">threshold_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>        <span class="n">trace_func</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">,</span> 
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="n">enabled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>    <span class="p">):</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the capacity scheduler.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">            patience: Number of epochs to wait after last validation loss improvement</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">                before increasing capacity.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">            capacity_start: Initial KL divergence capacity target.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">            capacity_max: Maximum capacity value (caps further increases).</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">            capacity_increment: Amount to change capacity when triggered.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">            capacity_increment_mode: Either &#39;abs&#39; (additive: capacity += increment) or </span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">                &#39;rel&#39; (multiplicative: capacity *= increment).</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">            threshold: Minimum change in validation loss to qualify as improvement.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">            threshold_mode: Either &#39;abs&#39; (absolute: loss &lt; best - threshold) or </span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">                &#39;rel&#39; (relative: loss &lt; best * (1 - threshold)).</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">            trace_func: Logging function for status messages (default: logging.info).</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">            enabled: If False, scheduler is disabled and get_capacity() returns None.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        Raises:</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">            AssertionError: If capacity_increment_mode or threshold_mode are invalid.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">=</span> <span class="n">capacity_start</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">capacity_max</span> <span class="o">=</span> <span class="n">capacity_max</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment</span> <span class="o">=</span> <span class="n">capacity_increment</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="k">assert</span> <span class="n">capacity_increment_mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;abs&#39;</span><span class="p">,</span> <span class="s1">&#39;rel&#39;</span><span class="p">],</span> <span class="s1">&#39;Invalid capacity increment mode selected.&#39;</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment_mode</span> <span class="o">=</span> <span class="n">capacity_increment_mode</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">=</span> <span class="n">threshold_mode</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="k">assert</span> <span class="n">threshold_mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;abs&#39;</span><span class="p">,</span> <span class="s1">&#39;rel&#39;</span><span class="p">],</span> <span class="s1">&#39;Invalid threshold mode selected.&#39;</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span> <span class="o">=</span> <span class="n">trace_func</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="n">enabled</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reached_max_capacity</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;CapacityScheduler initialized with patience = </span><span class="si">{}</span><span class="s1">, capacity = </span><span class="si">{}</span><span class="s1">, capacity_increment = </span><span class="si">{}</span><span class="s1">, capacity_increment_mode = </span><span class="si">{}</span><span class="s1">, threshold = </span><span class="si">{}</span><span class="s1">, threshold_mode = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment_mode</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span><span class="p">))</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span><span class="p">:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;CapacityScheduler disabled.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Update scheduler state based on current validation loss.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        Tracks validation loss improvements and increases capacity when loss</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">        plateaus for &#39;patience&#39; epochs. Capacity increases until reaching</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        capacity_max.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">            score: Current validation loss (typically MSE loss).</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">        Side Effects:</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">            - Updates counter and best_score</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">            - Increases capacity if patience threshold reached</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">            - Sets reached_max_capacity flag when maximum is hit</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">            - Logs capacity changes via trace_func</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reached_max_capacity</span><span class="p">:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>            <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">==</span> <span class="s1">&#39;abs&#39;</span><span class="p">:</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>                <span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>                    <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">==</span> <span class="s1">&#39;rel&#39;</span><span class="p">:</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>                <span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">):</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>                    <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>            <span class="k">if</span> <span class="n">_update_flag</span><span class="p">:</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reached_max_capacity</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>                    <span class="c1"># update capacity</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment_mode</span> <span class="o">==</span> <span class="s1">&#39;abs&#39;</span><span class="p">:</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>                        <span class="n">new_capacity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment_mode</span> <span class="o">==</span> <span class="s1">&#39;rel&#39;</span><span class="p">:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>                        <span class="n">new_capacity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>                    <span class="k">if</span> <span class="n">new_capacity</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_max</span><span class="p">:</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>                        <span class="n">new_capacity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_max</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">reached_max_capacity</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">CapacityScheduler reached maximum capacity of </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">capacity_max</span><span class="p">))</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">=</span> <span class="n">new_capacity</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">CapacityScheduler updated capacity to </span><span class="si">{}</span><span class="s1"> after </span><span class="si">{}</span><span class="s1"> epochs.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">capacity</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="p">))</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_capacity</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get current capacity target for KL divergence loss.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">            Current capacity value (float) if enabled, None if disabled.</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span> <span class="k">else</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">patience</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">capacity_start</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">capacity_max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">capacity_increment</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">capacity_increment_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">threshold_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">trace_func</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">,</span> <span class="n">enabled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize the capacity scheduler.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>patience</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs to wait after last validation loss improvement
before increasing capacity.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>capacity_start</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial KL divergence capacity target.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>capacity_max</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum capacity value (caps further increases).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>capacity_increment</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Amount to change capacity when triggered.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>capacity_increment_mode</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either 'abs' (additive: capacity += increment) or 
'rel' (multiplicative: capacity *= increment).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum change in validation loss to qualify as improvement.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold_mode</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either 'abs' (absolute: loss &lt; best - threshold) or 
'rel' (relative: loss &lt; best * (1 - threshold)).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>trace_func</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Logging function for status messages (default: logging.info).</p>
              </div>
            </td>
            <td>
                  <code><span title="logging.info">info</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enabled</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If False, scheduler is disabled and get_capacity() returns None.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="AssertionError">AssertionError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If capacity_increment_mode or threshold_mode are invalid.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/capacity_scheduler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span>
<span class="normal"><a href="#__codelineno-0-87">87</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="n">capacity_start</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="n">capacity_max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="n">capacity_increment</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="n">capacity_increment_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="n">threshold_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">trace_func</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">,</span> 
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>    <span class="n">enabled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="p">):</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the capacity scheduler.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">        patience: Number of epochs to wait after last validation loss improvement</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">            before increasing capacity.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        capacity_start: Initial KL divergence capacity target.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        capacity_max: Maximum capacity value (caps further increases).</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        capacity_increment: Amount to change capacity when triggered.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        capacity_increment_mode: Either &#39;abs&#39; (additive: capacity += increment) or </span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">            &#39;rel&#39; (multiplicative: capacity *= increment).</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        threshold: Minimum change in validation loss to qualify as improvement.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        threshold_mode: Either &#39;abs&#39; (absolute: loss &lt; best - threshold) or </span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">            &#39;rel&#39; (relative: loss &lt; best * (1 - threshold)).</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        trace_func: Logging function for status messages (default: logging.info).</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        enabled: If False, scheduler is disabled and get_capacity() returns None.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        AssertionError: If capacity_increment_mode or threshold_mode are invalid.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">=</span> <span class="n">capacity_start</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">capacity_max</span> <span class="o">=</span> <span class="n">capacity_max</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment</span> <span class="o">=</span> <span class="n">capacity_increment</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>    <span class="k">assert</span> <span class="n">capacity_increment_mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;abs&#39;</span><span class="p">,</span> <span class="s1">&#39;rel&#39;</span><span class="p">],</span> <span class="s1">&#39;Invalid capacity increment mode selected.&#39;</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment_mode</span> <span class="o">=</span> <span class="n">capacity_increment_mode</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">corresponding_score</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">=</span> <span class="n">threshold_mode</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="k">assert</span> <span class="n">threshold_mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;abs&#39;</span><span class="p">,</span> <span class="s1">&#39;rel&#39;</span><span class="p">],</span> <span class="s1">&#39;Invalid threshold mode selected.&#39;</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span> <span class="o">=</span> <span class="n">trace_func</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="n">enabled</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">reached_max_capacity</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;CapacityScheduler initialized with patience = </span><span class="si">{}</span><span class="s1">, capacity = </span><span class="si">{}</span><span class="s1">, capacity_increment = </span><span class="si">{}</span><span class="s1">, capacity_increment_mode = </span><span class="si">{}</span><span class="s1">, threshold = </span><span class="si">{}</span><span class="s1">, threshold_mode = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment_mode</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span><span class="p">))</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span><span class="p">:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;CapacityScheduler disabled.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.update" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update</span><span class="p">(</span><span class="n">score</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Update scheduler state based on current validation loss.</p>
<p>Tracks validation loss improvements and increases capacity when loss
plateaus for 'patience' epochs. Capacity increases until reaching
capacity_max.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>score</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current validation loss (typically MSE loss).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


<details class="side-effects" open>
  <summary>Side Effects</summary>
  <ul>
<li>Updates counter and best_score</li>
<li>Increases capacity if patience threshold reached</li>
<li>Sets reached_max_capacity flag when maximum is hit</li>
<li>Logs capacity changes via trace_func</li>
</ul>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/capacity_scheduler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Update scheduler state based on current validation loss.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">    Tracks validation loss improvements and increases capacity when loss</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">    plateaus for &#39;patience&#39; epochs. Capacity increases until reaching</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">    capacity_max.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        score: Current validation loss (typically MSE loss).</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    Side Effects:</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        - Updates counter and best_score</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        - Increases capacity if patience threshold reached</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">        - Sets reached_max_capacity flag when maximum is hit</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">        - Logs capacity changes via trace_func</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reached_max_capacity</span><span class="p">:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">==</span> <span class="s1">&#39;abs&#39;</span><span class="p">:</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>            <span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>                <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_mode</span> <span class="o">==</span> <span class="s1">&#39;rel&#39;</span><span class="p">:</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>            <span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">):</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>                <span class="n">_update_flag</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="k">if</span> <span class="n">_update_flag</span><span class="p">:</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reached_max_capacity</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>                <span class="c1"># update capacity</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment_mode</span> <span class="o">==</span> <span class="s1">&#39;abs&#39;</span><span class="p">:</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>                    <span class="n">new_capacity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment_mode</span> <span class="o">==</span> <span class="s1">&#39;rel&#39;</span><span class="p">:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>                    <span class="n">new_capacity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_increment</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>                <span class="k">if</span> <span class="n">new_capacity</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_max</span><span class="p">:</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>                    <span class="n">new_capacity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity_max</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">reached_max_capacity</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">CapacityScheduler reached maximum capacity of </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">capacity_max</span><span class="p">))</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">=</span> <span class="n">new_capacity</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">trace_func</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">CapacityScheduler updated capacity to </span><span class="si">{}</span><span class="s1"> after </span><span class="si">{}</span><span class="s1"> epochs.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">capacity</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="p">))</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.nn_utils.capacity_scheduler.capacity_scheduler.get_capacity" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_capacity</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Get current capacity target for KL divergence loss.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current capacity value (float) if enabled, None if disabled.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/nn_utils/capacity_scheduler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_capacity</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get current capacity target for KL divergence loss.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">        Current capacity value (float) if enabled, None if disabled.</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span> <span class="k">else</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/julius-aka/" target="_blank" rel="noopener" title="www.uni-augsburg.de" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M16.36 14c.08-.66.14-1.32.14-2s-.06-1.34-.14-2h3.38c.16.64.26 1.31.26 2s-.1 1.36-.26 2m-5.15 5.56c.6-1.11 1.06-2.31 1.38-3.56h2.95a8.03 8.03 0 0 1-4.33 3.56M14.34 14H9.66c-.1-.66-.16-1.32-.16-2s.06-1.35.16-2h4.68c.09.65.16 1.32.16 2s-.07 1.34-.16 2M12 19.96c-.83-1.2-1.5-2.53-1.91-3.96h3.82c-.41 1.43-1.08 2.76-1.91 3.96M8 8H5.08A7.92 7.92 0 0 1 9.4 4.44C8.8 5.55 8.35 6.75 8 8m-2.92 8H8c.35 1.25.8 2.45 1.4 3.56A8 8 0 0 1 5.08 16m-.82-2C4.1 13.36 4 12.69 4 12s.1-1.36.26-2h3.38c-.08.66-.14 1.32-.14 2s.06 1.34.14 2M12 4.03c.83 1.2 1.5 2.54 1.91 3.97h-3.82c.41-1.43 1.08-2.77 1.91-3.97M18.92 8h-2.95a15.7 15.7 0 0 0-1.38-3.56c1.84.63 3.37 1.9 4.33 3.56M12 2C6.47 2 2 6.5 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10A10 10 0 0 0 12 2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/julius-aka/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 3a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2zm-.5 15.5v-5.3a3.26 3.26 0 0 0-3.26-3.26c-.85 0-1.84.52-2.32 1.3v-1.11h-2.79v8.37h2.79v-4.93c0-.77.62-1.4 1.39-1.4a1.4 1.4 0 0 1 1.4 1.4v4.93zM6.88 8.56a1.68 1.68 0 0 0 1.68-1.68c0-.93-.75-1.69-1.68-1.69a1.69 1.69 0 0 0-1.69 1.69c0 .93.76 1.68 1.69 1.68m1.39 9.94v-8.37H5.5v8.37z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://scholar.google.com/citations?user=7SypqSQAAAAJ&hl" target="_blank" rel="noopener" title="scholar.google.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 3 1 9l11 6 9-4.91V17h2V9M5 13.18v4L12 21l7-3.82v-4L12 17z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/juliusaka" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.instant", "navigation.top", "navigation.tabs", "search.suggest", "search.highlight"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
    
  </body>
</html>