
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="bnode-core">
      
      
        <meta name="author" content="Julius Aka">
      
      
        <link rel="canonical" href="https://github.com/juliusaka/balanced-neural-odes/bnode_core/nn/vae/">
      
      
        <link rel="prev" href="../nn_utils/">
      
      
        <link rel="next" href="../../filepaths/">
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>VAE (Variational Autoencoder) - bnode-core</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#vae-variational-autoencoder" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="bnode-core" class="md-header__button md-logo" aria-label="bnode-core" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M16 0H8C6.9 0 6 .9 6 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V6zm4 18H8V2h7v5h5zM4 4v18h16v2H4c-1.1 0-2-.9-2-2V4zm6 6v2h8v-2zm0 4v2h5v-2z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            bnode-core
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              VAE (Variational Autoencoder)
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 0-7 7c0 2.38 1.19 4.47 3 5.74V17a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1v-2.26c1.81-1.27 3-3.36 3-5.74a7 7 0 0 0-7-7M9 21a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1H9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 1 7 7c0 2.38-1.19 4.47-3 5.74V17a1 1 0 0 1-1 1H9a1 1 0 0 1-1-1v-2.26C6.19 13.47 5 11.38 5 9a7 7 0 0 1 7-7M9 21v-1h6v1a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1m3-17a5 5 0 0 0-5 5c0 2.05 1.23 3.81 3 4.58V16h4v-2.42c1.77-.77 3-2.53 3-4.58a5 5 0 0 0-5-5"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/juliusaka/balanced-neural-odes" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../reference/" class="md-tabs__link">
          
  
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../config/" class="md-tabs__link">
          
  
  
  Config

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../LICENSE/" class="md-tabs__link">
        
  
  
    
  
  License

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="bnode-core" class="md-nav__button md-logo" aria-label="bnode-core" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M16 0H8C6.9 0 6 .9 6 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V6zm4 18H8V2h7v5h5zM4 4v18h16v2H4c-1.1 0-2-.9-2-2V4zm6 6v2h8v-2zm0 4v2h5v-2z"/></svg>

    </a>
    bnode-core
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/juliusaka/balanced-neural-odes" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Data Generation
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data Generation
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../data_generation/introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../data_generation/raw_data_generation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Raw Data Generation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../data_generation/data_preperation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data Preparation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    (B)NODE Module
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    (B)NODE Module
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/trainer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Trainer Module
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_2" >
        
          
          <label class="md-nav__link" for="__nav_2_3_2" id="__nav_2_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    BNODE
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    BNODE
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/bnode/bnode/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    BNODE Module
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/bnode/bnode_export/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    BNODE Export
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/node/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    NODE
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_4" >
        
          
          <label class="md-nav__link" for="__nav_2_3_4" id="__nav_2_3_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ODE Utilities
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    ODE Utilities
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ode/trainer_utils/test_from_mlflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Testing from MLflow checkpointed runs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" checked>
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Neural Networks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Neural Networks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nn_utils/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Neural Network Utils
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    VAE (Variational Autoencoder)
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    VAE (Variational Autoencoder)
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        vae_architecture
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="vae_architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Encoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        Encoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Encoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Encoder.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Encoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Decoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Decoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Decoder.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Decoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Regressor" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regressor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Regressor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Regressor.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE" class="md-nav__link">
    <span class="md-ellipsis">
      
        VAE
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VAE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.reparametrize" class="md-nav__link">
    <span class="md-ellipsis">
      
        reparametrize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.predict" class="md-nav__link">
    <span class="md-ellipsis">
      
        predict
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.save" class="md-nav__link">
    <span class="md-ellipsis">
      
        save
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.load" class="md-nav__link">
    <span class="md-ellipsis">
      
        load
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.loss_function" class="md-nav__link">
    <span class="md-ellipsis">
      
        loss_function
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test" class="md-nav__link">
    <span class="md-ellipsis">
      
        vae_train_test
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="vae_train_test">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--command-line-usage" class="md-nav__link">
    <span class="md-ellipsis">
      
        Command-line Usage
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--training-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--output-files" class="md-nav__link">
    <span class="md-ellipsis">
      
        Output Files
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--key-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Features
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test.train" class="md-nav__link">
    <span class="md-ellipsis">
      
        train
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test.main" class="md-nav__link">
    <span class="md-ellipsis">
      
        main
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../filepaths/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Filepaths
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../config/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Config
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Config
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../config/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../LICENSE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    License
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        vae_architecture
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="vae_architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Encoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        Encoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Encoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Encoder.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Encoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Decoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Decoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Decoder.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Decoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Regressor" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regressor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regressor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Regressor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.Regressor.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE" class="md-nav__link">
    <span class="md-ellipsis">
      
        VAE
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VAE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.reparametrize" class="md-nav__link">
    <span class="md-ellipsis">
      
        reparametrize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.predict" class="md-nav__link">
    <span class="md-ellipsis">
      
        predict
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.save" class="md-nav__link">
    <span class="md-ellipsis">
      
        save
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.VAE.load" class="md-nav__link">
    <span class="md-ellipsis">
      
        load
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_architecture.loss_function" class="md-nav__link">
    <span class="md-ellipsis">
      
        loss_function
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test" class="md-nav__link">
    <span class="md-ellipsis">
      
        vae_train_test
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="vae_train_test">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--command-line-usage" class="md-nav__link">
    <span class="md-ellipsis">
      
        Command-line Usage
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--training-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--output-files" class="md-nav__link">
    <span class="md-ellipsis">
      
        Output Files
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test--key-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Features
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test.train" class="md-nav__link">
    <span class="md-ellipsis">
      
        train
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnode_core.nn.vae.vae_train_test.main" class="md-nav__link">
    <span class="md-ellipsis">
      
        main
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="vae-variational-autoencoder">VAE (Variational Autoencoder)</h1>


<div class="doc doc-object doc-module">



<h2 id="bnode_core.nn.vae.vae_architecture" class="doc doc-heading">
            <code>bnode_core.nn.vae.vae_architecture</code>


</h2>

    <div class="doc doc-contents first">

        <p>Variational Autoencoder (VAE) architecture for timeseries reconstruction.</p>
<p>This module implements a Variational Autoencoder with parameter conditioning for 
timeseries data (states and outputs). The architecture supports multiple modes:</p>
<ul>
<li>Standard VAE: Encoder-Decoder with latent space</li>
<li>PELS-VAE: Parameter-conditioned VAE with Regressor for mu/logvar prediction</li>
<li>Feed-forward NN: Direct mapping from parameters to timeseries (bypasses latent space)</li>
</ul>
<p>The model can reconstruct timeseries from either the encoder (during training) or from
the regressor (during testing/prediction), enabling parameter-conditioned generation.</p>
<p>It is intedend to be used for task that model <code>physical parameters --&gt; complete timeseries</code>, e.g. the transient
response of a RC circuit with fixed initial condition on different parameter values <code>R,L,C</code>.</p>


<details class="attention" open>
  <summary>Attention</summary>
  <p>This documentation is AI generated. Be aware of possible inaccuricies.</p>
</details>        <p>Key components:</p>
<div class="highlight"><pre><span></span><code>- Encoder: Maps timeseries (states + outputs) to latent distribution (mu, logvar)
- Decoder: Maps latent samples (and optionally parameters) to reconstructed timeseries
- Regressor: Maps parameters to latent distribution for parameter-conditioned generation
- Normalization: Time-series and parameter normalization layers
</code></pre></div>
<p>Loss function:</p>
<div class="highlight"><pre><span></span><code>loss = mse_loss + beta * kl_loss + regressor_loss
or with capacity scheduling:
loss = mse_loss + gamma * |kl_loss - capacity| + regressor_loss
</code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="bnode_core.nn.vae.vae_architecture.Encoder" class="doc doc-heading">
            <code>Encoder</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Encoder network mapping timeseries to latent distribution parameters.</p>
<p>Maps concatenated states and outputs to mean (mu) and log-variance (logvar) 
of a multivariate Gaussian distribution in latent space. Uses a multi-layer 
perceptron (MLP) with configurable depth and hidden dimensions.</p>
<p>Architecture:</p>
<div class="highlight"><pre><span></span><code>Flatten -&gt; Linear(n_channels*seq_len, hidden_dim) -&gt; Activation
-&gt; [Linear(hidden_dim, hidden_dim) -&gt; Activation] x (n_layers-2)
-&gt; Linear(hidden_dim, 2*bottleneck_dim) -&gt; Reshape to [mu, logvar]
</code></pre></div>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Encoder.bottleneck_dim">bottleneck_dim</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimensionality of the latent space.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Encoder.flatten">flatten</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flattens input timeseries to 1D.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Encoder.linear">linear</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sequential MLP mapping flattened input to 2*bottleneck_dim outputs.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="k">class</span><span class="w"> </span><span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Encoder network mapping timeseries to latent distribution parameters.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    Maps concatenated states and outputs to mean (mu) and log-variance (logvar) </span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    of a multivariate Gaussian distribution in latent space. Uses a multi-layer </span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    perceptron (MLP) with configurable depth and hidden dimensions.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">    Architecture:</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        Flatten -&gt; Linear(n_channels*seq_len, hidden_dim) -&gt; Activation</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        -&gt; [Linear(hidden_dim, hidden_dim) -&gt; Activation] x (n_layers-2)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        -&gt; Linear(hidden_dim, 2*bottleneck_dim) -&gt; Reshape to [mu, logvar]</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        bottleneck_dim: Dimensionality of the latent space.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        flatten: Flattens input timeseries to 1D.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        linear: Sequential MLP mapping flattened input to 2*bottleneck_dim outputs.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>                 <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the Encoder network.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">            n_channels: Number of input channels (states + outputs concatenated).</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">            seq_len: Length of the timeseries sequence.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">            hidden_dim: Number of hidden units in intermediate layers.</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">            bottleneck_dim: Dimensionality of latent space (output is 2*bottleneck_dim for mu and logvar).</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">            activation: Activation function class (default: nn.ReLU).</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">            n_layers: Total number of linear layers (minimum 2, includes input and output layers).</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="c1"># save dimensions of output</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_dim</span> <span class="o">=</span> <span class="n">bottleneck_dim</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="c1"># construct MLP</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="n">modules</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_channels</span><span class="o">*</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>            <span class="n">activation</span><span class="p">(),</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="p">]</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="k">if</span> <span class="n">n_layers</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;n_layers must be at least 2, setting n_layers to 2&#39;</span><span class="p">)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>            <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>            <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">())</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">bottleneck_dim</span><span class="p">))</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">)</span>  
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode timeseries to latent distribution parameters.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">            x: Input timeseries tensor of shape (batch, n_channels, seq_len).</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">            Tuple of (mu, logvar) where:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">                - mu: Mean of latent distribution, shape (batch, bottleneck_dim)</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">                - logvar: Log-variance of latent distribution, shape (batch, bottleneck_dim)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="n">latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="n">latent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">latent</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_dim</span><span class="p">))</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">latent</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">latent</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.Encoder.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">n_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize the Encoder network.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n_channels</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of input channels (states + outputs concatenated).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seq_len</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of the timeseries sequence.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of hidden units in intermediate layers.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bottleneck_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimensionality of latent space (output is 2*bottleneck_dim for mu and logvar).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>activation</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Activation function class (default: nn.ReLU).</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.ReLU">ReLU</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_layers</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of linear layers (minimum 2, includes input and output layers).</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span>
<span class="normal"><a href="#__codelineno-0-87">87</a></span>
<span class="normal"><a href="#__codelineno-0-88">88</a></span>
<span class="normal"><a href="#__codelineno-0-89">89</a></span>
<span class="normal"><a href="#__codelineno-0-90">90</a></span>
<span class="normal"><a href="#__codelineno-0-91">91</a></span>
<span class="normal"><a href="#__codelineno-0-92">92</a></span>
<span class="normal"><a href="#__codelineno-0-93">93</a></span>
<span class="normal"><a href="#__codelineno-0-94">94</a></span>
<span class="normal"><a href="#__codelineno-0-95">95</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>             <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the Encoder network.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">        n_channels: Number of input channels (states + outputs concatenated).</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">        seq_len: Length of the timeseries sequence.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">        hidden_dim: Number of hidden units in intermediate layers.</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">        bottleneck_dim: Dimensionality of latent space (output is 2*bottleneck_dim for mu and logvar).</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">        activation: Activation function class (default: nn.ReLU).</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">        n_layers: Total number of linear layers (minimum 2, includes input and output layers).</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="c1"># save dimensions of output</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_dim</span> <span class="o">=</span> <span class="n">bottleneck_dim</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="c1"># construct MLP</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="n">modules</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_channels</span><span class="o">*</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="n">activation</span><span class="p">(),</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="p">]</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="k">if</span> <span class="n">n_layers</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;n_layers must be at least 2, setting n_layers to 2&#39;</span><span class="p">)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">())</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>    <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">bottleneck_dim</span><span class="p">))</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">)</span>  
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.Encoder.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Encode timeseries to latent distribution parameters.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input timeseries tensor of shape (batch, n_channels, seq_len).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Tuple">Tuple</span>[<span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple of (mu, logvar) where:</p>
<ul>
<li>mu: Mean of latent distribution, shape (batch, bottleneck_dim)</li>
<li>logvar: Log-variance of latent distribution, shape (batch, bottleneck_dim)</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Encode timeseries to latent distribution parameters.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        x: Input timeseries tensor of shape (batch, n_channels, seq_len).</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">        Tuple of (mu, logvar) where:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">            - mu: Mean of latent distribution, shape (batch, bottleneck_dim)</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">            - logvar: Log-variance of latent distribution, shape (batch, bottleneck_dim)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="n">latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="n">latent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">latent</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_dim</span><span class="p">))</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">latent</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">latent</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="bnode_core.nn.vae.vae_architecture.Decoder" class="doc doc-heading">
            <code>Decoder</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Decoder network for VAE, generating timeseries from latent vectors.</p>
<p>The decoder maps latent vectors (and optionally system parameters) back to timeseries
data. It supports three modes:</p>
<ul>
<li>Standard VAE: z_latent  timeseries</li>
<li>PELS-VAE: (z_latent, parameters)  timeseries (params_to_decoder=True)</li>
<li>Feed-forward: parameters  timeseries (bottleneck_dim=0, params_to_decoder=True)</li>
</ul>
<p>Architecture: Linear (latent+params  hidden)  MLP  Linear (hidden  n_channels*seq_len)  Reshape</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Decoder.channels">channels</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of output channels in reconstructed timeseries.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Decoder.seq_len">seq_len</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of output timeseries sequence.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Decoder.params_to_decoder">params_to_decoder</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, concatenate normalized parameters to latent vector as decoder input.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Decoder.param_normalization">param_normalization</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Normalization layer for parameters (if params_to_decoder=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Decoder.feed_forward_nn">feed_forward_nn</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, decoder operates in feed-forward mode (no latent vector).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Decoder.linear">linear</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sequential MLP mapping latent (+ params) to flattened timeseries.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="k">class</span><span class="w"> </span><span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Decoder network for VAE, generating timeseries from latent vectors.</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">    The decoder maps latent vectors (and optionally system parameters) back to timeseries</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">    data. It supports three modes:</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">    - Standard VAE: z_latent  timeseries</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">    - PELS-VAE: (z_latent, parameters)  timeseries (params_to_decoder=True)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">    - Feed-forward: parameters  timeseries (bottleneck_dim=0, params_to_decoder=True)</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">    Architecture: Linear (latent+params  hidden)  MLP  Linear (hidden  n_channels*seq_len)  Reshape</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">        channels: Number of output channels in reconstructed timeseries.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">        seq_len: Length of output timeseries sequence.</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">        params_to_decoder: If True, concatenate normalized parameters to latent vector as decoder input.</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        param_normalization: Normalization layer for parameters (if params_to_decoder=True).</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">        feed_forward_nn: If True, decoder operates in feed-forward mode (no latent vector).</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">        linear: Sequential MLP mapping latent (+ params) to flattened timeseries.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>                 <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">params_to_decoder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>                 <span class="n">param_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the Decoder network.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">            n_channels: Number of output channels in reconstructed timeseries.</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">            seq_len: Length of output timeseries sequence.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">            hidden_dim: Number of hidden units in intermediate layers.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">            bottleneck_dim: Dimensionality of latent space input (0 for feed-forward mode).</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">            activation: Activation function class (default: nn.ReLU).</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">            n_layers: Total number of linear layers (minimum 2).</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">            params_to_decoder: If True, concatenate system parameters to latent input (PELS-VAE mode).</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">            param_dim: Dimensionality of parameter vector (required if params_to_decoder=True).</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="c1"># save dimensions of output</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">n_channels</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">params_to_decoder</span> <span class="o">=</span> <span class="n">params_to_decoder</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="k">if</span> <span class="n">params_to_decoder</span><span class="p">:</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>            <span class="k">assert</span> <span class="n">param_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;param_dim must be specified if params_to_decoder is True&#39;</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">param_normalization</span> <span class="o">=</span> <span class="n">NormalizationLayer1D</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">param_dim</span><span class="p">)</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">bottleneck_dim</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">False</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span><span class="p">:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>            <span class="k">assert</span> <span class="n">params_to_decoder</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;params_to_decoder must be True if bottleneck_dim is 0&#39;</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>        <span class="c1"># construct MLP</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>        <span class="n">modules</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">bottleneck_dim</span> <span class="k">if</span> <span class="n">params_to_decoder</span> <span class="ow">is</span> <span class="kc">False</span> <span class="k">else</span> <span class="n">bottleneck_dim</span> <span class="o">+</span> <span class="n">param_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>            <span class="n">activation</span><span class="p">(),</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>        <span class="p">]</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="k">if</span> <span class="n">n_layers</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;n_layers must be at least 2, setting n_layers to 2&#39;</span><span class="p">)</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>            <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>            <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">())</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_channels</span><span class="o">*</span><span class="n">seq_len</span><span class="p">))</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">)</span>  
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_latent</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Decode latent vector (and optionally parameters) to timeseries.</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">            z_latent: Latent vector of shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">            param: System parameters of shape (batch, param_dim) (required if params_to_decoder=True).</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">            Reconstructed timeseries tensor of shape (batch, n_channels, seq_len).</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params_to_decoder</span><span class="p">:</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>            <span class="n">param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_normalization</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">z_latent</span><span class="p">,</span> <span class="n">param</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">z_latent</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">))</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.Decoder.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">n_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">params_to_decoder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">param_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize the Decoder network.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n_channels</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of output channels in reconstructed timeseries.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seq_len</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of output timeseries sequence.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of hidden units in intermediate layers.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bottleneck_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimensionality of latent space input (0 for feed-forward mode).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>activation</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Activation function class (default: nn.ReLU).</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.ReLU">ReLU</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_layers</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of linear layers (minimum 2).</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params_to_decoder</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, concatenate system parameters to latent input (PELS-VAE mode).</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>param_dim</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimensionality of parameter vector (required if params_to_decoder=True).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>             <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">params_to_decoder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>             <span class="n">param_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the Decoder network.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">        n_channels: Number of output channels in reconstructed timeseries.</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">        seq_len: Length of output timeseries sequence.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        hidden_dim: Number of hidden units in intermediate layers.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">        bottleneck_dim: Dimensionality of latent space input (0 for feed-forward mode).</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">        activation: Activation function class (default: nn.ReLU).</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">        n_layers: Total number of linear layers (minimum 2).</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">        params_to_decoder: If True, concatenate system parameters to latent input (PELS-VAE mode).</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">        param_dim: Dimensionality of parameter vector (required if params_to_decoder=True).</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>    <span class="c1"># save dimensions of output</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">n_channels</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">params_to_decoder</span> <span class="o">=</span> <span class="n">params_to_decoder</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="k">if</span> <span class="n">params_to_decoder</span><span class="p">:</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>        <span class="k">assert</span> <span class="n">param_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;param_dim must be specified if params_to_decoder is True&#39;</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">param_normalization</span> <span class="o">=</span> <span class="n">NormalizationLayer1D</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">param_dim</span><span class="p">)</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">bottleneck_dim</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">False</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span><span class="p">:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>        <span class="k">assert</span> <span class="n">params_to_decoder</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;params_to_decoder must be True if bottleneck_dim is 0&#39;</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="c1"># construct MLP</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">modules</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">bottleneck_dim</span> <span class="k">if</span> <span class="n">params_to_decoder</span> <span class="ow">is</span> <span class="kc">False</span> <span class="k">else</span> <span class="n">bottleneck_dim</span> <span class="o">+</span> <span class="n">param_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>        <span class="n">activation</span><span class="p">(),</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>    <span class="p">]</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>    <span class="k">if</span> <span class="n">n_layers</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;n_layers must be at least 2, setting n_layers to 2&#39;</span><span class="p">)</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">())</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_channels</span><span class="o">*</span><span class="n">seq_len</span><span class="p">))</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">)</span>  
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.Decoder.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">z_latent</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Decode latent vector (and optionally parameters) to timeseries.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>z_latent</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Latent vector of shape (batch, bottleneck_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>param</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>System parameters of shape (batch, param_dim) (required if params_to_decoder=True).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Reconstructed timeseries tensor of shape (batch, n_channels, seq_len).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_latent</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Decode latent vector (and optionally parameters) to timeseries.</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">        z_latent: Latent vector of shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">        param: System parameters of shape (batch, param_dim) (required if params_to_decoder=True).</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">        Reconstructed timeseries tensor of shape (batch, n_channels, seq_len).</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params_to_decoder</span><span class="p">:</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>        <span class="n">param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_normalization</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">z_latent</span><span class="p">,</span> <span class="n">param</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">z_latent</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">))</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="bnode_core.nn.vae.vae_architecture.Regressor" class="doc doc-heading">
            <code>Regressor</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Regressor network mapping system parameters to latent distribution.</p>
<p>Used in PELS-VAE mode to predict latent distribution parameters (mu, logvar) 
directly from system parameters, without requiring timeseries input. This allows
the VAE to learn relationships between system parameters and latent representations.</p>
<p>Architecture: </p>
<div class="highlight"><pre><span></span><code>Normalize params  Linear (params  hidden)  MLP  Linear (hidden  2*bottleneck_dim)  Reshape to (mu, logvar)
</code></pre></div>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Regressor.bottleneck_dim">bottleneck_dim</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimensionality of the latent space.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Regressor.normalization">normalization</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Normalization layer for input parameters.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.Regressor.linear">linear</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sequential MLP mapping parameters to 2*bottleneck_dim outputs.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="k">class</span><span class="w"> </span><span class="nc">Regressor</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Regressor network mapping system parameters to latent distribution.</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">    Used in PELS-VAE mode to predict latent distribution parameters (mu, logvar) </span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a><span class="sd">    directly from system parameters, without requiring timeseries input. This allows</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a><span class="sd">    the VAE to learn relationships between system parameters and latent representations.</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a><span class="sd">    Architecture: </span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a><span class="sd">        Normalize params  Linear (params  hidden)  MLP  Linear (hidden  2*bottleneck_dim)  Reshape to (mu, logvar)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a><span class="sd">        bottleneck_dim: Dimensionality of the latent space.</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a><span class="sd">        normalization: Normalization layer for input parameters.</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a><span class="sd">        linear: Sequential MLP mapping parameters to 2*bottleneck_dim outputs.</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>                 <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> 
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>                 <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the Regressor network.</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a><span class="sd">            parameter_dim: Dimensionality of input parameter vector.</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a><span class="sd">            hidden_dim: Number of hidden units in intermediate layers.</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a><span class="sd">            bottleneck_dim: Dimensionality of latent space (output is 2*bottleneck_dim for mu and logvar).</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a><span class="sd">            activation: Activation function class (default: nn.ReLU).</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a><span class="sd">            n_layers: Total number of linear layers (minimum 2).</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>        <span class="c1"># save dimensions of output</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_dim</span> <span class="o">=</span> <span class="n">bottleneck_dim</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">normalization</span> <span class="o">=</span> <span class="n">NormalizationLayer1D</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">)</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>        <span class="c1"># construct MLP</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>        <span class="n">modules</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">parameter_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>            <span class="n">activation</span><span class="p">(),</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>        <span class="p">]</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>        <span class="k">if</span> <span class="n">n_layers</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;n_layers must be at least 2, setting n_layers to 2&#39;</span><span class="p">)</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>            <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>            <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">())</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">bottleneck_dim</span><span class="p">))</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">)</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict latent distribution parameters from system parameters.</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">            param: System parameters of shape (batch, parameter_dim).</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="sd">            Tuple of (mu, logvar) where:</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">                - mu: Predicted mean of latent distribution, shape (batch, bottleneck_dim)</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="sd">                - logvar: Predicted log-variance of latent distribution, shape (batch, bottleneck_dim)</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>        <span class="n">param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalization</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>        <span class="n">latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>        <span class="n">latent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">latent</span><span class="p">,(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_dim</span><span class="p">))</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">latent</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">latent</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.Regressor.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">parameter_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize the Regressor network.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>parameter_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimensionality of input parameter vector.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of hidden units in intermediate layers.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bottleneck_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimensionality of latent space (output is 2*bottleneck_dim for mu and logvar).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>activation</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Activation function class (default: nn.ReLU).</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.ReLU">ReLU</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_layers</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of linear layers (minimum 2).</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-212" name="__codelineno-0-212"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>             <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> 
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>             <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the Regressor network.</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a><span class="sd">        parameter_dim: Dimensionality of input parameter vector.</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a><span class="sd">        hidden_dim: Number of hidden units in intermediate layers.</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a><span class="sd">        bottleneck_dim: Dimensionality of latent space (output is 2*bottleneck_dim for mu and logvar).</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a><span class="sd">        activation: Activation function class (default: nn.ReLU).</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a><span class="sd">        n_layers: Total number of linear layers (minimum 2).</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>    <span class="c1"># save dimensions of output</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_dim</span> <span class="o">=</span> <span class="n">bottleneck_dim</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">normalization</span> <span class="o">=</span> <span class="n">NormalizationLayer1D</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">)</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>    <span class="c1"># construct MLP</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>    <span class="n">modules</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">parameter_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>        <span class="n">activation</span><span class="p">(),</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>    <span class="p">]</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>    <span class="k">if</span> <span class="n">n_layers</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;n_layers must be at least 2, setting n_layers to 2&#39;</span><span class="p">)</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">())</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>    <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">bottleneck_dim</span><span class="p">))</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.Regressor.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">param</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Predict latent distribution parameters from system parameters.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>param</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>System parameters of shape (batch, parameter_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Tuple">Tuple</span>[<span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple of (mu, logvar) where:
- mu: Predicted mean of latent distribution, shape (batch, bottleneck_dim)
- logvar: Predicted log-variance of latent distribution, shape (batch, bottleneck_dim)</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-243" name="__codelineno-0-243"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Predict latent distribution parameters from system parameters.</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">        param: System parameters of shape (batch, parameter_dim).</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="sd">        Tuple of (mu, logvar) where:</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">            - mu: Predicted mean of latent distribution, shape (batch, bottleneck_dim)</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="sd">            - logvar: Predicted log-variance of latent distribution, shape (batch, bottleneck_dim)</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>    <span class="n">param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalization</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>    <span class="n">latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>    <span class="n">latent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">latent</span><span class="p">,(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_dim</span><span class="p">))</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>    <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">latent</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">latent</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>    <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="bnode_core.nn.vae.vae_architecture.VAE" class="doc doc-heading">
            <code>VAE</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Variational Autoencoder for timeseries modeling with parameter conditioning.</p>
<p>This class implements three operational modes:</p>
<ol>
<li><strong>Standard VAE</strong>: Encodes timeseries to latent space, decodes back to timeseries.
   Uses both Encoder and Regressor to predict latent distributions.</li>
<li><strong>PELS-VAE</strong> (params_to_decoder=True): Decoder receives both latent vector and 
   system parameters, allowing parameter-conditioned reconstruction.</li>
<li><strong>Feed-forward NN</strong> (feed_forward_nn=True): Bypasses latent space entirely,
   directly mapping parameters to timeseries outputs.</li>
</ol>
<p>The model jointly trains:</p>
<ul>
<li>Encoder: timeseries  (mu_encoder, logvar_encoder)</li>
<li>Regressor: parameters  (mu_regressor, logvar_regressor)</li>
<li>Decoder: latent vector (+ params)  timeseries</li>
</ul>
<p>During training, reconstruction uses Encoder's latent distribution.
During prediction, reconstruction uses Regressor's latent distribution.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.VAE.n_channels">n_channels</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of channels (n_states + n_outputs).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.VAE.n_states">n_states</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of state channels.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.VAE.n_outputs">n_outputs</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of output channels.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.VAE.timeseries_normalization">timeseries_normalization</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Normalization layer for timeseries data.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.VAE.feed_forward_nn">feed_forward_nn</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, operates in feed-forward mode (no latent space).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.VAE.Regressor">Regressor</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Parameter-to-latent network (if not feed_forward_nn).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.VAE.Encoder">Encoder</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Timeseries-to-latent network (if not feed_forward_nn).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="bnode_core.nn.vae.vae_architecture.VAE.Decoder">Decoder</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Latent-to-timeseries network.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span>
<span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span>
<span class="normal"><a href="#__codelineno-0-502">502</a></span>
<span class="normal"><a href="#__codelineno-0-503">503</a></span>
<span class="normal"><a href="#__codelineno-0-504">504</a></span>
<span class="normal"><a href="#__codelineno-0-505">505</a></span>
<span class="normal"><a href="#__codelineno-0-506">506</a></span>
<span class="normal"><a href="#__codelineno-0-507">507</a></span>
<span class="normal"><a href="#__codelineno-0-508">508</a></span>
<span class="normal"><a href="#__codelineno-0-509">509</a></span>
<span class="normal"><a href="#__codelineno-0-510">510</a></span>
<span class="normal"><a href="#__codelineno-0-511">511</a></span>
<span class="normal"><a href="#__codelineno-0-512">512</a></span>
<span class="normal"><a href="#__codelineno-0-513">513</a></span>
<span class="normal"><a href="#__codelineno-0-514">514</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-260" name="__codelineno-0-260"></a><span class="k">class</span><span class="w"> </span><span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Variational Autoencoder for timeseries modeling with parameter conditioning.</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a><span class="sd">    This class implements three operational modes:</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a><span class="sd">    1. **Standard VAE**: Encodes timeseries to latent space, decodes back to timeseries.</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="sd">       Uses both Encoder and Regressor to predict latent distributions.</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a><span class="sd">    2. **PELS-VAE** (params_to_decoder=True): Decoder receives both latent vector and </span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">       system parameters, allowing parameter-conditioned reconstruction.</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">    3. **Feed-forward NN** (feed_forward_nn=True): Bypasses latent space entirely,</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a><span class="sd">       directly mapping parameters to timeseries outputs.</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">    The model jointly trains:</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a><span class="sd">    - Encoder: timeseries  (mu_encoder, logvar_encoder)</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">    - Regressor: parameters  (mu_regressor, logvar_regressor)</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">    - Decoder: latent vector (+ params)  timeseries</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a><span class="sd">    During training, reconstruction uses Encoder&#39;s latent distribution.</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a><span class="sd">    During prediction, reconstruction uses Regressor&#39;s latent distribution.</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="sd">        n_channels: Total number of channels (n_states + n_outputs).</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">        n_states: Number of state channels.</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="sd">        n_outputs: Number of output channels.</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a><span class="sd">        timeseries_normalization: Normalization layer for timeseries data.</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">        feed_forward_nn: If True, operates in feed-forward mode (no latent space).</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a><span class="sd">        Regressor: Parameter-to-latent network (if not feed_forward_nn).</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a><span class="sd">        Encoder: Timeseries-to-latent network (if not feed_forward_nn).</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="sd">        Decoder: Latent-to-timeseries network.</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_states</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>                 <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> 
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>                 <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">params_to_decoder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">feed_forward_nn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the VAE model.</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a><span class="sd">            n_states: Number of state channels in timeseries.</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a><span class="sd">            n_outputs: Number of output channels in timeseries.</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a><span class="sd">            seq_len: Length of timeseries sequence.</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="sd">            parameter_dim: Dimensionality of system parameters.</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a><span class="sd">            hidden_dim: Number of hidden units in all sub-networks.</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">            bottleneck_dim: Dimensionality of latent space.</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a><span class="sd">            activation: Activation function class (default: nn.ReLU).</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a><span class="sd">            n_layers: Number of layers in all sub-networks (minimum 2).</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a><span class="sd">            params_to_decoder: If True, decoder receives parameters as additional input (PELS-VAE mode).</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a><span class="sd">            feed_forward_nn: If True, operate in feed-forward mode without latent space.</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>        <span class="k">if</span> <span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>            <span class="k">if</span> <span class="n">params_to_decoder</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>                <span class="ne">Warning</span><span class="p">(</span><span class="s1">&#39;params_to_decoder is set to False, but feed_forward_nn is set to True. Setting params_to_decoder to True&#39;</span><span class="p">)</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span> <span class="o">=</span> <span class="n">n_states</span> <span class="o">+</span> <span class="n">n_outputs</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_states</span> <span class="o">=</span> <span class="n">n_states</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="n">n_outputs</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span> <span class="o">=</span> <span class="n">NormalizationLayerTimeSeries</span><span class="p">(</span><span class="n">n_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">)</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="o">=</span> <span class="n">feed_forward_nn</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>        <span class="k">if</span> <span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">Regressor</span> <span class="o">=</span> <span class="n">Regressor</span><span class="p">(</span><span class="n">parameter_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">Encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>                                <span class="n">bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>                                <span class="n">bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>                                <span class="n">params_to_decoder</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">)</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>            <span class="n">_bottleneck_dim</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>            <span class="n">_params_to_decoder</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>                                   <span class="n">_bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>                                      <span class="n">_params_to_decoder</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">)</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;VAE with n_channels = </span><span class="si">{}</span><span class="s1">, seq_len = </span><span class="si">{}</span><span class="s1">, parameter_dim = </span><span class="si">{}</span><span class="s1">, </span><span class="se">\</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a><span class="s1">                     hidden_dim = </span><span class="si">{}</span><span class="s1">, bottleneck_dim = </span><span class="si">{}</span><span class="s1">, activation = </span><span class="si">{}</span><span class="s1">, n_layers = </span><span class="si">{}</span><span class="s1">, params to decoder: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>                         <span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="o">.</span><span class="n">params_to_decoder</span><span class="p">))</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;VAE initialized with </span><span class="si">{}</span><span class="s1"> parameters&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">count_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)))</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reparametrize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply reparametrization trick to sample from latent distribution.</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a><span class="sd">        Samples z ~ N(mu, exp(0.5 * logvar)) using z = mu + eps * std, where eps ~ N(0, I).</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a><span class="sd">        This allows backpropagation through the sampling operation.</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a><span class="sd">            mu: Mean of latent distribution, shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a><span class="sd">            logvar: Log-variance of latent distribution, shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a><span class="sd">            Sampled latent vector z of shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>        <span class="c1"># if device.type == &#39;cuda&#39;:</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>        <span class="c1">#     eps = torch.autograd.Variable(torch.cuda.FloatTensor(mu.shape).normal_())</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>        <span class="c1"># else: </span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>        <span class="c1">#     eps = torch.autograd.Variable(torch.FloatTensor(mu.shape).normal_())</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">mu</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>        <span class="n">std</span> <span class="o">=</span> <span class="n">logvar</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>        <span class="n">z_latent</span> <span class="o">=</span> <span class="n">eps</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a>        <span class="k">return</span> <span class="n">z_latent</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>        <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-362" name="__codelineno-0-362"></a>        <span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-363" name="__codelineno-0-363"></a>        <span class="n">outputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-364" name="__codelineno-0-364"></a>        <span class="n">params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-365" name="__codelineno-0-365"></a>        <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
<a id="__codelineno-0-366" name="__codelineno-0-366"></a>        <span class="n">predict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>        <span class="n">n_passes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
<a id="__codelineno-0-368" name="__codelineno-0-368"></a>        <span class="n">test_with_zero_eps</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform forward pass through the VAE network.</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a><span class="sd">        Three operational modes based on flags:</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a><span class="sd">        1. Training (train=True, predict=False): Encode timeseries, reconstruct using Encoder&#39;s latent distribution</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a><span class="sd">        2. Testing (train=False, predict=False): Encode timeseries, reconstruct using Regressor&#39;s latent distribution</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a><span class="sd">        3. Prediction (predict=True, train=False): Skip Encoder, reconstruct using Regressor&#39;s latent distribution only</span>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a><span class="sd">            states: State timeseries of shape (batch, n_states, seq_len).</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="sd">            outputs: Output timeseries of shape (batch, n_outputs, seq_len).</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a><span class="sd">            params: System parameters of shape (batch, parameter_dim).</span>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a><span class="sd">            train: If True, use Encoder&#39;s latent distribution for reconstruction.</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a><span class="sd">            predict: If True, bypass Encoder and reconstruct from parameters only.</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a><span class="sd">            n_passes: Number of decoder passes to average (for stochastic predictions).</span>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a><span class="sd">            test_with_zero_eps: If True during testing, use mu directly (zero variance sampling).</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a><span class="sd">            device: Device for tensor operations.</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a><span class="sd">            Tuple of (x, x_hat, states_hat, outputs_hat, mu_encoder, logvar_encoder, </span>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a><span class="sd">                     mu_regressor, logvar_regressor, retvals_norm) where:</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a><span class="sd">                - x: Concatenated input timeseries (states + outputs)</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a><span class="sd">                - x_hat: Reconstructed timeseries</span>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a><span class="sd">                - states_hat: Reconstructed states</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a><span class="sd">                - outputs_hat: Reconstructed outputs</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a><span class="sd">                - mu_encoder: Encoder&#39;s predicted latent mean</span>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a><span class="sd">                - logvar_encoder: Encoder&#39;s predicted latent log-variance</span>
<a id="__codelineno-0-399" name="__codelineno-0-399"></a><span class="sd">                - mu_regressor: Regressor&#39;s predicted latent mean</span>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a><span class="sd">                - logvar_regressor: Regressor&#39;s predicted latent log-variance</span>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a><span class="sd">                - retvals_norm: Dictionary of normalized versions of above tensors</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a>            <span class="k">if</span> <span class="n">predict</span><span class="p">:</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a>                <span class="k">assert</span> <span class="ow">not</span> <span class="n">train</span><span class="p">,</span> <span class="s1">&#39;predict and train cannot be true at the same time&#39;</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a>                <span class="c1"># concatenate states and outputs</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-409" name="__codelineno-0-409"></a>                <span class="n">x_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-410" name="__codelineno-0-410"></a>                <span class="n">states_norm</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,:</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">]</span>
<a id="__codelineno-0-411" name="__codelineno-0-411"></a>                <span class="n">outputs_norm</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">:]</span>
<a id="__codelineno-0-412" name="__codelineno-0-412"></a>                <span class="n">mu_encoder</span><span class="p">,</span> <span class="n">logvar_encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Encoder</span><span class="p">(</span><span class="n">x_norm</span><span class="p">)</span>
<a id="__codelineno-0-413" name="__codelineno-0-413"></a>            <span class="n">mu_regressor</span><span class="p">,</span> <span class="n">logvar_regressor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Regressor</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-414" name="__codelineno-0-414"></a>            <span class="c1"># assign mu, logvar based on if train or not</span>
<a id="__codelineno-0-415" name="__codelineno-0-415"></a>            <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
<a id="__codelineno-0-416" name="__codelineno-0-416"></a>                <span class="n">mu</span> <span class="o">=</span> <span class="n">mu_encoder</span>
<a id="__codelineno-0-417" name="__codelineno-0-417"></a>                <span class="n">logvar</span> <span class="o">=</span> <span class="n">logvar_encoder</span>
<a id="__codelineno-0-418" name="__codelineno-0-418"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-419" name="__codelineno-0-419"></a>                <span class="n">mu</span> <span class="o">=</span> <span class="n">mu_regressor</span>
<a id="__codelineno-0-420" name="__codelineno-0-420"></a>                <span class="n">logvar</span> <span class="o">=</span> <span class="n">logvar_regressor</span>
<a id="__codelineno-0-421" name="__codelineno-0-421"></a>            <span class="c1"># if predict, we need some dummy values for mu_encoder and logvar_encoder</span>
<a id="__codelineno-0-422" name="__codelineno-0-422"></a>            <span class="k">if</span> <span class="n">predict</span><span class="p">:</span>
<a id="__codelineno-0-423" name="__codelineno-0-423"></a>                <span class="n">mu_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">mu_encoder</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-424" name="__codelineno-0-424"></a>                <span class="n">logvar_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">logvar_encoder</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-425" name="__codelineno-0-425"></a>            <span class="c1"># perform multiple passes through decoder</span>
<a id="__codelineno-0-426" name="__codelineno-0-426"></a>            <span class="n">x_pass</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-427" name="__codelineno-0-427"></a>            <span class="n">x_pass_norm</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-428" name="__codelineno-0-428"></a>            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_passes</span><span class="p">):</span>
<a id="__codelineno-0-429" name="__codelineno-0-429"></a>                <span class="k">if</span> <span class="n">train</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">test_with_zero_eps</span><span class="p">:</span>
<a id="__codelineno-0-430" name="__codelineno-0-430"></a>                    <span class="n">z_latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparametrize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>                    <span class="n">z_latent</span> <span class="o">=</span> <span class="n">mu</span>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="o">.</span><span class="n">params_to_decoder</span><span class="p">:</span>
<a id="__codelineno-0-434" name="__codelineno-0-434"></a>                    <span class="n">x_i_hat_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">z_latent</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-435" name="__codelineno-0-435"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-436" name="__codelineno-0-436"></a>                    <span class="n">x_i_hat_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">z_latent</span><span class="p">)</span>
<a id="__codelineno-0-437" name="__codelineno-0-437"></a>                <span class="n">x_i_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span><span class="p">(</span><span class="n">x_i_hat_norm</span><span class="p">,</span> <span class="n">denormalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-438" name="__codelineno-0-438"></a>                <span class="n">x_pass</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_i_hat</span><span class="p">)</span>
<a id="__codelineno-0-439" name="__codelineno-0-439"></a>                <span class="n">x_pass_norm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_i_hat_norm</span><span class="p">)</span>
<a id="__codelineno-0-440" name="__codelineno-0-440"></a>            <span class="c1"># stack along new dimension 1 and take mean along that dimension</span>
<a id="__codelineno-0-441" name="__codelineno-0-441"></a>            <span class="n">x_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_pass</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-442" name="__codelineno-0-442"></a>            <span class="n">x_hat_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_pass_norm</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-443" name="__codelineno-0-443"></a>            <span class="c1"># unpack x</span>
<a id="__codelineno-0-444" name="__codelineno-0-444"></a>            <span class="n">states_hat</span><span class="p">,</span> <span class="n">outputs_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-445" name="__codelineno-0-445"></a>            <span class="c1"># unpack x_norm</span>
<a id="__codelineno-0-446" name="__codelineno-0-446"></a>            <span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">outputs_hat_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x_hat_norm</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-447" name="__codelineno-0-447"></a>            <span class="n">retvals_norm</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-448" name="__codelineno-0-448"></a>                <span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">x_norm</span><span class="p">,</span>
<a id="__codelineno-0-449" name="__codelineno-0-449"></a>                <span class="s1">&#39;x_hat&#39;</span><span class="p">:</span> <span class="n">x_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-450" name="__codelineno-0-450"></a>                <span class="s1">&#39;states&#39;</span><span class="p">:</span> <span class="n">states_norm</span><span class="p">,</span>
<a id="__codelineno-0-451" name="__codelineno-0-451"></a>                <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="n">outputs_norm</span><span class="p">,</span>
<a id="__codelineno-0-452" name="__codelineno-0-452"></a>                <span class="s1">&#39;states_hat&#39;</span><span class="p">:</span> <span class="n">states_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-453" name="__codelineno-0-453"></a>                <span class="s1">&#39;outputs_hat&#39;</span><span class="p">:</span> <span class="n">outputs_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-454" name="__codelineno-0-454"></a>            <span class="p">}</span>
<a id="__codelineno-0-455" name="__codelineno-0-455"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-456" name="__codelineno-0-456"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-457" name="__codelineno-0-457"></a>            <span class="n">x_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-458" name="__codelineno-0-458"></a>            <span class="n">states_norm</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,:</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">]</span>
<a id="__codelineno-0-459" name="__codelineno-0-459"></a>            <span class="n">outputs_norm</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">:]</span>
<a id="__codelineno-0-460" name="__codelineno-0-460"></a>            <span class="n">x_hat_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-461" name="__codelineno-0-461"></a>            <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span><span class="p">(</span><span class="n">x_hat_norm</span><span class="p">,</span> <span class="n">denormalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-462" name="__codelineno-0-462"></a>             <span class="c1"># unpack x</span>
<a id="__codelineno-0-463" name="__codelineno-0-463"></a>            <span class="n">states_hat</span><span class="p">,</span> <span class="n">outputs_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-464" name="__codelineno-0-464"></a>            <span class="c1"># unpack x_norm</span>
<a id="__codelineno-0-465" name="__codelineno-0-465"></a>            <span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">outputs_hat_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x_hat_norm</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-466" name="__codelineno-0-466"></a>            <span class="n">retvals_norm</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-467" name="__codelineno-0-467"></a>                <span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">x_norm</span><span class="p">,</span>
<a id="__codelineno-0-468" name="__codelineno-0-468"></a>                <span class="s1">&#39;x_hat&#39;</span><span class="p">:</span> <span class="n">x_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-469" name="__codelineno-0-469"></a>                <span class="s1">&#39;states&#39;</span><span class="p">:</span> <span class="n">states_norm</span><span class="p">,</span>
<a id="__codelineno-0-470" name="__codelineno-0-470"></a>                <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="n">outputs_norm</span><span class="p">,</span>
<a id="__codelineno-0-471" name="__codelineno-0-471"></a>                <span class="s1">&#39;states_hat&#39;</span><span class="p">:</span> <span class="n">states_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-472" name="__codelineno-0-472"></a>                <span class="s1">&#39;outputs_hat&#39;</span><span class="p">:</span> <span class="n">outputs_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-473" name="__codelineno-0-473"></a>            <span class="p">}</span>
<a id="__codelineno-0-474" name="__codelineno-0-474"></a>            <span class="n">mu_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-475" name="__codelineno-0-475"></a>            <span class="n">logvar_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-476" name="__codelineno-0-476"></a>            <span class="n">mu_regressor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-477" name="__codelineno-0-477"></a>            <span class="n">logvar_regressor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a>        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">states_hat</span><span class="p">,</span> <span class="n">outputs_hat</span><span class="p">,</span> <span class="n">mu_encoder</span><span class="p">,</span> <span class="n">logvar_encoder</span><span class="p">,</span> <span class="n">mu_regressor</span><span class="p">,</span> <span class="n">logvar_regressor</span><span class="p">,</span> <span class="n">retvals_norm</span>
<a id="__codelineno-0-480" name="__codelineno-0-480"></a>
<a id="__codelineno-0-481" name="__codelineno-0-481"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate timeseries predictions from system parameters only.</span>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a><span class="sd">        Convenience method for inference mode. Bypasses Encoder and generates</span>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="sd">        predictions using only Regressor and Decoder.</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a><span class="sd">            param: System parameters of shape (batch, parameter_dim).</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a><span class="sd">            Same as forward() method with predict=True.</span>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">param</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">predict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">):</span>
<a id="__codelineno-0-496" name="__codelineno-0-496"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Save model state dictionary to disk.</span>
<a id="__codelineno-0-497" name="__codelineno-0-497"></a>
<a id="__codelineno-0-498" name="__codelineno-0-498"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-499" name="__codelineno-0-499"></a><span class="sd">            path: Path to save the model weights. Parent directories are created if needed.</span>
<a id="__codelineno-0-500" name="__codelineno-0-500"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-501" name="__codelineno-0-501"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
<a id="__codelineno-0-502" name="__codelineno-0-502"></a>            <span class="n">path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-503" name="__codelineno-0-503"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
<a id="__codelineno-0-504" name="__codelineno-0-504"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Saved model to </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
<a id="__codelineno-0-505" name="__codelineno-0-505"></a>
<a id="__codelineno-0-506" name="__codelineno-0-506"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-507" name="__codelineno-0-507"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model state dictionary from disk.</span>
<a id="__codelineno-0-508" name="__codelineno-0-508"></a>
<a id="__codelineno-0-509" name="__codelineno-0-509"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-510" name="__codelineno-0-510"></a><span class="sd">            path: Path to the saved model weights.</span>
<a id="__codelineno-0-511" name="__codelineno-0-511"></a><span class="sd">            device: Device to map the loaded weights to (e.g., &#39;cpu&#39;, &#39;cuda&#39;).</span>
<a id="__codelineno-0-512" name="__codelineno-0-512"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-513" name="__codelineno-0-513"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
<a id="__codelineno-0-514" name="__codelineno-0-514"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">Loaded model from </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.VAE.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">n_states</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">params_to_decoder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">feed_forward_nn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize the VAE model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n_states</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of state channels in timeseries.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_outputs</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of output channels in timeseries.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seq_len</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of timeseries sequence.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>parameter_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimensionality of system parameters.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of hidden units in all sub-networks.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bottleneck_dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimensionality of latent space.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>activation</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Activation function class (default: nn.ReLU).</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.ReLU">ReLU</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_layers</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of layers in all sub-networks (minimum 2).</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params_to_decoder</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, decoder receives parameters as additional input (PELS-VAE mode).</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>feed_forward_nn</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, operate in feed-forward mode without latent space.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_states</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>             <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> 
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>             <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">params_to_decoder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">feed_forward_nn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the VAE model.</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a><span class="sd">        n_states: Number of state channels in timeseries.</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a><span class="sd">        n_outputs: Number of output channels in timeseries.</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a><span class="sd">        seq_len: Length of timeseries sequence.</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="sd">        parameter_dim: Dimensionality of system parameters.</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a><span class="sd">        hidden_dim: Number of hidden units in all sub-networks.</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">        bottleneck_dim: Dimensionality of latent space.</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a><span class="sd">        activation: Activation function class (default: nn.ReLU).</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a><span class="sd">        n_layers: Number of layers in all sub-networks (minimum 2).</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a><span class="sd">        params_to_decoder: If True, decoder receives parameters as additional input (PELS-VAE mode).</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a><span class="sd">        feed_forward_nn: If True, operate in feed-forward mode without latent space.</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>    <span class="k">if</span> <span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>        <span class="k">if</span> <span class="n">params_to_decoder</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>            <span class="ne">Warning</span><span class="p">(</span><span class="s1">&#39;params_to_decoder is set to False, but feed_forward_nn is set to True. Setting params_to_decoder to True&#39;</span><span class="p">)</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span> <span class="o">=</span> <span class="n">n_states</span> <span class="o">+</span> <span class="n">n_outputs</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">n_states</span> <span class="o">=</span> <span class="n">n_states</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="n">n_outputs</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span> <span class="o">=</span> <span class="n">NormalizationLayerTimeSeries</span><span class="p">(</span><span class="n">n_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">)</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="o">=</span> <span class="n">feed_forward_nn</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>    <span class="k">if</span> <span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">Regressor</span> <span class="o">=</span> <span class="n">Regressor</span><span class="p">(</span><span class="n">parameter_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">Encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>                            <span class="n">bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>                            <span class="n">bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>                            <span class="n">params_to_decoder</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">)</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>        <span class="n">_bottleneck_dim</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>        <span class="n">_params_to_decoder</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>                               <span class="n">_bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>                                  <span class="n">_params_to_decoder</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">)</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;VAE with n_channels = </span><span class="si">{}</span><span class="s1">, seq_len = </span><span class="si">{}</span><span class="s1">, parameter_dim = </span><span class="si">{}</span><span class="s1">, </span><span class="se">\</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a><span class="s1">                 hidden_dim = </span><span class="si">{}</span><span class="s1">, bottleneck_dim = </span><span class="si">{}</span><span class="s1">, activation = </span><span class="si">{}</span><span class="s1">, n_layers = </span><span class="si">{}</span><span class="s1">, params to decoder: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>                     <span class="bp">self</span><span class="o">.</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">parameter_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">bottleneck_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="o">.</span><span class="n">params_to_decoder</span><span class="p">))</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;VAE initialized with </span><span class="si">{}</span><span class="s1"> parameters&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">count_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.VAE.reparametrize" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reparametrize</span><span class="p">(</span><span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Apply reparametrization trick to sample from latent distribution.</p>
<p>Samples z ~ N(mu, exp(0.5 * logvar)) using z = mu + eps * std, where eps ~ N(0, I).
This allows backpropagation through the sampling operation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mu</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mean of latent distribution, shape (batch, bottleneck_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logvar</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Log-variance of latent distribution, shape (batch, bottleneck_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampled latent vector z of shape (batch, bottleneck_dim).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-337" name="__codelineno-0-337"></a><span class="k">def</span><span class="w"> </span><span class="nf">reparametrize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply reparametrization trick to sample from latent distribution.</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a><span class="sd">    Samples z ~ N(mu, exp(0.5 * logvar)) using z = mu + eps * std, where eps ~ N(0, I).</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a><span class="sd">    This allows backpropagation through the sampling operation.</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a><span class="sd">        mu: Mean of latent distribution, shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a><span class="sd">        logvar: Log-variance of latent distribution, shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a><span class="sd">        Sampled latent vector z of shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>    <span class="c1"># if device.type == &#39;cuda&#39;:</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>    <span class="c1">#     eps = torch.autograd.Variable(torch.cuda.FloatTensor(mu.shape).normal_())</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>    <span class="c1"># else: </span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>    <span class="c1">#     eps = torch.autograd.Variable(torch.FloatTensor(mu.shape).normal_())</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>    <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">mu</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>    <span class="n">std</span> <span class="o">=</span> <span class="n">logvar</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>    <span class="n">z_latent</span> <span class="o">=</span> <span class="n">eps</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a>    <span class="k">return</span> <span class="n">z_latent</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.VAE.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">predict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">n_passes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">test_with_zero_eps</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Perform forward pass through the VAE network.</p>
<p>Three operational modes based on flags:</p>
<ol>
<li>Training (train=True, predict=False): Encode timeseries, reconstruct using Encoder's latent distribution</li>
<li>Testing (train=False, predict=False): Encode timeseries, reconstruct using Regressor's latent distribution</li>
<li>Prediction (predict=True, train=False): Skip Encoder, reconstruct using Regressor's latent distribution only</li>
</ol>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>states</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>State timeseries of shape (batch, n_states, seq_len).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>outputs</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Output timeseries of shape (batch, n_outputs, seq_len).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>System parameters of shape (batch, parameter_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use Encoder's latent distribution for reconstruction.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>predict</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, bypass Encoder and reconstruct from parameters only.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_passes</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decoder passes to average (for stochastic predictions).</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>test_with_zero_eps</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True during testing, use mu directly (zero variance sampling).</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.device">device</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device for tensor operations.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Tuple">Tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple of (x, x_hat, states_hat, outputs_hat, mu_encoder, logvar_encoder, 
     mu_regressor, logvar_regressor, retvals_norm) where:</p>
<ul>
<li>x: Concatenated input timeseries (states + outputs)</li>
<li>x_hat: Reconstructed timeseries</li>
<li>states_hat: Reconstructed states</li>
<li>outputs_hat: Reconstructed outputs</li>
<li>mu_encoder: Encoder's predicted latent mean</li>
<li>logvar_encoder: Encoder's predicted latent log-variance</li>
<li>mu_regressor: Regressor's predicted latent mean</li>
<li>logvar_regressor: Regressor's predicted latent log-variance</li>
<li>retvals_norm: Dictionary of normalized versions of above tensors</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span>
<span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-360" name="__codelineno-0-360"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>    <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-362" name="__codelineno-0-362"></a>    <span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-363" name="__codelineno-0-363"></a>    <span class="n">outputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-364" name="__codelineno-0-364"></a>    <span class="n">params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-365" name="__codelineno-0-365"></a>    <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
<a id="__codelineno-0-366" name="__codelineno-0-366"></a>    <span class="n">predict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>    <span class="n">n_passes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
<a id="__codelineno-0-368" name="__codelineno-0-368"></a>    <span class="n">test_with_zero_eps</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform forward pass through the VAE network.</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a><span class="sd">    Three operational modes based on flags:</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a><span class="sd">    1. Training (train=True, predict=False): Encode timeseries, reconstruct using Encoder&#39;s latent distribution</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a><span class="sd">    2. Testing (train=False, predict=False): Encode timeseries, reconstruct using Regressor&#39;s latent distribution</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a><span class="sd">    3. Prediction (predict=True, train=False): Skip Encoder, reconstruct using Regressor&#39;s latent distribution only</span>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a><span class="sd">        states: State timeseries of shape (batch, n_states, seq_len).</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="sd">        outputs: Output timeseries of shape (batch, n_outputs, seq_len).</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a><span class="sd">        params: System parameters of shape (batch, parameter_dim).</span>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a><span class="sd">        train: If True, use Encoder&#39;s latent distribution for reconstruction.</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a><span class="sd">        predict: If True, bypass Encoder and reconstruct from parameters only.</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a><span class="sd">        n_passes: Number of decoder passes to average (for stochastic predictions).</span>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a><span class="sd">        test_with_zero_eps: If True during testing, use mu directly (zero variance sampling).</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a><span class="sd">        device: Device for tensor operations.</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a><span class="sd">        Tuple of (x, x_hat, states_hat, outputs_hat, mu_encoder, logvar_encoder, </span>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a><span class="sd">                 mu_regressor, logvar_regressor, retvals_norm) where:</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a><span class="sd">            - x: Concatenated input timeseries (states + outputs)</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a><span class="sd">            - x_hat: Reconstructed timeseries</span>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a><span class="sd">            - states_hat: Reconstructed states</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a><span class="sd">            - outputs_hat: Reconstructed outputs</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a><span class="sd">            - mu_encoder: Encoder&#39;s predicted latent mean</span>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a><span class="sd">            - logvar_encoder: Encoder&#39;s predicted latent log-variance</span>
<a id="__codelineno-0-399" name="__codelineno-0-399"></a><span class="sd">            - mu_regressor: Regressor&#39;s predicted latent mean</span>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a><span class="sd">            - logvar_regressor: Regressor&#39;s predicted latent log-variance</span>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a><span class="sd">            - retvals_norm: Dictionary of normalized versions of above tensors</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a>        <span class="k">if</span> <span class="n">predict</span><span class="p">:</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">train</span><span class="p">,</span> <span class="s1">&#39;predict and train cannot be true at the same time&#39;</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a>            <span class="c1"># concatenate states and outputs</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-409" name="__codelineno-0-409"></a>            <span class="n">x_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-410" name="__codelineno-0-410"></a>            <span class="n">states_norm</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,:</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">]</span>
<a id="__codelineno-0-411" name="__codelineno-0-411"></a>            <span class="n">outputs_norm</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">:]</span>
<a id="__codelineno-0-412" name="__codelineno-0-412"></a>            <span class="n">mu_encoder</span><span class="p">,</span> <span class="n">logvar_encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Encoder</span><span class="p">(</span><span class="n">x_norm</span><span class="p">)</span>
<a id="__codelineno-0-413" name="__codelineno-0-413"></a>        <span class="n">mu_regressor</span><span class="p">,</span> <span class="n">logvar_regressor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Regressor</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-414" name="__codelineno-0-414"></a>        <span class="c1"># assign mu, logvar based on if train or not</span>
<a id="__codelineno-0-415" name="__codelineno-0-415"></a>        <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
<a id="__codelineno-0-416" name="__codelineno-0-416"></a>            <span class="n">mu</span> <span class="o">=</span> <span class="n">mu_encoder</span>
<a id="__codelineno-0-417" name="__codelineno-0-417"></a>            <span class="n">logvar</span> <span class="o">=</span> <span class="n">logvar_encoder</span>
<a id="__codelineno-0-418" name="__codelineno-0-418"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-419" name="__codelineno-0-419"></a>            <span class="n">mu</span> <span class="o">=</span> <span class="n">mu_regressor</span>
<a id="__codelineno-0-420" name="__codelineno-0-420"></a>            <span class="n">logvar</span> <span class="o">=</span> <span class="n">logvar_regressor</span>
<a id="__codelineno-0-421" name="__codelineno-0-421"></a>        <span class="c1"># if predict, we need some dummy values for mu_encoder and logvar_encoder</span>
<a id="__codelineno-0-422" name="__codelineno-0-422"></a>        <span class="k">if</span> <span class="n">predict</span><span class="p">:</span>
<a id="__codelineno-0-423" name="__codelineno-0-423"></a>            <span class="n">mu_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">mu_encoder</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-424" name="__codelineno-0-424"></a>            <span class="n">logvar_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">logvar_encoder</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-425" name="__codelineno-0-425"></a>        <span class="c1"># perform multiple passes through decoder</span>
<a id="__codelineno-0-426" name="__codelineno-0-426"></a>        <span class="n">x_pass</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-427" name="__codelineno-0-427"></a>        <span class="n">x_pass_norm</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-428" name="__codelineno-0-428"></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_passes</span><span class="p">):</span>
<a id="__codelineno-0-429" name="__codelineno-0-429"></a>            <span class="k">if</span> <span class="n">train</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">test_with_zero_eps</span><span class="p">:</span>
<a id="__codelineno-0-430" name="__codelineno-0-430"></a>                <span class="n">z_latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparametrize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>                <span class="n">z_latent</span> <span class="o">=</span> <span class="n">mu</span>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="o">.</span><span class="n">params_to_decoder</span><span class="p">:</span>
<a id="__codelineno-0-434" name="__codelineno-0-434"></a>                <span class="n">x_i_hat_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">z_latent</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-435" name="__codelineno-0-435"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-436" name="__codelineno-0-436"></a>                <span class="n">x_i_hat_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">z_latent</span><span class="p">)</span>
<a id="__codelineno-0-437" name="__codelineno-0-437"></a>            <span class="n">x_i_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span><span class="p">(</span><span class="n">x_i_hat_norm</span><span class="p">,</span> <span class="n">denormalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-438" name="__codelineno-0-438"></a>            <span class="n">x_pass</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_i_hat</span><span class="p">)</span>
<a id="__codelineno-0-439" name="__codelineno-0-439"></a>            <span class="n">x_pass_norm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_i_hat_norm</span><span class="p">)</span>
<a id="__codelineno-0-440" name="__codelineno-0-440"></a>        <span class="c1"># stack along new dimension 1 and take mean along that dimension</span>
<a id="__codelineno-0-441" name="__codelineno-0-441"></a>        <span class="n">x_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_pass</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-442" name="__codelineno-0-442"></a>        <span class="n">x_hat_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_pass_norm</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-443" name="__codelineno-0-443"></a>        <span class="c1"># unpack x</span>
<a id="__codelineno-0-444" name="__codelineno-0-444"></a>        <span class="n">states_hat</span><span class="p">,</span> <span class="n">outputs_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-445" name="__codelineno-0-445"></a>        <span class="c1"># unpack x_norm</span>
<a id="__codelineno-0-446" name="__codelineno-0-446"></a>        <span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">outputs_hat_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x_hat_norm</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-447" name="__codelineno-0-447"></a>        <span class="n">retvals_norm</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-448" name="__codelineno-0-448"></a>            <span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">x_norm</span><span class="p">,</span>
<a id="__codelineno-0-449" name="__codelineno-0-449"></a>            <span class="s1">&#39;x_hat&#39;</span><span class="p">:</span> <span class="n">x_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-450" name="__codelineno-0-450"></a>            <span class="s1">&#39;states&#39;</span><span class="p">:</span> <span class="n">states_norm</span><span class="p">,</span>
<a id="__codelineno-0-451" name="__codelineno-0-451"></a>            <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="n">outputs_norm</span><span class="p">,</span>
<a id="__codelineno-0-452" name="__codelineno-0-452"></a>            <span class="s1">&#39;states_hat&#39;</span><span class="p">:</span> <span class="n">states_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-453" name="__codelineno-0-453"></a>            <span class="s1">&#39;outputs_hat&#39;</span><span class="p">:</span> <span class="n">outputs_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-454" name="__codelineno-0-454"></a>        <span class="p">}</span>
<a id="__codelineno-0-455" name="__codelineno-0-455"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-456" name="__codelineno-0-456"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-457" name="__codelineno-0-457"></a>        <span class="n">x_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-458" name="__codelineno-0-458"></a>        <span class="n">states_norm</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,:</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">]</span>
<a id="__codelineno-0-459" name="__codelineno-0-459"></a>        <span class="n">outputs_norm</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">:]</span>
<a id="__codelineno-0-460" name="__codelineno-0-460"></a>        <span class="n">x_hat_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-461" name="__codelineno-0-461"></a>        <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">timeseries_normalization</span><span class="p">(</span><span class="n">x_hat_norm</span><span class="p">,</span> <span class="n">denormalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-462" name="__codelineno-0-462"></a>         <span class="c1"># unpack x</span>
<a id="__codelineno-0-463" name="__codelineno-0-463"></a>        <span class="n">states_hat</span><span class="p">,</span> <span class="n">outputs_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-464" name="__codelineno-0-464"></a>        <span class="c1"># unpack x_norm</span>
<a id="__codelineno-0-465" name="__codelineno-0-465"></a>        <span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">outputs_hat_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x_hat_norm</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-466" name="__codelineno-0-466"></a>        <span class="n">retvals_norm</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-467" name="__codelineno-0-467"></a>            <span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">x_norm</span><span class="p">,</span>
<a id="__codelineno-0-468" name="__codelineno-0-468"></a>            <span class="s1">&#39;x_hat&#39;</span><span class="p">:</span> <span class="n">x_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-469" name="__codelineno-0-469"></a>            <span class="s1">&#39;states&#39;</span><span class="p">:</span> <span class="n">states_norm</span><span class="p">,</span>
<a id="__codelineno-0-470" name="__codelineno-0-470"></a>            <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="n">outputs_norm</span><span class="p">,</span>
<a id="__codelineno-0-471" name="__codelineno-0-471"></a>            <span class="s1">&#39;states_hat&#39;</span><span class="p">:</span> <span class="n">states_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-472" name="__codelineno-0-472"></a>            <span class="s1">&#39;outputs_hat&#39;</span><span class="p">:</span> <span class="n">outputs_hat_norm</span><span class="p">,</span>
<a id="__codelineno-0-473" name="__codelineno-0-473"></a>        <span class="p">}</span>
<a id="__codelineno-0-474" name="__codelineno-0-474"></a>        <span class="n">mu_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-475" name="__codelineno-0-475"></a>        <span class="n">logvar_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-476" name="__codelineno-0-476"></a>        <span class="n">mu_regressor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-477" name="__codelineno-0-477"></a>        <span class="n">logvar_regressor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">states_hat_norm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a>    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">states_hat</span><span class="p">,</span> <span class="n">outputs_hat</span><span class="p">,</span> <span class="n">mu_encoder</span><span class="p">,</span> <span class="n">logvar_encoder</span><span class="p">,</span> <span class="n">mu_regressor</span><span class="p">,</span> <span class="n">logvar_regressor</span><span class="p">,</span> <span class="n">retvals_norm</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.VAE.predict" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">param</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Generate timeseries predictions from system parameters only.</p>
<p>Convenience method for inference mode. Bypasses Encoder and generates
predictions using only Regressor and Decoder.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>param</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>System parameters of shape (batch, parameter_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Tuple">Tuple</span>[<span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Same as forward() method with predict=True.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-481" name="__codelineno-0-481"></a><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate timeseries predictions from system parameters only.</span>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a><span class="sd">    Convenience method for inference mode. Bypasses Encoder and generates</span>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="sd">    predictions using only Regressor and Decoder.</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a><span class="sd">        param: System parameters of shape (batch, parameter_dim).</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a><span class="sd">        Same as forward() method with predict=True.</span>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">param</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">predict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.VAE.save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Save model state dictionary to disk.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="pathlib.Path">Path</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to save the model weights. Parent directories are created if needed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span>
<span class="normal"><a href="#__codelineno-0-502">502</a></span>
<span class="normal"><a href="#__codelineno-0-503">503</a></span>
<span class="normal"><a href="#__codelineno-0-504">504</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-495" name="__codelineno-0-495"></a><span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">):</span>
<a id="__codelineno-0-496" name="__codelineno-0-496"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Save model state dictionary to disk.</span>
<a id="__codelineno-0-497" name="__codelineno-0-497"></a>
<a id="__codelineno-0-498" name="__codelineno-0-498"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-499" name="__codelineno-0-499"></a><span class="sd">        path: Path to save the model weights. Parent directories are created if needed.</span>
<a id="__codelineno-0-500" name="__codelineno-0-500"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-501" name="__codelineno-0-501"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
<a id="__codelineno-0-502" name="__codelineno-0-502"></a>        <span class="n">path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-503" name="__codelineno-0-503"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
<a id="__codelineno-0-504" name="__codelineno-0-504"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Saved model to </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="bnode_core.nn.vae.vae_architecture.VAE.load" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Load model state dictionary from disk.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="pathlib.Path">Path</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to the saved model weights.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.device">device</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device to map the loaded weights to (e.g., 'cpu', 'cuda').</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-506">506</a></span>
<span class="normal"><a href="#__codelineno-0-507">507</a></span>
<span class="normal"><a href="#__codelineno-0-508">508</a></span>
<span class="normal"><a href="#__codelineno-0-509">509</a></span>
<span class="normal"><a href="#__codelineno-0-510">510</a></span>
<span class="normal"><a href="#__codelineno-0-511">511</a></span>
<span class="normal"><a href="#__codelineno-0-512">512</a></span>
<span class="normal"><a href="#__codelineno-0-513">513</a></span>
<span class="normal"><a href="#__codelineno-0-514">514</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-506" name="__codelineno-0-506"></a><span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-507" name="__codelineno-0-507"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Load model state dictionary from disk.</span>
<a id="__codelineno-0-508" name="__codelineno-0-508"></a>
<a id="__codelineno-0-509" name="__codelineno-0-509"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-510" name="__codelineno-0-510"></a><span class="sd">        path: Path to the saved model weights.</span>
<a id="__codelineno-0-511" name="__codelineno-0-511"></a><span class="sd">        device: Device to map the loaded weights to (e.g., &#39;cpu&#39;, &#39;cuda&#39;).</span>
<a id="__codelineno-0-512" name="__codelineno-0-512"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-513" name="__codelineno-0-513"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
<a id="__codelineno-0-514" name="__codelineno-0-514"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">Loaded model from </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="bnode_core.nn.vae.vae_architecture.loss_function" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">loss_function</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mu_hat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">logvar_hat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">,</span> <span class="n">capacity</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute composite loss function for VAE training.</p>
<p>Implements the PELS-VAE loss combining reconstruction, KL divergence, and regressor losses.
Supports two modes:</p>
<ol>
<li>Standard -VAE: loss = mse_loss +  * kl_loss + regressor_loss</li>
<li>Capacity-constrained: loss = mse_loss +  * |kl_loss - capacity| + regressor_loss</li>
</ol>
<p>The regressor loss ensures that the Regressor's predicted latent distribution
matches the Encoder's latent distribution, enabling parameter-to-latent predictions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Original timeseries (normalized), shape (batch, n_channels, seq_len).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>x_hat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Reconstructed timeseries (normalized), shape (batch, n_channels, seq_len).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mu</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Encoder's latent mean, shape (batch, bottleneck_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mu_hat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Regressor's latent mean, shape (batch, bottleneck_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logvar</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Encoder's latent log-variance, shape (batch, bottleneck_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logvar_hat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Regressor's latent log-variance, shape (batch, bottleneck_dim).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>beta</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Weight for KL divergence term (ignored if capacity is not None).</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>gamma</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Weight for capacity constraint term (used only if capacity is not None).</p>
              </div>
            </td>
            <td>
                  <code>1000.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>capacity</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target KL divergence capacity. If None, uses standard -VAE loss.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>reduce</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, return scalar losses. If False, return per-sample losses.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.device">device</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device for tensor operations.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Tuple">Tuple</span>[<span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple of (loss, mse_loss, kl_loss, regressor_loss) where:</p>
<ul>
<li>loss: Total loss (inf if reduce=False)</li>
<li>mse_loss: Mean squared error between x and x_hat</li>
<li>kl_loss: KL divergence KL(N(mu, exp(logvar)) || N(0, I))</li>
<li>regressor_loss: MSE between (mu, logvar) and (mu_hat, logvar_hat)</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="notes" open>
  <summary>Notes</summary>
  <p>The capacity constraint encourages the model to use exactly 'capacity' nats
of information in the latent space, preventing posterior collapse or over-regularization.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-516">516</a></span>
<span class="normal"><a href="#__codelineno-0-517">517</a></span>
<span class="normal"><a href="#__codelineno-0-518">518</a></span>
<span class="normal"><a href="#__codelineno-0-519">519</a></span>
<span class="normal"><a href="#__codelineno-0-520">520</a></span>
<span class="normal"><a href="#__codelineno-0-521">521</a></span>
<span class="normal"><a href="#__codelineno-0-522">522</a></span>
<span class="normal"><a href="#__codelineno-0-523">523</a></span>
<span class="normal"><a href="#__codelineno-0-524">524</a></span>
<span class="normal"><a href="#__codelineno-0-525">525</a></span>
<span class="normal"><a href="#__codelineno-0-526">526</a></span>
<span class="normal"><a href="#__codelineno-0-527">527</a></span>
<span class="normal"><a href="#__codelineno-0-528">528</a></span>
<span class="normal"><a href="#__codelineno-0-529">529</a></span>
<span class="normal"><a href="#__codelineno-0-530">530</a></span>
<span class="normal"><a href="#__codelineno-0-531">531</a></span>
<span class="normal"><a href="#__codelineno-0-532">532</a></span>
<span class="normal"><a href="#__codelineno-0-533">533</a></span>
<span class="normal"><a href="#__codelineno-0-534">534</a></span>
<span class="normal"><a href="#__codelineno-0-535">535</a></span>
<span class="normal"><a href="#__codelineno-0-536">536</a></span>
<span class="normal"><a href="#__codelineno-0-537">537</a></span>
<span class="normal"><a href="#__codelineno-0-538">538</a></span>
<span class="normal"><a href="#__codelineno-0-539">539</a></span>
<span class="normal"><a href="#__codelineno-0-540">540</a></span>
<span class="normal"><a href="#__codelineno-0-541">541</a></span>
<span class="normal"><a href="#__codelineno-0-542">542</a></span>
<span class="normal"><a href="#__codelineno-0-543">543</a></span>
<span class="normal"><a href="#__codelineno-0-544">544</a></span>
<span class="normal"><a href="#__codelineno-0-545">545</a></span>
<span class="normal"><a href="#__codelineno-0-546">546</a></span>
<span class="normal"><a href="#__codelineno-0-547">547</a></span>
<span class="normal"><a href="#__codelineno-0-548">548</a></span>
<span class="normal"><a href="#__codelineno-0-549">549</a></span>
<span class="normal"><a href="#__codelineno-0-550">550</a></span>
<span class="normal"><a href="#__codelineno-0-551">551</a></span>
<span class="normal"><a href="#__codelineno-0-552">552</a></span>
<span class="normal"><a href="#__codelineno-0-553">553</a></span>
<span class="normal"><a href="#__codelineno-0-554">554</a></span>
<span class="normal"><a href="#__codelineno-0-555">555</a></span>
<span class="normal"><a href="#__codelineno-0-556">556</a></span>
<span class="normal"><a href="#__codelineno-0-557">557</a></span>
<span class="normal"><a href="#__codelineno-0-558">558</a></span>
<span class="normal"><a href="#__codelineno-0-559">559</a></span>
<span class="normal"><a href="#__codelineno-0-560">560</a></span>
<span class="normal"><a href="#__codelineno-0-561">561</a></span>
<span class="normal"><a href="#__codelineno-0-562">562</a></span>
<span class="normal"><a href="#__codelineno-0-563">563</a></span>
<span class="normal"><a href="#__codelineno-0-564">564</a></span>
<span class="normal"><a href="#__codelineno-0-565">565</a></span>
<span class="normal"><a href="#__codelineno-0-566">566</a></span>
<span class="normal"><a href="#__codelineno-0-567">567</a></span>
<span class="normal"><a href="#__codelineno-0-568">568</a></span>
<span class="normal"><a href="#__codelineno-0-569">569</a></span>
<span class="normal"><a href="#__codelineno-0-570">570</a></span>
<span class="normal"><a href="#__codelineno-0-571">571</a></span>
<span class="normal"><a href="#__codelineno-0-572">572</a></span>
<span class="normal"><a href="#__codelineno-0-573">573</a></span>
<span class="normal"><a href="#__codelineno-0-574">574</a></span>
<span class="normal"><a href="#__codelineno-0-575">575</a></span>
<span class="normal"><a href="#__codelineno-0-576">576</a></span>
<span class="normal"><a href="#__codelineno-0-577">577</a></span>
<span class="normal"><a href="#__codelineno-0-578">578</a></span>
<span class="normal"><a href="#__codelineno-0-579">579</a></span>
<span class="normal"><a href="#__codelineno-0-580">580</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-516" name="__codelineno-0-516"></a><span class="k">def</span><span class="w"> </span><span class="nf">loss_function</span><span class="p">(</span>
<a id="__codelineno-0-517" name="__codelineno-0-517"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-518" name="__codelineno-0-518"></a>    <span class="n">x_hat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-519" name="__codelineno-0-519"></a>    <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-520" name="__codelineno-0-520"></a>    <span class="n">mu_hat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-521" name="__codelineno-0-521"></a>    <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
<a id="__codelineno-0-522" name="__codelineno-0-522"></a>    <span class="n">logvar_hat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-523" name="__codelineno-0-523"></a>    <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> 
<a id="__codelineno-0-524" name="__codelineno-0-524"></a>    <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">,</span> 
<a id="__codelineno-0-525" name="__codelineno-0-525"></a>    <span class="n">capacity</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-526" name="__codelineno-0-526"></a>    <span class="n">reduce</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-527" name="__codelineno-0-527"></a>    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-528" name="__codelineno-0-528"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-529" name="__codelineno-0-529"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute composite loss function for VAE training.</span>
<a id="__codelineno-0-530" name="__codelineno-0-530"></a>
<a id="__codelineno-0-531" name="__codelineno-0-531"></a><span class="sd">    Implements the PELS-VAE loss combining reconstruction, KL divergence, and regressor losses.</span>
<a id="__codelineno-0-532" name="__codelineno-0-532"></a><span class="sd">    Supports two modes:</span>
<a id="__codelineno-0-533" name="__codelineno-0-533"></a>
<a id="__codelineno-0-534" name="__codelineno-0-534"></a><span class="sd">    1. Standard -VAE: loss = mse_loss +  * kl_loss + regressor_loss</span>
<a id="__codelineno-0-535" name="__codelineno-0-535"></a><span class="sd">    2. Capacity-constrained: loss = mse_loss +  * |kl_loss - capacity| + regressor_loss</span>
<a id="__codelineno-0-536" name="__codelineno-0-536"></a>
<a id="__codelineno-0-537" name="__codelineno-0-537"></a><span class="sd">    The regressor loss ensures that the Regressor&#39;s predicted latent distribution</span>
<a id="__codelineno-0-538" name="__codelineno-0-538"></a><span class="sd">    matches the Encoder&#39;s latent distribution, enabling parameter-to-latent predictions.</span>
<a id="__codelineno-0-539" name="__codelineno-0-539"></a>
<a id="__codelineno-0-540" name="__codelineno-0-540"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-541" name="__codelineno-0-541"></a><span class="sd">        x: Original timeseries (normalized), shape (batch, n_channels, seq_len).</span>
<a id="__codelineno-0-542" name="__codelineno-0-542"></a><span class="sd">        x_hat: Reconstructed timeseries (normalized), shape (batch, n_channels, seq_len).</span>
<a id="__codelineno-0-543" name="__codelineno-0-543"></a><span class="sd">        mu: Encoder&#39;s latent mean, shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-544" name="__codelineno-0-544"></a><span class="sd">        mu_hat: Regressor&#39;s latent mean, shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-545" name="__codelineno-0-545"></a><span class="sd">        logvar: Encoder&#39;s latent log-variance, shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-546" name="__codelineno-0-546"></a><span class="sd">        logvar_hat: Regressor&#39;s latent log-variance, shape (batch, bottleneck_dim).</span>
<a id="__codelineno-0-547" name="__codelineno-0-547"></a><span class="sd">        beta: Weight for KL divergence term (ignored if capacity is not None).</span>
<a id="__codelineno-0-548" name="__codelineno-0-548"></a><span class="sd">        gamma: Weight for capacity constraint term (used only if capacity is not None).</span>
<a id="__codelineno-0-549" name="__codelineno-0-549"></a><span class="sd">        capacity: Target KL divergence capacity. If None, uses standard -VAE loss.</span>
<a id="__codelineno-0-550" name="__codelineno-0-550"></a><span class="sd">        reduce: If True, return scalar losses. If False, return per-sample losses.</span>
<a id="__codelineno-0-551" name="__codelineno-0-551"></a><span class="sd">        device: Device for tensor operations.</span>
<a id="__codelineno-0-552" name="__codelineno-0-552"></a>
<a id="__codelineno-0-553" name="__codelineno-0-553"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-554" name="__codelineno-0-554"></a><span class="sd">        Tuple of (loss, mse_loss, kl_loss, regressor_loss) where:</span>
<a id="__codelineno-0-555" name="__codelineno-0-555"></a>
<a id="__codelineno-0-556" name="__codelineno-0-556"></a><span class="sd">            - loss: Total loss (inf if reduce=False)</span>
<a id="__codelineno-0-557" name="__codelineno-0-557"></a><span class="sd">            - mse_loss: Mean squared error between x and x_hat</span>
<a id="__codelineno-0-558" name="__codelineno-0-558"></a><span class="sd">            - kl_loss: KL divergence KL(N(mu, exp(logvar)) || N(0, I))</span>
<a id="__codelineno-0-559" name="__codelineno-0-559"></a><span class="sd">            - regressor_loss: MSE between (mu, logvar) and (mu_hat, logvar_hat)</span>
<a id="__codelineno-0-560" name="__codelineno-0-560"></a>
<a id="__codelineno-0-561" name="__codelineno-0-561"></a><span class="sd">    Notes:</span>
<a id="__codelineno-0-562" name="__codelineno-0-562"></a><span class="sd">        The capacity constraint encourages the model to use exactly &#39;capacity&#39; nats</span>
<a id="__codelineno-0-563" name="__codelineno-0-563"></a><span class="sd">        of information in the latent space, preventing posterior collapse or over-regularization.</span>
<a id="__codelineno-0-564" name="__codelineno-0-564"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-565" name="__codelineno-0-565"></a>    <span class="n">mse</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span> <span class="k">if</span> <span class="n">reduce</span> <span class="k">else</span> <span class="s1">&#39;none&#39;</span><span class="p">)</span>
<a id="__codelineno-0-566" name="__codelineno-0-566"></a>    <span class="n">mse_loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-567" name="__codelineno-0-567"></a>    <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">kullback_leibler</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">,</span> <span class="n">per_dimension</span><span class="o">=</span><span class="ow">not</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="n">reduce</span><span class="p">)</span>
<a id="__codelineno-0-568" name="__codelineno-0-568"></a>    <span class="n">regressor_loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">mu_hat</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span> <span class="o">+</span> <span class="n">mse</span><span class="p">(</span><span class="n">logvar_hat</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
<a id="__codelineno-0-569" name="__codelineno-0-569"></a>    <span class="k">if</span> <span class="n">reduce</span><span class="p">:</span>
<a id="__codelineno-0-570" name="__codelineno-0-570"></a>        <span class="k">if</span> <span class="n">capacity</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-571" name="__codelineno-0-571"></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">mse_loss</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">kl_loss</span> <span class="o">+</span> <span class="n">regressor_loss</span>
<a id="__codelineno-0-572" name="__codelineno-0-572"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-573" name="__codelineno-0-573"></a>            <span class="k">if</span> <span class="n">capacity</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-574" name="__codelineno-0-574"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;capacity must be positive&#39;</span><span class="p">)</span>
<a id="__codelineno-0-575" name="__codelineno-0-575"></a>            <span class="c1"># kl_loss is always positive, so subtracting capacity and </span>
<a id="__codelineno-0-576" name="__codelineno-0-576"></a>            <span class="c1"># taking the absolute value sets a capacity</span>
<a id="__codelineno-0-577" name="__codelineno-0-577"></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">mse_loss</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">kl_loss</span> <span class="o">-</span> <span class="n">capacity</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">+</span> <span class="n">regressor_loss</span>
<a id="__codelineno-0-578" name="__codelineno-0-578"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-579" name="__codelineno-0-579"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-580" name="__codelineno-0-580"></a>    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">mse_loss</span><span class="p">,</span> <span class="n">kl_loss</span><span class="p">,</span> <span class="n">regressor_loss</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="bnode_core.nn.vae.vae_train_test" class="doc doc-heading">
            <code>bnode_core.nn.vae.vae_train_test</code>


</h2>

    <div class="doc doc-contents first">

        <p>VAE training and testing pipeline for timeseries modeling.</p>
<p>This module implements the complete training pipeline for Variational Autoencoders (VAE)
with parameter conditioning, supporting standard VAE, PELS-VAE, and feed-forward modes.</p>


<details class="attention" open>
  <summary>Attention</summary>
  <p>This documentation is AI generated. Be aware of possible inaccuricies.</p>
</details>        <h5 id="bnode_core.nn.vae.vae_train_test--command-line-usage">Command-line Usage</h5>
<p>The module uses Hydra for configuration management and MLflow for experiment tracking.
Training is launched via the command line:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>uv<span class="w"> </span>run<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>bnode_core.nn.vae.vae_train_test
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>uv<span class="w"> </span>run<span class="w"> </span>&lt;path<span class="w"> </span>to<span class="w"> </span>vae_train_test.py&gt;
</code></pre></div>
<p>Configuration files are loaded from <code>conf/train_test_vae.yaml</code> (or specified config path).</p>
<h5 id="bnode_core.nn.vae.vae_train_test--configuration">Configuration</h5>
<p>Key configuration parameters (via Hydra config):</p>
<ul>
<li><code>dataset_name</code>: Name of HDF5 dataset to load</li>
<li><code>use_cuda</code>: Enable CUDA acceleration</li>
<li><code>use_amp</code>: Enable automatic mixed precision training</li>
<li><code>nn_model.network.*</code>: Model architecture parameters (hidden_dim, n_latent, activation, etc.)</li>
<li><code>nn_model.training.*</code>: Training hyperparameters (batch_size, lr, max_epochs, etc.)</li>
</ul>
<h5 id="bnode_core.nn.vae.vae_train_test--training-workflow">Training Workflow</h5>
<ol>
<li>Load HDF5 dataset and create train/validation/test/common_test dataloaders</li>
<li>Initialize VAE model with specified architecture</li>
<li>Initialize normalization layers on full training dataset</li>
<li>
<p>Train with:</p>
</li>
<li>
<p>Adam optimizer with learning rate scheduling (ReduceLROnPlateau)</p>
</li>
<li>Early stopping monitoring validation loss</li>
<li>Capacity scheduling for controlled KL divergence growth</li>
<li>Automatic mixed precision (AMP) support</li>
<li>Gradient clipping for stability</li>
<li>Save best model checkpoint based on validation loss</li>
<li>Evaluate on all dataset splits and save predictions to HDF5 file</li>
<li>Log all metrics and artifacts to MLflow</li>
</ol>
<h5 id="bnode_core.nn.vae.vae_train_test--output-files">Output Files</h5>
<ul>
<li><code>model.pth</code>: Best model checkpoint (state_dict)</li>
<li><code>dataset_with_predictions.h5</code>: Copy of input dataset with added model predictions</li>
<li><code>vae_train_test.py</code>, <code>vae_architecture.py</code>: Copies of source files for reproducibility</li>
</ul>
<h5 id="bnode_core.nn.vae.vae_train_test--key-features">Key Features</h5>
<ul>
<li><strong>Multi-pass prediction</strong>: Average multiple stochastic forward passes for robust predictions</li>
<li><strong>Capacity scheduling</strong>: Gradually increase KL divergence capacity to prevent posterior collapse</li>
<li><strong>Early stopping</strong>: Monitor validation loss with configurable patience and threshold</li>
<li><strong>MLflow integration</strong>: Automatic logging of metrics, parameters, and artifacts via decorator</li>
<li><strong>Reproducibility</strong>: Saves source code and full configuration to output directory</li>
</ul>










<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="bnode_core.nn.vae.vae_train_test.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">(</span><span class="n">cfg</span><span class="p">:</span> <span class="n">train_test_config_class</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Train VAE model on timeseries dataset with MLflow tracking.</p>
<p>Complete training pipeline including:</p>
<ul>
<li>Dataset loading and preprocessing</li>
<li>Model initialization and normalization layer setup</li>
<li>Training loop with early stopping and capacity scheduling</li>
<li>Evaluation on all dataset splits</li>
<li>Model checkpoint saving and artifact logging</li>
</ul>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>cfg</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="train_test_config_class (bnode_core.config.train_test_config_class)" href="../../config/#bnode_core.config.train_test_config_class">train_test_config_class</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hydra configuration object containing all training parameters.
Key sections: dataset_name, use_cuda, use_amp, nn_model.network, nn_model.training</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Final MSE loss on test set (float).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="notes" open>
  <summary>Notes</summary>
  <ul>
<li>Uses @log_hydra_to_mlflow decorator for automatic MLflow experiment tracking</li>
<li>Saves best model based on validation loss</li>
<li>Copies dataset to output directory with added model predictions</li>
<li>Logs metrics at each epoch: loss, mse_loss, kl_loss, regressor_loss, populated_dims</li>
</ul>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_train_test.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span>
<span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="nd">@log_hydra_to_mlflow</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">cfg</span><span class="p">:</span> <span class="n">train_test_config_class</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Train VAE model on timeseries dataset with MLflow tracking.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">    Complete training pipeline including:</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">    - Dataset loading and preprocessing</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">    - Model initialization and normalization layer setup</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    - Training loop with early stopping and capacity scheduling</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">    - Evaluation on all dataset splits</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">    - Model checkpoint saving and artifact logging</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">        cfg: Hydra configuration object containing all training parameters.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">            Key sections: dataset_name, use_cuda, use_amp, nn_model.network, nn_model.training</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        Final MSE loss on test set (float).</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">    Notes:</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">        - Uses @log_hydra_to_mlflow decorator for automatic MLflow experiment tracking</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">        - Saves best model based on validation loss</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">        - Copies dataset to output directory with added model predictions</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">        - Logs metrics at each epoch: loss, mse_loss, kl_loss, regressor_loss, populated_dims</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_cuda</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="c1"># load dataset and config</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_config</span> <span class="o">=</span> <span class="n">load_dataset_and_config</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">)</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="c1"># make train and test torch tensor datasets</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">make_stacked_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">make_stacked_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">)</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">make_stacked_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">)</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="n">common_test_dataset</span> <span class="o">=</span> <span class="n">make_stacked_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;common_test&#39;</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="c1"># initialize data loaders</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="n">common_test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">common_test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>    <span class="c1"># initialize model</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>    <span class="n">model</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="n">n_states</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;states&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="n">n_outputs</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;outputs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="n">seq_len</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;states&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="n">parameter_dim</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="n">hidden_dim</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">linear_hidden_dim</span><span class="p">,</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="n">bottleneck_dim</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">n_latent</span><span class="p">,</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="n">activation</span><span class="o">=</span><span class="nb">eval</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">activation</span><span class="p">),</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="n">n_layers</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">n_linear_layers</span><span class="p">,</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="n">params_to_decoder</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">params_to_decoder</span><span class="p">,</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="n">feed_forward_nn</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">feed_forward_nn</span><span class="p">,</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="p">)</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="c1"># initialize timeseries_normalization layer on whole dataset</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>    <span class="n">_states</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;states&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="n">_outputs</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;outputs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="n">_parameters</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="n">_x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">_states</span><span class="p">,</span> <span class="n">_outputs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>    <span class="n">model</span><span class="o">.</span><span class="n">timeseries_normalization</span><span class="o">.</span><span class="n">initialize_normalization</span><span class="p">(</span><span class="n">_x</span><span class="p">)</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>    <span class="n">model</span><span class="o">.</span><span class="n">Regressor</span><span class="o">.</span><span class="n">normalization</span><span class="p">(</span><span class="n">_parameters</span><span class="p">)</span> <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">False</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>    <span class="k">del</span> <span class="n">_states</span><span class="p">,</span> <span class="n">_outputs</span><span class="p">,</span> <span class="n">_parameters</span><span class="p">,</span> <span class="n">_x</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Initialized timeseries_normalization layer on whole dataset&#39;</span><span class="p">)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Initialized Regressor normalization layer on whole dataset&#39;</span><span class="p">)</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>    <span class="c1"># initialize optimizer</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_start</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>    <span class="c1">#optimizer = torch.optim.SGD(model.parameters(), lr=cfg.nn_model.training.lr_start)</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="c1"># initialize lr scheduler</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>                                                            <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>                                                            <span class="n">factor</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_scheduler_plateau_gamma</span><span class="p">,</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>                                                            <span class="n">patience</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_scheduler_plateau_patience</span><span class="p">,</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>                                                            <span class="n">threshold</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_scheduler_threshold</span><span class="p">,</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>                                                            <span class="n">threshold_mode</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_scheduler_threshold_mode</span><span class="p">,</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>                                                            <span class="n">min_lr</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_min</span><span class="p">,</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>                                                            <span class="p">)</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="c1"># initialize early stopping</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">early_stopping_patience</span><span class="p">,</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>                                      <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>                                      <span class="n">threshold</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">early_stopping_threshold</span><span class="p">,</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>                                      <span class="n">threshold_mode</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">early_stopping_threshold_mode</span><span class="p">,</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>                                      <span class="n">path</span><span class="o">=</span><span class="n">filepaths</span><span class="o">.</span><span class="n">filepath_model_current_hydra_output</span><span class="p">(),</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>                                      <span class="n">trace_func</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">)</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="c1"># initialize capacity scheduler</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="n">capacity_scheduler</span> <span class="o">=</span> <span class="n">CapacityScheduler</span><span class="p">(</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="n">patience</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">capacity_patience</span><span class="p">,</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="n">capacity_start</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">capacity_start</span><span class="p">,</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="n">capacity_max</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">capacity_max</span><span class="p">,</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="n">capacity_increment</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">capacity_increment</span><span class="p">,</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>        <span class="n">capacity_increment_mode</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">capacity_increment_mode</span><span class="p">,</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="n">threshold</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">capacity_threshold</span><span class="p">,</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="n">threshold_mode</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">capacity_threshold_mode</span><span class="p">,</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>        <span class="n">trace_func</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">,</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>        <span class="n">enabled</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_capacity</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>    <span class="p">)</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>    <span class="c1"># initialize gradient scaler</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>    <span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">GradScaler</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_amp</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Training with automatic mixed precision: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_amp</span><span class="p">))</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="c1"># define one model and loss evaluation</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">model_and_loss_evaluation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_passes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">return_model_outputs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">test_from_regressor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate model forward pass and compute all loss components.</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a><span class="sd">            model: VAE model instance.</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">            states: State timeseries tensor, shape (batch, n_states, seq_len).</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">            outputs: Output timeseries tensor, shape (batch, n_outputs, seq_len).</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="sd">            parameters: System parameters tensor, shape (batch, parameter_dim).</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a><span class="sd">            train: If True, use Encoder&#39;s latent distribution. If False, controlled by test_from_regressor.</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">            n_passes: Number of stochastic forward passes to average.</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a><span class="sd">            return_model_outputs: If True, return model outputs (predictions, latent variables, raw losses).</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a><span class="sd">            test_from_regressor: If True during testing, use Regressor&#39;s latent distribution instead of Encoder&#39;s.</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a><span class="sd">            Dictionary with keys: loss, mse_loss, kl_loss, regressor_loss, populated_dims.</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a><span class="sd">            If return_model_outputs=True, returns tuple (ret_val, model_outputs) where model_outputs</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a><span class="sd">            contains: mse_loss_raw, kl_loss_raw, regressor_loss_raw, states_hat, outputs_hat, </span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a><span class="sd">            mu, logvar, mu_hat, logvar_hat.</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>        <span class="n">_train</span> <span class="o">=</span> <span class="n">train</span> <span class="k">if</span> <span class="n">train</span> <span class="ow">is</span> <span class="kc">True</span> <span class="k">else</span> <span class="n">test_from_regressor</span> <span class="c1"># if not training, do the test with either mu, logvar from regressor or from encoder</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">states_hat</span><span class="p">,</span> <span class="n">outputs_hat</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">,</span> <span class="n">mu_hat</span><span class="p">,</span> <span class="n">logvar_hat</span><span class="p">,</span> <span class="n">normed_values</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">_train</span><span class="p">,</span> 
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>                                                                                                 <span class="n">predict</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="n">n_passes</span><span class="p">,</span> 
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>                                                                                                 <span class="n">test_with_zero_eps</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">test_with_zero_eps</span><span class="p">,</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>                                                                                                 <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>        <span class="n">loss</span><span class="p">,</span> <span class="n">mse_loss</span><span class="p">,</span> <span class="n">kl_loss</span><span class="p">,</span> <span class="n">regressor_loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>                    <span class="n">normed_values</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">normed_values</span><span class="p">[</span><span class="s1">&#39;x_hat&#39;</span><span class="p">],</span> <span class="n">mu</span><span class="p">,</span> <span class="n">mu_hat</span><span class="p">,</span> 
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>                    <span class="n">logvar</span><span class="p">,</span> <span class="n">logvar_hat</span><span class="p">,</span> 
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>                    <span class="n">beta</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">beta_start</span><span class="p">,</span> 
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>                    <span class="n">gamma</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>                    <span class="n">capacity</span><span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_capacity</span> <span class="ow">is</span> <span class="kc">False</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>                        <span class="k">else</span> <span class="n">capacity_scheduler</span><span class="o">.</span><span class="n">get_capacity</span><span class="p">(),</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>                    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>        <span class="p">)</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>        <span class="n">_populated_dimensions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">count_populated_dimensions</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">count_populated_dimensions_threshold</span><span class="p">)</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>        <span class="n">ret_val</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>            <span class="s1">&#39;mse_loss&#39;</span><span class="p">:</span> <span class="n">mse_loss</span><span class="p">,</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>            <span class="s1">&#39;kl_loss&#39;</span><span class="p">:</span> <span class="n">kl_loss</span><span class="p">,</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>            <span class="s1">&#39;regressor_loss&#39;</span><span class="p">:</span> <span class="n">regressor_loss</span><span class="p">,</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>            <span class="s1">&#39;populated_dims&#39;</span><span class="p">:</span> <span class="n">_populated_dimensions</span><span class="p">,</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>        <span class="p">}</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>        <span class="k">if</span> <span class="n">return_model_outputs</span><span class="p">:</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>            <span class="c1"># losses per dim</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>            <span class="n">_</span><span class="p">,</span> <span class="n">mse_loss_raw</span><span class="p">,</span> <span class="n">kl_loss_raw</span><span class="p">,</span> <span class="n">regressor_loss_raw</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>                    <span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">mu_hat</span><span class="p">,</span> 
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>                    <span class="n">logvar</span><span class="p">,</span> <span class="n">logvar_hat</span><span class="p">,</span> 
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>                    <span class="n">beta</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">beta_start</span><span class="p">,</span> 
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>                    <span class="n">gamma</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>                    <span class="n">capacity</span><span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>                    <span class="n">reduce</span><span class="o">=</span><span class="kc">False</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>                    <span class="p">)</span>   
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>            <span class="n">model_outputs</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>                <span class="s1">&#39;mse_loss_raw&#39;</span><span class="p">:</span> <span class="n">mse_loss_raw</span><span class="p">,</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>                <span class="s1">&#39;kl_loss_raw&#39;</span><span class="p">:</span> <span class="n">kl_loss_raw</span><span class="p">,</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>                <span class="s1">&#39;regressor_loss_raw&#39;</span><span class="p">:</span> <span class="n">regressor_loss_raw</span><span class="p">,</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>                <span class="s1">&#39;states_hat&#39;</span><span class="p">:</span> <span class="n">states_hat</span><span class="p">,</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>                <span class="s1">&#39;outputs_hat&#39;</span><span class="p">:</span> <span class="n">outputs_hat</span><span class="p">,</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>                <span class="s1">&#39;mu&#39;</span><span class="p">:</span> <span class="n">mu</span><span class="p">,</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>                <span class="s1">&#39;logvar&#39;</span><span class="p">:</span> <span class="n">logvar</span><span class="p">,</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>                <span class="s1">&#39;mu_hat&#39;</span><span class="p">:</span> <span class="n">mu_hat</span><span class="p">,</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>                <span class="s1">&#39;logvar_hat&#39;</span><span class="p">:</span> <span class="n">logvar_hat</span><span class="p">,</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>            <span class="p">}</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">train</span><span class="p">:</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>            <span class="c1"># call value.item() for each value in return_value</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>            <span class="n">ret_val</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">({</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">ret_val</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>            <span class="k">if</span> <span class="n">return_model_outputs</span><span class="p">:</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>                <span class="n">model_outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">({</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">model_outputs</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>        <span class="k">return</span> <span class="n">ret_val</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">return_model_outputs</span> <span class="k">else</span> <span class="p">(</span><span class="n">ret_val</span><span class="p">,</span> <span class="n">model_outputs</span><span class="p">)</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_model_inputs</span><span class="p">(</span><span class="n">data_loader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract model inputs from data loader or data dictionary.</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a><span class="sd">            data_loader: PyTorch DataLoader (if provided, fetches next batch).</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a><span class="sd">            data: Dictionary with keys &#39;states&#39;, &#39;outputs&#39;, &#39;parameters&#39; (alternative to data_loader).</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="sd">            Tuple of (states, outputs, parameters) tensors moved to device.</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a>        <span class="k">if</span> <span class="n">data_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a>            <span class="k">assert</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Either data_loader or data must be not None&#39;</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>            <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">))</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a>        <span class="c1"># get data from data loader</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>        <span class="n">states</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;states&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;outputs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a>        <span class="n">parameters</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a>        <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">parameters</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>    <span class="c1"># define train loop for one epoch</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute one training epoch with gradient updates.</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">        Iterates through all batches in train_loader, computes losses, performs</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="sd">        backpropagation with gradient clipping and AMP scaling.</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a><span class="sd">            model: VAE model instance.</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a><span class="sd">            train_loader: PyTorch DataLoader for training data.</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="sd">            optimizer: PyTorch optimizer.</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="sd">            scaler: CUDA AMP gradient scaler.</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="sd">            epoch: Current epoch number (for logging).</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a><span class="sd">            Dictionary with training metrics: loss, mse_loss, kl_loss, regressor_loss, populated_dims.</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>        <span class="c1"># get data from train loader</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a>        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a>        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a>            <span class="c1"># get data from data loader</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a>            <span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">get_model_inputs</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a>            <span class="c1"># zero the parameter gradients</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a>            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a>            <span class="c1"># forward + backward + optimize</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_amp</span><span class="p">):</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a>                <span class="n">ret_vals_train</span> <span class="o">=</span> <span class="n">model_and_loss_evaluation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">n_passes_train</span><span class="p">,</span> <span class="n">test_from_regressor</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">test_from_regressor</span><span class="p">)</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">ret_vals_train</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">False</span> <span class="k">else</span> <span class="n">ret_vals_train</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">]</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a>            <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a>            <span class="n">scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">clip_grad_norm</span><span class="p">)</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>            <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>            <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>        <span class="c1"># call value.item() for each value in return_value</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>        <span class="n">ret_vals_train</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">({</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">ret_vals_train</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>        <span class="k">return</span> <span class="n">ret_vals_train</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">test_or_validate_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">_data_loader</span><span class="p">,</span> <span class="n">n_passes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">all_batches</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>                                   <span class="n">return_model_outputs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate model on validation or test set without gradient computation.</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a><span class="sd">            model: VAE model instance.</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a><span class="sd">            _data_loader: PyTorch DataLoader for evaluation data.</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a><span class="sd">            n_passes: Number of stochastic forward passes to average.</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a><span class="sd">            all_batches: If True, evaluate on all batches and average metrics. If False, evaluate only first batch.</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a><span class="sd">            return_model_outputs: If True, return model predictions and latent variables.</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a><span class="sd">            Dictionary with evaluation metrics: loss, mse_loss, kl_loss, regressor_loss, populated_dims.</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a><span class="sd">            If return_model_outputs=True, returns tuple (ret_vals, model_outputs) where model_outputs</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a><span class="sd">            contains predictions and latent variables for all evaluated batches.</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>        <span class="c1"># make sure that the data loader is not shuffled by initializing a new data loader</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>        <span class="k">if</span> <span class="n">all_batches</span><span class="p">:</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>            <span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">_data_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">_data_loader</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>            <span class="n">data_loader</span> <span class="o">=</span> <span class="n">_data_loader</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>        <span class="n">_ret_vals</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>        <span class="n">_model_outputs</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>        <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>            <span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">get_model_inputs</span><span class="p">(</span><span class="n">data_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>            <span class="c1"># forward</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a>            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>                <span class="n">ret_vals</span><span class="p">,</span> <span class="n">model_outputs</span> <span class="o">=</span> <span class="n">model_and_loss_evaluation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="n">n_passes</span><span class="p">,</span> <span class="n">return_model_outputs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">test_from_regressor</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">test_from_regressor</span><span class="p">)</span>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>            <span class="n">_ret_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ret_vals</span><span class="p">)</span>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a>            <span class="n">_model_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_outputs</span><span class="p">)</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a>            <span class="k">if</span> <span class="n">all_batches</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a>                <span class="k">break</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>        <span class="c1"># average over all calls</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>        <span class="k">if</span> <span class="n">all_batches</span><span class="p">:</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>            <span class="n">ret_vals</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">_ret_vals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>                <span class="n">ret_vals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">_ret_val</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">_ret_val</span> <span class="ow">in</span> <span class="n">_ret_vals</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">_ret_vals</span><span class="p">)</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>            <span class="n">ret_vals</span> <span class="o">=</span> <span class="n">_ret_vals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a>        <span class="c1"># make one tensor from all model outputs</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a>        <span class="k">if</span> <span class="n">return_model_outputs</span><span class="p">:</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a>            <span class="n">model_outputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">_batch_output</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">_batch_output</span> <span class="ow">in</span> <span class="n">_model_outputs</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">_model_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>        <span class="k">return</span> <span class="n">ret_vals</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">return_model_outputs</span> <span class="k">else</span> <span class="p">(</span><span class="n">ret_vals</span><span class="p">,</span> <span class="n">model_outputs</span><span class="p">)</span>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">append_context_to_dict_keys</span><span class="p">(</span><span class="n">dictionary</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Add context suffix to all dictionary keys for MLflow logging.</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a><span class="sd">            dictionary: Dictionary with metric names as keys.</span>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a><span class="sd">            context: Suffix to append (e.g., &#39;train&#39;, &#39;validation&#39;, &#39;test&#39;).</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="sd">            New dictionary with keys formatted as &#39;original_key_context&#39;.</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a>        <span class="k">return</span> <span class="nb">dict</span><span class="p">({</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>    <span class="c1"># training loop</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a>    <span class="n">_flag_break_next_epoch</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">):</span>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>        <span class="c1"># train one epoch</span>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">_flag_break_next_epoch</span><span class="p">:</span>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a>            <span class="n">ret_vals_train</span> <span class="o">=</span> <span class="n">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a>            <span class="n">ret_vals_train</span> <span class="o">=</span> <span class="n">test_or_validate_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">n_passes_test</span><span class="p">)</span>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a>        <span class="c1"># validate one epoch</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a>        <span class="n">ret_vals_validation</span> <span class="o">=</span> <span class="n">test_or_validate_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">n_passes_test</span><span class="p">)</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a>        <span class="c1"># test one epoch</span>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a>        <span class="n">ret_vals_test</span> <span class="o">=</span> <span class="n">test_or_validate_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">n_passes_test</span><span class="p">)</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a>        <span class="c1"># lr scheduler step</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">_flag_break_next_epoch</span><span class="p">:</span>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a>            <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">False</span> <span class="k">else</span> <span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">])</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a>        <span class="c1"># early stopping</span>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a>            <span class="n">early_stopping</span><span class="p">(</span><span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">feed_forward_nn</span> <span class="ow">is</span> <span class="kc">False</span> <span class="k">else</span> <span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">],</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>                           <span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">corresponding_loss</span> <span class="o">=</span> <span class="n">ret_vals_train</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a>        <span class="c1"># capacity scheduler</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a>        <span class="n">capacity_scheduler</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">])</span>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a>        <span class="c1"># log stats with logging</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a>        <span class="n">string</span> <span class="o">=</span> <span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> | train/validate/test: </span><span class="si">{:.4f}</span><span class="s1">/</span><span class="si">{:.4f}</span><span class="s1">/</span><span class="si">{:.4f}</span><span class="s1"> | mse: </span><span class="si">{:.4f}</span><span class="s1">/</span><span class="si">{:.4f}</span><span class="s1">/</span><span class="si">{:.4f}</span><span class="s1"> | kl_loss: </span><span class="si">{:.4f}</span><span class="s1">/</span><span class="si">{:.4f}</span><span class="s1">/</span><span class="si">{:.4f}</span><span class="s1"> | regressor_loss: </span><span class="si">{:.4f}</span><span class="s1">/</span><span class="si">{:.4f}</span><span class="s1">/</span><span class="si">{:.4f}</span><span class="s1"> | pop. dim: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> | </span><span class="se">\</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a><span class="s1">            </span><span class="se">\t\t\t</span><span class="s1">| batches: </span><span class="si">{}</span><span class="s1"> | lr: </span><span class="si">{:.6f}</span><span class="s1"> |&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a>            <span class="n">epoch</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">,</span>
<a id="__codelineno-0-399" name="__codelineno-0-399"></a>            <span class="n">ret_vals_train</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">ret_vals_test</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a>            <span class="n">ret_vals_train</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">],</span> <span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">],</span> <span class="n">ret_vals_test</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">],</span>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a>            <span class="n">ret_vals_train</span><span class="p">[</span><span class="s1">&#39;kl_loss&#39;</span><span class="p">],</span> <span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;kl_loss&#39;</span><span class="p">],</span> <span class="n">ret_vals_test</span><span class="p">[</span><span class="s1">&#39;kl_loss&#39;</span><span class="p">],</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a>            <span class="n">ret_vals_train</span><span class="p">[</span><span class="s1">&#39;regressor_loss&#39;</span><span class="p">],</span> <span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;regressor_loss&#39;</span><span class="p">],</span> <span class="n">ret_vals_test</span><span class="p">[</span><span class="s1">&#39;regressor_loss&#39;</span><span class="p">],</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>            <span class="n">ret_vals_train</span><span class="p">[</span><span class="s1">&#39;populated_dims&#39;</span><span class="p">],</span> <span class="n">ret_vals_validation</span><span class="p">[</span><span class="s1">&#39;populated_dims&#39;</span><span class="p">],</span> <span class="n">ret_vals_test</span><span class="p">[</span><span class="s1">&#39;populated_dims&#39;</span><span class="p">],</span>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a>            <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a>            <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a>        <span class="n">string</span> <span class="o">=</span> <span class="n">string</span> <span class="o">+</span> <span class="s1">&#39; capacity: </span><span class="si">{:.4f}</span><span class="s1"> |&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">capacity_scheduler</span><span class="o">.</span><span class="n">get_capacity</span><span class="p">())</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_capacity</span> <span class="k">else</span> <span class="n">string</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a>        <span class="n">string</span> <span class="o">=</span> <span class="n">string</span> <span class="o">+</span> <span class="s1">&#39; EarlyStopping: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> |&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">early_stopping</span><span class="o">.</span><span class="n">counter</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">.</span><span class="n">patience</span><span class="p">)</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">string</span><span class="p">)</span>
<a id="__codelineno-0-409" name="__codelineno-0-409"></a>        <span class="c1"># log stats with mlflow</span>
<a id="__codelineno-0-410" name="__codelineno-0-410"></a>        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">append_context_to_dict_keys</span><span class="p">(</span><span class="n">ret_vals_train</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="p">)</span>
<a id="__codelineno-0-411" name="__codelineno-0-411"></a>        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">append_context_to_dict_keys</span><span class="p">(</span><span class="n">ret_vals_validation</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-412" name="__codelineno-0-412"></a>        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">append_context_to_dict_keys</span><span class="p">(</span><span class="n">ret_vals_test</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-413" name="__codelineno-0-413"></a>        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">],</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-414" name="__codelineno-0-414"></a>        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;EarlyStopping_counter&#39;</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">.</span><span class="n">counter</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-415" name="__codelineno-0-415"></a>        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;capacity&#39;</span><span class="p">,</span> <span class="n">capacity_scheduler</span><span class="o">.</span><span class="n">get_capacity</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_capacity</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-416" name="__codelineno-0-416"></a>
<a id="__codelineno-0-417" name="__codelineno-0-417"></a>        <span class="c1"># check early stopping</span>
<a id="__codelineno-0-418" name="__codelineno-0-418"></a>        <span class="k">if</span> <span class="n">early_stopping</span><span class="o">.</span><span class="n">early_stop</span><span class="p">:</span>
<a id="__codelineno-0-419" name="__codelineno-0-419"></a>            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Early stopping&quot;</span><span class="p">)</span>
<a id="__codelineno-0-420" name="__codelineno-0-420"></a>            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s1">&#39;ended_by&#39;</span><span class="p">,</span> <span class="s1">&#39;early_stopping&#39;</span><span class="p">)</span>
<a id="__codelineno-0-421" name="__codelineno-0-421"></a>            <span class="c1"># let the evaluation run one more time to record the outputs of the best model</span>
<a id="__codelineno-0-422" name="__codelineno-0-422"></a>            <span class="n">_flag_break_next_epoch</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-423" name="__codelineno-0-423"></a>            <span class="c1"># load the best model</span>
<a id="__codelineno-0-424" name="__codelineno-0-424"></a>            <span class="n">model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filepaths</span><span class="o">.</span><span class="n">filepath_model_current_hydra_output</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-425" name="__codelineno-0-425"></a>        <span class="k">if</span> <span class="n">_flag_break_next_epoch</span><span class="p">:</span>
<a id="__codelineno-0-426" name="__codelineno-0-426"></a>            <span class="k">break</span>
<a id="__codelineno-0-427" name="__codelineno-0-427"></a>
<a id="__codelineno-0-428" name="__codelineno-0-428"></a>    <span class="c1"># Check performance of model on all datasets</span>
<a id="__codelineno-0-429" name="__codelineno-0-429"></a>
<a id="__codelineno-0-430" name="__codelineno-0-430"></a>    <span class="c1"># load best model</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>    <span class="n">model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filepaths</span><span class="o">.</span><span class="n">filepath_model_current_hydra_output</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>    <span class="c1"># close initial dataset</span>
<a id="__codelineno-0-434" name="__codelineno-0-434"></a>    <span class="n">dataset</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<a id="__codelineno-0-435" name="__codelineno-0-435"></a>    <span class="c1"># copy dataset to hydra output directory</span>
<a id="__codelineno-0-436" name="__codelineno-0-436"></a>    <span class="n">_path</span> <span class="o">=</span> <span class="n">filepaths</span><span class="o">.</span><span class="n">filepath_dataset_current_hydra_output</span><span class="p">()</span>
<a id="__codelineno-0-437" name="__codelineno-0-437"></a>    <span class="n">shutil</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">filepaths</span><span class="o">.</span><span class="n">filepath_dataset_from_config</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">),</span> <span class="n">_path</span><span class="p">)</span>
<a id="__codelineno-0-438" name="__codelineno-0-438"></a>    <span class="n">dataset</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">_path</span><span class="p">,</span> <span class="s1">&#39;r+&#39;</span><span class="p">)</span>
<a id="__codelineno-0-439" name="__codelineno-0-439"></a>    <span class="c1"># add model outputs to dataset</span>
<a id="__codelineno-0-440" name="__codelineno-0-440"></a>    <span class="k">for</span> <span class="n">context</span><span class="p">,</span> <span class="n">dataloader</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">,</span> <span class="s1">&#39;common_test&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">,</span> <span class="n">common_test_loader</span><span class="p">]):</span>
<a id="__codelineno-0-441" name="__codelineno-0-441"></a>        <span class="n">ret_vals</span><span class="p">,</span> <span class="n">model_outputs</span> <span class="o">=</span> <span class="n">test_or_validate_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">nn_model</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">n_passes_test</span><span class="p">,</span> <span class="n">all_batches</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_model_outputs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-442" name="__codelineno-0-442"></a>
<a id="__codelineno-0-443" name="__codelineno-0-443"></a>        <span class="c1"># log stats with logging</span>
<a id="__codelineno-0-444" name="__codelineno-0-444"></a>        <span class="n">string</span> <span class="o">=</span> <span class="n">context</span>
<a id="__codelineno-0-445" name="__codelineno-0-445"></a>        <span class="n">string</span> <span class="o">=</span> <span class="n">string</span> <span class="o">+</span> <span class="s1">&#39;: loss: </span><span class="si">{:.4f}</span><span class="s1"> | mse: </span><span class="si">{:.4f}</span><span class="s1"> | kl_loss: </span><span class="si">{:.4f}</span><span class="s1"> | regressor_loss: </span><span class="si">{:.4f}</span><span class="s1"> | pop. dim: </span><span class="si">{}</span><span class="s1"> |&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-446" name="__codelineno-0-446"></a>            <span class="n">ret_vals</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
<a id="__codelineno-0-447" name="__codelineno-0-447"></a>            <span class="n">ret_vals</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">],</span>
<a id="__codelineno-0-448" name="__codelineno-0-448"></a>            <span class="n">ret_vals</span><span class="p">[</span><span class="s1">&#39;kl_loss&#39;</span><span class="p">],</span>
<a id="__codelineno-0-449" name="__codelineno-0-449"></a>            <span class="n">ret_vals</span><span class="p">[</span><span class="s1">&#39;regressor_loss&#39;</span><span class="p">],</span>
<a id="__codelineno-0-450" name="__codelineno-0-450"></a>            <span class="n">ret_vals</span><span class="p">[</span><span class="s1">&#39;populated_dims&#39;</span><span class="p">],</span>
<a id="__codelineno-0-451" name="__codelineno-0-451"></a>        <span class="p">)</span>
<a id="__codelineno-0-452" name="__codelineno-0-452"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">string</span><span class="p">)</span>
<a id="__codelineno-0-453" name="__codelineno-0-453"></a>
<a id="__codelineno-0-454" name="__codelineno-0-454"></a>        <span class="c1"># save loss function values</span>
<a id="__codelineno-0-455" name="__codelineno-0-455"></a>        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">ret_vals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-456" name="__codelineno-0-456"></a>            <span class="n">dataset</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">context</span><span class="o">+</span><span class="s1">&#39;/&#39;</span><span class="o">+</span><span class="n">key</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">value</span><span class="p">)</span> 
<a id="__codelineno-0-457" name="__codelineno-0-457"></a>        <span class="c1"># save reconstructed timeseries and raw loss function values</span>
<a id="__codelineno-0-458" name="__codelineno-0-458"></a>        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">model_outputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-459" name="__codelineno-0-459"></a>            <span class="n">dataset</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">context</span><span class="o">+</span><span class="s1">&#39;/&#39;</span><span class="o">+</span><span class="n">key</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
<a id="__codelineno-0-460" name="__codelineno-0-460"></a>        <span class="c1"># log to mlflow</span>
<a id="__codelineno-0-461" name="__codelineno-0-461"></a>        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">append_context_to_dict_keys</span><span class="p">(</span><span class="n">ret_vals</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
<a id="__codelineno-0-462" name="__codelineno-0-462"></a>    <span class="n">dataset</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<a id="__codelineno-0-463" name="__codelineno-0-463"></a>
<a id="__codelineno-0-464" name="__codelineno-0-464"></a>    <span class="c1"># save this file and the vae_architecture.py file to hydra output directory</span>
<a id="__codelineno-0-465" name="__codelineno-0-465"></a>    <span class="n">shutil</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">),</span> <span class="n">filepaths</span><span class="o">.</span><span class="n">dir_current_hydra_output</span><span class="p">())</span>
<a id="__codelineno-0-466" name="__codelineno-0-466"></a>    <span class="k">return</span> <span class="n">ret_vals</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="bnode_core.nn.vae.vae_train_test.main" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">main</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Entry point for VAE training via Hydra CLI.</p>
<p>Initializes Hydra configuration system and launches train with validated
config. Auto-detects config directory and uses 'train_test_vae' as the
default config name.</p>
<p>This function can be registered in pyproject.toml, enabling command-line
execution via a custom script name.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <p>Run from command line::</p>
<div class="highlight"><pre><span></span><code>uv run python -m bnode_core.nn.vae.vae_train_test
</code></pre></div>
<p>With config overrides::</p>
<div class="highlight"><pre><span></span><code>uv run python -m bnode_core.nn.vae.vae_train_test \
    nn_model.training.lr_start=0.0001 \
    dataset_name=my_dataset
</code></pre></div>


<details class="side-effects" open>
  <summary>Side Effects</summary>
  <ul>
<li>Registers config store with Hydra</li>
<li>Auto-detects config directory from filepaths</li>
<li>Launches Hydra-decorated train function</li>
</ul>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/bnode_core/nn/vae/vae_train_test.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-468" name="__codelineno-0-468"></a><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
<a id="__codelineno-0-469" name="__codelineno-0-469"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Entry point for VAE training via Hydra CLI.</span>
<a id="__codelineno-0-470" name="__codelineno-0-470"></a>
<a id="__codelineno-0-471" name="__codelineno-0-471"></a><span class="sd">    Initializes Hydra configuration system and launches train with validated</span>
<a id="__codelineno-0-472" name="__codelineno-0-472"></a><span class="sd">    config. Auto-detects config directory and uses &#39;train_test_vae&#39; as the</span>
<a id="__codelineno-0-473" name="__codelineno-0-473"></a><span class="sd">    default config name.</span>
<a id="__codelineno-0-474" name="__codelineno-0-474"></a>
<a id="__codelineno-0-475" name="__codelineno-0-475"></a><span class="sd">    This function can be registered in pyproject.toml, enabling command-line</span>
<a id="__codelineno-0-476" name="__codelineno-0-476"></a><span class="sd">    execution via a custom script name.</span>
<a id="__codelineno-0-477" name="__codelineno-0-477"></a>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a><span class="sd">    Examples:</span>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a><span class="sd">        Run from command line::</span>
<a id="__codelineno-0-480" name="__codelineno-0-480"></a>
<a id="__codelineno-0-481" name="__codelineno-0-481"></a><span class="sd">            uv run python -m bnode_core.nn.vae.vae_train_test</span>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a><span class="sd">        With config overrides::</span>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="sd">            uv run python -m bnode_core.nn.vae.vae_train_test \\</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a><span class="sd">                nn_model.training.lr_start=0.0001 \\</span>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a><span class="sd">                dataset_name=my_dataset</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a><span class="sd">    Side Effects:</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a><span class="sd">        - Registers config store with Hydra</span>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a><span class="sd">        - Auto-detects config directory from filepaths</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a><span class="sd">        - Launches Hydra-decorated train function</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>    <span class="kn">from</span><span class="w"> </span><span class="nn">bnode_core.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_config_store</span>
<a id="__codelineno-0-496" name="__codelineno-0-496"></a>    <span class="n">cs</span> <span class="o">=</span> <span class="n">get_config_store</span><span class="p">()</span>
<a id="__codelineno-0-497" name="__codelineno-0-497"></a>    <span class="n">config_dir</span> <span class="o">=</span> <span class="n">filepaths</span><span class="o">.</span><span class="n">config_dir_auto_recognize</span><span class="p">()</span>
<a id="__codelineno-0-498" name="__codelineno-0-498"></a>    <span class="n">config_name</span> <span class="o">=</span> <span class="s1">&#39;train_test_vae&#39;</span>
<a id="__codelineno-0-499" name="__codelineno-0-499"></a>    <span class="n">hydra</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="n">config_path</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">config_dir</span><span class="o">.</span><span class="n">absolute</span><span class="p">()),</span> <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span> <span class="n">version_base</span><span class="o">=</span><span class="kc">None</span><span class="p">)(</span><span class="n">train</span><span class="p">)()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/julius-aka/" target="_blank" rel="noopener" title="www.uni-augsburg.de" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M16.36 14c.08-.66.14-1.32.14-2s-.06-1.34-.14-2h3.38c.16.64.26 1.31.26 2s-.1 1.36-.26 2m-5.15 5.56c.6-1.11 1.06-2.31 1.38-3.56h2.95a8.03 8.03 0 0 1-4.33 3.56M14.34 14H9.66c-.1-.66-.16-1.32-.16-2s.06-1.35.16-2h4.68c.09.65.16 1.32.16 2s-.07 1.34-.16 2M12 19.96c-.83-1.2-1.5-2.53-1.91-3.96h3.82c-.41 1.43-1.08 2.76-1.91 3.96M8 8H5.08A7.92 7.92 0 0 1 9.4 4.44C8.8 5.55 8.35 6.75 8 8m-2.92 8H8c.35 1.25.8 2.45 1.4 3.56A8 8 0 0 1 5.08 16m-.82-2C4.1 13.36 4 12.69 4 12s.1-1.36.26-2h3.38c-.08.66-.14 1.32-.14 2s.06 1.34.14 2M12 4.03c.83 1.2 1.5 2.54 1.91 3.97h-3.82c.41-1.43 1.08-2.77 1.91-3.97M18.92 8h-2.95a15.7 15.7 0 0 0-1.38-3.56c1.84.63 3.37 1.9 4.33 3.56M12 2C6.47 2 2 6.5 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10A10 10 0 0 0 12 2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/julius-aka/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 3a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2zm-.5 15.5v-5.3a3.26 3.26 0 0 0-3.26-3.26c-.85 0-1.84.52-2.32 1.3v-1.11h-2.79v8.37h2.79v-4.93c0-.77.62-1.4 1.39-1.4a1.4 1.4 0 0 1 1.4 1.4v4.93zM6.88 8.56a1.68 1.68 0 0 0 1.68-1.68c0-.93-.75-1.69-1.68-1.69a1.69 1.69 0 0 0-1.69 1.69c0 .93.76 1.68 1.69 1.68m1.39 9.94v-8.37H5.5v8.37z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://scholar.google.com/citations?user=7SypqSQAAAAJ&hl" target="_blank" rel="noopener" title="scholar.google.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 3 1 9l11 6 9-4.91V17h2V9M5 13.18v4L12 21l7-3.82v-4L12 17z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/juliusaka" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.instant", "navigation.top", "navigation.tabs", "search.suggest", "search.highlight"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
    
  </body>
</html>